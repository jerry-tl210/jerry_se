{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM, BertForQuestionAnswering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence \n",
    "import torchvision\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.optimization import AdamW\n",
    "from transformers.optimization import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = pd.read_json(\"FGC_release_1.7.13/FGC_release_all_dev.json\")\n",
    "training_data = pd.read_json(\"FGC_release_1.7.13/FGC_release_all_train.json\")\n",
    "test_data = pd.read_json(\"FGC_release_1.7.13/FGC_release_all_test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_load(fp):\n",
    "    with open(fp) as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json_load(\"FGC_release_1.7.13/FGC_release_all_dev.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 4]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['QUESTIONS'][0]['SHINT_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all the questions where there's no supporting evidence to it\n",
    "training_data = training_data[training_data['QUESTIONS'].apply(lambda x: len(x[0]['SHINT_']) > 0)]\n",
    "validation_data = validation_data[validation_data['QUESTIONS'].apply(lambda x: len(x[0]['SHINT_']) > 0)]\n",
    "test_data = test_data[test_data['QUESTIONS'].apply(lambda x: len(x[0]['SHINT_']) > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DID</th>\n",
       "      <th>QUESTIONS</th>\n",
       "      <th>DTEXT</th>\n",
       "      <th>DTEXT_CN</th>\n",
       "      <th>SENTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>D002</td>\n",
       "      <td>[{'QID': 'D002Q01', 'QTYPE': '基礎題', 'ATYPE_': ...</td>\n",
       "      <td>嘉佑二年（1057年），蘇軾才20歲，與弟弟蘇轍一同進京參加會考，蘇軾中進士第2名。當時主試...</td>\n",
       "      <td>嘉佑二年（1057年），苏轼才20岁，与弟弟苏辙一同进京参加会考，苏轼中进士第2名。当时主试...</td>\n",
       "      <td>[{'text': '嘉佑二年（1057年），', 'start': 0, 'end': 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DID                                          QUESTIONS  \\\n",
       "0  D002  [{'QID': 'D002Q01', 'QTYPE': '基礎題', 'ATYPE_': ...   \n",
       "\n",
       "                                               DTEXT  \\\n",
       "0  嘉佑二年（1057年），蘇軾才20歲，與弟弟蘇轍一同進京參加會考，蘇軾中進士第2名。當時主試...   \n",
       "\n",
       "                                            DTEXT_CN  \\\n",
       "0  嘉佑二年（1057年），苏轼才20岁，与弟弟苏辙一同进京参加会考，苏轼中进士第2名。当时主试...   \n",
       "\n",
       "                                               SENTS  \n",
       "0  [{'text': '嘉佑二年（1057年），', 'start': 0, 'end': 1...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['苏东坡的老家在哪?',\n",
       " '苏东坡出生于哪一年?',\n",
       " '苏东坡和谁一起进京参加会考?',\n",
       " '苏东坡在会考中所写的作文题目为何?',\n",
       " '苏东坡与曾巩是否同为欧阳修的学生?',\n",
       " '苏东坡与王安石在职场上是否理念相同?',\n",
       " '王安石在宋朝哪一位皇帝手下做事?',\n",
       " '宋神宗是否信任苏东坡?',\n",
       " '在苏东坡被王安石诬陷时，谁为他说话？',\n",
       " '苏东坡在宋哲宗时期,曾出任过哪些官职?',\n",
       " '苏东坡曾在哪些城市工作过?',\n",
       " '苏东坡工作地点离京城最远的地点在哪里?',\n",
       " '苏东坡哪一年离开海南岛?',\n",
       " '苏东坡死于哪一年?',\n",
       " '苏东坡在哪个城市过世?',\n",
       " '苏东坡死后葬在哪里?',\n",
       " '苏东坡对于王安石变法的态度为何?',\n",
       " '苏东坡是否为一好官?',\n",
       " '苏东坡是否弊案缠身？',\n",
       " '首次使用「阿拉伯之春」描述阿拉伯世界的革命浪潮，是哪一个媒体？',\n",
       " '在「阿拉伯之春」运动中，哪一个国家成功从专制政体走向民主？',\n",
       " '哪一个组织在在「阿拉伯之春」运动中借机壮大，并使国家陷入动乱？',\n",
       " '引发「阿拉伯之春」运动的自焚青年叫什么名字?',\n",
       " '「阿拉伯之春」运动的的起源地在哪里?',\n",
       " '「阿拉伯之春」运动中，被推翻的突尼西亚总统是谁?',\n",
       " '「阿拉伯之春」运动中，被推翻的突尼西亚总统在第一时间逃到哪个国家?',\n",
       " '「阿拉伯之春」运动中，有哪六个国家政权被推翻？',\n",
       " '「阿拉伯之春」运动中，被推翻的埃及总统是哪一位?',\n",
       " '「阿拉伯之春」运动中，被推翻的利比亚总统是哪一位?',\n",
       " '「阿拉伯之春」运动中，被推翻的叶门总统是哪一位?',\n",
       " '「阿拉伯之春」运动中，被推翻的阿尔及利亚总统是哪一位?',\n",
       " '「阿拉伯之春」运动中，被推翻的苏丹总统是哪一位?',\n",
       " '「茉莉花革命」开始于哪一年?',\n",
       " '「茉莉花革命」发生在哪一个国家?',\n",
       " '「茉莉花」是哪一个国家的国花?',\n",
       " '「茉莉花革命」又被西方媒体称为什么事件?',\n",
       " '「茉莉花革命」充分运用了新兴媒体传递消息，所以又被称为什么革命？',\n",
       " '「茉莉花革命」的影响了阿拉伯世界的哪些地区?',\n",
       " '气象学上「台风」是指热带气旋中心持续风速已达到每小时多少公里以上?',\n",
       " '形成于北大西洋的热带气旋，又被称为什么？',\n",
       " '形成于北太平洋的热带气旋，又被称为什么？',\n",
       " '形成于北印度洋的热带气旋，又被称为什么？',\n",
       " '发生于美国的热带气旋，我们叫它什么？',\n",
       " '发生于韩国的热带气旋，我们叫它什么？',\n",
       " '发生于日本的热带气旋，我们叫它什么？',\n",
       " '发生于台湾的热带气旋，我们叫它什么？',\n",
       " '高雄市最大的河流是哪一条?',\n",
       " '台湾水系最大的河流是哪一条?',\n",
       " '高屏溪流经哪些县市?',\n",
       " '高雄市境内有几条河川流过?',\n",
       " '高雄市境内有哪几条河川流过?',\n",
       " '高雄市的空气品质好不好?',\n",
       " '高雄市的空气品质最不好的行政区是哪里?',\n",
       " '高雄市哪两个地区的空污最为严重?',\n",
       " '全台湾悬浮微粒每小时浓度超标第一名的城市是?',\n",
       " '到高雄想泡温泉可以去哪些地区呢?',\n",
       " '文本中描述了台湾哪两条河川以泛舟闻名?',\n",
       " '以恶地景观著名的是高雄哪一个景点?',\n",
       " '高雄的月世界位于哪一个行政区划?',\n",
       " '高雄最大的湖泊是哪一座?',\n",
       " '新版的北美贸易协定英文简称为何?',\n",
       " '新版的北美贸易协定英文全名为何?',\n",
       " '新版的北美贸易协定中文名称为何?',\n",
       " '北美贸易协定涉及哪三个国家?',\n",
       " '第一次签订的北美贸易协定于何时签署?',\n",
       " '第一次签订的北美贸易协定于何时生效?',\n",
       " '第一次签订的北美贸易协定从签署至生效过了几日?',\n",
       " '第二次签订的北美贸易协定于何时签署?',\n",
       " '第二次签订的北美贸易协定原先预计于何时生效?',\n",
       " '科技部「与AI对话」比赛何时开始报名?',\n",
       " '科技部「与AI对话」比赛报名截止日期是哪一天?',\n",
       " '科技部「与AI对话」比赛第1名最高可获得多少元的奖金?',\n",
       " '科技部「与AI对话」比赛语音辨识模组是哪一个系统?',\n",
       " '科技部「与AI对话」比赛语音辨识模组是哪一个实验室的系统?',\n",
       " '科技部「与AI对话」比赛语音辨识系统是由哪一位研究学者领军?',\n",
       " '科技部「与AI对话」初赛预计在何时举行?(请以西元年月作答)',\n",
       " '科技部「与AI对话」决赛预计在何时举行?(请以西元年月作答)',\n",
       " '科技部「与AI对话」初赛预计在何时举行?(请以国历年月作答)',\n",
       " '科技部「与AI对话」决赛预计在何时举行?(请以国历年月作答)',\n",
       " '父亲的兄长，我们要称他为什么？',\n",
       " '爸爸的哥哥，要如何称呼他？',\n",
       " '父亲的弟弟，我们要称他为什么？',\n",
       " '爸爸的弟弟，要如何称呼他？',\n",
       " '父亲的姐姐，我们要称她为什么？',\n",
       " '父亲的妹妹，我们要称她为什么？',\n",
       " '母亲的兄长，我们要称他为什么？',\n",
       " '妈妈的哥哥，要如何称呼他？',\n",
       " '母亲的弟弟，我们要称他为什么？',\n",
       " '妈妈的弟弟，要如何称呼他？',\n",
       " '母亲的姐姐，我们要称她为什么？',\n",
       " '母亲的妹妹，我们要称她为什么？',\n",
       " '伯伯的妻子，要如何称呼她？',\n",
       " '伯伯的配偶，要如何称呼她？',\n",
       " '叔叔的妻子，要如何称呼她？',\n",
       " '姑姑的先生，我们要称他为什么？',\n",
       " '姑姑的丈夫，我们要称他为什么？',\n",
       " '姑姑的另一半，我们要称他为什么？',\n",
       " '阿姨的另一半，我们要称他为什么？',\n",
       " '阿姨的丈夫，我们要称他为什么？',\n",
       " '被称为计算机科学与人工智慧之父的是哪位学者?',\n",
       " '图灵在二战期间在哪里工作?',\n",
       " '图灵在二战期间工作的机构地点在哪里?',\n",
       " '图灵在二战期间破解了哪一个国家的海军密码?',\n",
       " '图灵是哪一国人?',\n",
       " '图灵出生于哪一年?',\n",
       " '图灵于哪一年过逝?',\n",
       " '图灵几岁时过逝?',\n",
       " '最早的计算机软体叫么名字?',\n",
       " '最早的计算机位于哪一个机构内?',\n",
       " '哥哥的太太在亲属关系中是我的谁?',\n",
       " '弟弟的太太在亲属关系中是我的谁?',\n",
       " '姐姐的先生亲属关系中是我的谁?',\n",
       " '妹妹的先生亲属关系中是我的谁?',\n",
       " '对丈夫的哥哥要如何称呼他?(亲属关系称谓)',\n",
       " '对丈夫的弟弟要如何称呼他?(亲属关系称谓)',\n",
       " '对丈夫的姐姐要如何称呼他?(亲属关系称谓)',\n",
       " '对丈夫的妹妹要如何称呼他?(亲属关系称谓)',\n",
       " '对太太的哥哥要如何称呼他?(亲属关系称谓)',\n",
       " '对太太的弟弟要如何称呼他?(亲属关系称谓)',\n",
       " '对太太的姐姐要如何称呼他?(亲属关系称谓)',\n",
       " '对太太的妹妹要如何称呼他?(亲属关系称谓) ',\n",
       " '兄弟的太太之间在亲属关系的称谓为何?',\n",
       " '姐妹的先生之间在亲属关系的称谓为何?',\n",
       " '弟弟的太太要如何称呼哥哥的太太?',\n",
       " '新闻中的沼气发电设备位于台湾的哪一个县市?',\n",
       " '新闻中的沼气发电设备位于哪一座牧场内?',\n",
       " '新闻中的沼气发电的原料是什么动物的排泄物?',\n",
       " '新合兴牧场位于南投县的哪一个行政区?',\n",
       " '买下新合兴牧场的公司名称为何?',\n",
       " '新合兴牧场的拥有者是谁?',\n",
       " '吴昆民在祥圃实业公司担任的职务为?',\n",
       " '新闻中的沼气发电系统是采用什么技术?',\n",
       " '新合兴牧场沼气发电设备的建置是由哪些团队合作而完成的?',\n",
       " '新合兴牧场沼气发电设备于民国哪一年完工?',\n",
       " '新合兴牧场沼气发电设备于民国哪一年开始运转?',\n",
       " '负责新合兴牧场沼气发电设备设计与施工的瑞助营造获得何种奖项?',\n",
       " '新合兴牧场沼气发电系统目前仰赖多少头猪的排泄物来发电?',\n",
       " '新合兴牧场与哪一个公司签定售电合约?',\n",
       " '新合兴牧场沼气发电设备预计每年可以有多少的产电收入?',\n",
       " '「悬浮微粒特征对民众健康影响之研究」测试了哪六大通勤方式?',\n",
       " '这份研究报告是由哪两个单位合作进行的研究?',\n",
       " '这份研究报告使用的测量工具为何？',\n",
       " '哪一种通勤方式所接触的PM2.5的瞬间数值最高?',\n",
       " '哪一种通勤方式所接触的PM2.5的平均数值最高?',\n",
       " '六大通勤方式的细悬浮微粒（PM2.5）平均浓度暴露由高至低前三名是哪三种交通工具?',\n",
       " '徐淑芷任职于哪个单位?',\n",
       " '测量捷运空气品质的空气盒子装置于捷运的哪个位置?',\n",
       " '本文中提到几个聊天机器人?',\n",
       " '史上第一个聊天机器人叫什么名字?',\n",
       " '史上第一个聊天机器人是哪一个机构发明的?',\n",
       " '史上第一个聊天机器人是哪一年发明的?',\n",
       " '根据维基百科定义，什么是聊天机器人?',\n",
       " '本文中提到哪些聊天机器人?',\n",
       " '「小冰」是哪一家公司的产品?',\n",
       " '爸爸的祖父要如何称呼他呢？',\n",
       " '爸爸的祖母要如何称呼她呢？',\n",
       " '爸爸的外祖父要如何称呼他呢？',\n",
       " '爸爸的外祖母要如何称呼她呢？',\n",
       " '爸爸的爸爸要如何称呼他呢？',\n",
       " '爸爸的妈妈要如何称呼她呢？',\n",
       " '爷爷是爸爸的什么人？',\n",
       " '祖父是爸爸的什么人？',\n",
       " '奶奶是爸爸的什么人？',\n",
       " '阿嬷是爸爸的什么人？',\n",
       " '有哪些队伍在预选赛就被淘汰而无缘参与2018世界杯足球赛?(文本中)',\n",
       " '2018年世界杯足球赛的前四强是哪四个国家的足球队?',\n",
       " '2018年世界杯足球赛冠军是哪一队?',\n",
       " '2018年世界杯足球赛季军是哪一队?',\n",
       " '2018年世界杯足球赛殿军是哪一队?',\n",
       " '2018年世界杯足球赛第一名是哪一队?',\n",
       " '2018年世界杯足球赛第三名是哪一队?',\n",
       " '陈由豪曾经担任哪一家公司的总裁？',\n",
       " '陈由豪多少年前欠债欠税潜逃至大陆？',\n",
       " '陈由豪目前人在哪一个国家？',\n",
       " '陈由豪名列台湾十大通缉要犯主要因为那两大案件？',\n",
       " '陈由豪还有多少税款尚未缴清？',\n",
       " '郭雪湖本名为何？',\n",
       " '郭金火幼时是否由父亲独力扶养长大？',\n",
       " '郭雪湖在几岁的时候，母亲带他前往『雪溪画馆』拜师学艺？',\n",
       " '郭金火在16岁的时候拜谁为师？',\n",
       " '郭雪湖的冥诞是哪一天？',\n",
       " '郭雪胡出生于哪里？',\n",
       " '郭雪湖的妻子是谁？',\n",
       " '郭雪湖曾去过哪些国家？',\n",
       " '郭雪湖有几个孩子？',\n",
       " '发现郭雪湖绘画天分的小学老师为谁？',\n",
       " '郭雪湖的妻子的专业为何？',\n",
       " '帮助郭雪湖奠定描绘观音、帝君及裱褙的技艺的画家为谁？',\n",
       " '13 郭雪湖何时过世？',\n",
       " '郭雪湖几岁过世？',\n",
       " '郭雪湖享年几岁',\n",
       " '「郭雪湖百岁回顾展」于何时展出？',\n",
       " '2019三义木雕艺术节从哪一天开始?',\n",
       " '2019三义木雕艺术节到哪一天结束?',\n",
       " '2019三义木雕艺术节在哪个县市举办?',\n",
       " '2019三义木雕艺术节首日由哪两个活动揭开序幕?',\n",
       " '2019三义木雕艺术节活动于三义的哪两个地点举行?',\n",
       " '斯文豪的英文全名为?',\n",
       " '斯文豪的中文译名有哪些?',\n",
       " '斯文豪出生地在哪里?',\n",
       " '斯文豪的曾担任台湾哪个地区的领事?',\n",
       " '斯文豪的在担任驻台湾领事时，对于哪一动物的生态特别有兴趣?',\n",
       " '斯文豪出生于哪一年？',\n",
       " '斯文豪哪一年开始担任外交官？',\n",
       " '斯文豪去世时是几岁？',\n",
       " '世界上最早的中国与台湾鸟类名录被收录在哪个学会的杂志？',\n",
       " '世界上最早的中国与台湾鸟类名录被收录在哪一个杂志？',\n",
       " '世界上最早的中国与台湾鸟类名录是哪一位鸟类研究学者所撰写？',\n",
       " '张大千的出生地在中国哪里?',\n",
       " '张大千的生日是哪一天?',\n",
       " '张大千几岁时过逝呢?',\n",
       " '有「渡海三家」之称的是哪三位艺术家?',\n",
       " '与张大千同一时期的还有哪些有名的艺术家?(文本中)',\n",
       " '文中提及张大千曾经在哪些国家举办过画展?',\n",
       " '张大千曾经在哪些城市举办过画展?',\n",
       " '张大千曾经在哪里举办过画展?',\n",
       " '张大千特有的画功是什么?',\n",
       " '张大千哪一年离开中国?',\n",
       " '张大千哪一年定居台湾?',\n",
       " '张大千哪一年去世?',\n",
       " '张大千在哪里去世?',\n",
       " '张大千离开中国到定居台北，中间隔了多长的时间?',\n",
       " '张大千得到纽约国际艺术学会选为世界大画家荣获金奖的作品是哪一幅画作?',\n",
       " '张大千先生的最后一部大作是哪一幅画?',\n",
       " '莎士比亚的中文全名为?',\n",
       " '莎士比亚的英文全名为?',\n",
       " '莎士比亚的生日是哪一天?',\n",
       " '莎士比亚的出生地在哪?',\n",
       " '莎士比亚的妻子叫什么名字?',\n",
       " '莎士比亚死于何地?',\n",
       " '莎士比亚的喜剧作品有哪些?(在文本中)',\n",
       " '莎士比亚的悲剧作品有哪些?(在文本中)',\n",
       " '莎士比亚的悲喜剧作品有哪些?(在文本中)',\n",
       " '美国总统川普现年几岁?',\n",
       " '美国总统川普在家排行老几?',\n",
       " '美国总统川普有几个兄弟姊妹?',\n",
       " '美国总统川普的英文全名为?',\n",
       " '美国总统川普有个当法官的姐姐叫什么名字?',\n",
       " '美国总统川普总共有几个小孩?',\n",
       " '美国总统川普结了几次婚?',\n",
       " '美国总统川普离过几次婚?',\n",
       " '美国总统川普在当总统前是做什么的?',\n",
       " '美国总统川普几岁时当上总统?',\n",
       " '现任美国第一夫人是谁?',\n",
       " '马可.波罗在几岁的时候跟著父亲和叔父去遥远的东方做生意？',\n",
       " '马可.波罗的宗教信仰为何?',\n",
       " '马可.波罗第一次抵达中国是哪一年？',\n",
       " '马可.波罗和父亲以及叔父晋见了哪一朝的皇帝？',\n",
       " '马可.波罗和父亲以及叔父去的元朝是哪一位皇帝？',\n",
       " '哪一位教宗写信给匆必烈?',\n",
       " '马可.波罗受到谁的托咐，护送蒙古公主出嫁？',\n",
       " '马可.波罗护送蒙古公主到哪一个国家合亲？',\n",
       " '马可.波罗护送的蒙古公主叫什么名字？',\n",
       " '马可.波罗是哪一国人？(文本中)',\n",
       " '妈妈的阿公，我要怎么称呼他？',\n",
       " '妈妈的阿妈，我要怎么称呼她？',\n",
       " '在亲属关系中，我的外公是谁的爸爸？',\n",
       " '在亲属关系中，我的外婆是谁的妈妈？',\n",
       " '在亲属关系中，妈妈的哥哥，我要叫他什么？',\n",
       " '在亲属关系中，妈妈的姐姐，我要叫他什么？',\n",
       " '在亲属关系中，阿姨的先生是我的什么人?',\n",
       " '在亲属关系中，舅舅的太太是我的什么人?',\n",
       " '第二届「科技大擂台 与AI对话」哪一天开始报名?(完整日期年月日)',\n",
       " '科技部表示今年竞赛的重点在于AI的哪一项能力?(文本中)',\n",
       " '根据新闻文本，第二届科技大擂台的测验有哪两大类?',\n",
       " 'ＡＩ应用核心是什么技术？',\n",
       " '第二届「科技大擂台 与AI对话」报名截止日是哪一天?',\n",
       " '为让年青学子也能共同参与ＡＩ人机对话应用，科技部还举办了什么活动？',\n",
       " 'FUN CUP营队何时开始报名？(完整日期年月日)',\n",
       " '这起事故发生在哪个路段？',\n",
       " '事故发生的时间？（完整日期与时间）',\n",
       " '这起事故的肇事者是谁？',\n",
       " '这起事故的肇事者驾驶何种车辆？',\n",
       " '这起事故连同肇事车辆共波及多少部车？',\n",
       " '这起事故有多少人受伤？',\n",
       " '这起事故的肇事车辆是从哪里出发？',\n",
       " '这起事故的肇事车辆的目的地是哪里？',\n",
       " '这起事故的肇事者是否酒驾?',\n",
       " '这起事故的肇事车辆所载的货物是什么?',\n",
       " '自然界中的能源常以哪些型式存在？',\n",
       " '传统对能源的二分法是哪两类？',\n",
       " '石油是否为可再生能源？',\n",
       " '太阳能是否为不可再生能源？',\n",
       " '火力发电厂所使用的煤是否为可再生能源？',\n",
       " '风力发电厂是否仰赖不可再生能源？',\n",
       " '生质燃料是否为可再生能源?',\n",
       " '生质燃料是否有效减低全球暖化的速度?',\n",
       " '生质燃料是否对生态保护也有一定的效果?',\n",
       " '试举出文本中非动物废弃物的生质燃料原料。',\n",
       " '试举出文本中五项作为生质燃料原料的粮食作物。',\n",
       " '文本中有哪些水果也能作为生质燃料的原料?',\n",
       " '文本中有哪些生质燃料已证实对环境造成负面影响?',\n",
       " '传统媒体与社群媒体在传递讯息的速度上，哪一个比较快？',\n",
       " '传统媒体与社群媒体在传递讯息的内容上，哪一个专业门槛较高？',\n",
       " '传统媒体与社群媒体在传递讯息的内容上，哪一个比较容易更新？',\n",
       " '传统媒体与社群媒体在传递讯息的制作成本上，哪一个比较高？',\n",
       " '传统媒体与社群媒体在点阅率上，哪一个可以快速被量化？',\n",
       " '奈米技术在广义上是制造尺寸多大的结构技术?',\n",
       " '奈米尺度下，什么金属会从原本不透明变为透明？',\n",
       " '奈米尺度下，什么金属会在室温下由固体变成液体？',\n",
       " '奈米尺度下，什么材质会从原本的绝绿体变为导体？',\n",
       " '第一个提出奈米技术概念的研究学者是哪位?\\u3000',\n",
       " '第一个提出奈米科技定义的研究学者是哪位?',\n",
       " '奈米元年是哪一年?',\n",
       " '奈米元年的提出哪一项应用被发明出来?',\n",
       " '生物医学所使用的奈米结晶金属是哪两种?(在本文中)',\n",
       " '可用来杀菌的奈米结晶金属是哪一种?(在本文中)',\n",
       " '可用做人工关节的奈米结晶金属是哪一种?(在本文中)',\n",
       " '繁体字在哪些地区被使用?',\n",
       " '繁体字有哪些不同称呼?',\n",
       " '香港何时回归中国?',\n",
       " '香港哪一年回归中国?',\n",
       " '香港主权移交至中国至今(2020年)，已有多少年？',\n",
       " '澳门何时回归中国?',\n",
       " '澳门哪一年回归中国?',\n",
       " '澳门主权移交至中国至今(2020年)，已有多少年？',\n",
       " '「繁体字」一词最早出现于哪一年?',\n",
       " '台湾官方使用的中文是「简体字」还是「繁体字」?',\n",
       " '香港官方使用的中文是「简体字」还是「繁体字」?',\n",
       " '新加坡官方使用的中文是「简体字」还是「繁体字」?',\n",
       " '伊甸基金会是由谁所创立的?',\n",
       " '伊甸基金会于哪一年成立的?',\n",
       " '伊甸基金会主要服务的对象有哪些?',\n",
       " '伊甸基金会成立至2017年有多少年了?',\n",
       " '伊甸基金会任用身心障碍者工作占全体员工的百分比是多少?',\n",
       " '宝可梦的英文是什么?',\n",
       " '宝可梦在中国地区的译名有哪些?',\n",
       " '第一个宝可梦游戏起源于何时?',\n",
       " '宝可梦至2019年8月止, 一共有多少种精灵宝可梦生物?',\n",
       " '宝可梦是哪一公司的产品?',\n",
       " '宝可梦在1996年发行时的游戏名称叫什么?',\n",
       " '宝可梦最早是由谁所提出的?',\n",
       " '皮卡丘的英文怎么拼写?',\n",
       " '皮卡丘的名字是怎么来的?',\n",
       " '皮卡丘身高几公分?',\n",
       " '皮卡丘体重是几公斤?',\n",
       " '皮卡丘的肤色是什么颜色?',\n",
       " '《精灵宝可梦》系列有多少个虚构生物?',\n",
       " '《精灵宝可梦》系列中最具代表性的宝可梦是哪一个?',\n",
       " '2019年在台湾举办的宝可梦活动从哪一天开始?',\n",
       " '2019年在台湾举办的宝可梦活动到哪一天结束?',\n",
       " '2019年在台湾举办的宝可梦活动为期几天?',\n",
       " '2019年在台湾举办的宝可梦活动的地点在哪呢?',\n",
       " '2019年台湾宝可梦活动在哪一个县市举办?',\n",
       " '2019年台湾宝可梦活动期间有哪些宝可梦精灵在新北市景点出现?',\n",
       " '有哪些大众运输工具可以到达2019年台湾宝可梦活动会场呢?',\n",
       " '台湾第一次发现H1N1流感的日期是哪一天?',\n",
       " '台湾第一次发现H1N1群聚感染的日期是哪一天?',\n",
       " '台湾第一次发现H1N1群聚感染的人数有几人?',\n",
       " '台湾第一起因 H1N1 过逝的人是谁?',\n",
       " '台湾第一起因 H1N1 死亡的案例是哪一天?',\n",
       " '香港第一次发现 H1N1 流感的日期是哪一天?',\n",
       " '全民健保卡何时完成全面IC卡化?',\n",
       " '行政院卫生署中央健康保险局的首长职称为何?',\n",
       " '行政院卫生署中央健康保险局现更名为?',\n",
       " '我国的所实施的全民健康保险分类上是否与加拿大类似?',\n",
       " '我国的所实施的全民健康保险费率是否与加拿大类似?',\n",
       " '卫福部于哪一年成立?',\n",
       " '健康存折要使用哪两种卡片择一登入?',\n",
       " '健康照护体系有哪三种保险制?',\n",
       " '三大健康照护体系保险制分别以哪三个国家做代表?(前项其代表国家，后项列出请列出保险制)',\n",
       " '我们的国家的健康照护体系保险制是哪一种?',\n",
       " '社会保险制的医疗开支由疾病保险基金所支付，其基金的来源有哪些?',\n",
       " '公医制的医疗开支的经费由何而来?',\n",
       " '自由市场的医疗开支的经费由何而来?',\n",
       " '三大健康照护体系保险制度中，政府涉入程度低的是哪一种？',\n",
       " '三大健康照护体系保险制度中，政府涉入程度高的是哪一种？',\n",
       " '2019年「协助单身及鼓励婚育租金补贴试办方案」何时开始申请？',\n",
       " '「协助单身及鼓励婚育租金补贴试办方案」补助的单身青年是介于几岁到几岁之间?',\n",
       " '「协助单身及鼓励婚育租金补贴试办方案」补助的单身青年最低年龄是几岁?',\n",
       " '「协助单身及鼓励婚育租金补贴试办方案」补助的单身青年最高年龄是几岁?',\n",
       " '「协助单身及鼓励婚育租金补贴试办方案」补助的新婚夫妻指的是结婚几年内的夫妇?',\n",
       " '单身族群最高可以领到多少钱?',\n",
       " '「协助单身及鼓励婚育租金补贴试办方案」为期多久?',\n",
       " '为何全球的罹癌率每年上升？',\n",
       " '台湾十大死因之首是什么？',\n",
       " '老人是否为最容易罹患癌症的族群？',\n",
       " '儿童是否为最容易罹患癌症的族群？',\n",
       " '美国人因癌症而死亡的人口比例是多少百分比？',\n",
       " '根据２０１２年的数据，因癌症而死亡的人口比例是多少百分比？',\n",
       " '根据文本的数据，男性癌症前三名是哪三种？',\n",
       " '根据文本的数据，女性癌症前三名是哪三种？',\n",
       " '根据文章内容是否多吃蔬菜少吃肉就会减低癌症风险?',\n",
       " '根据文章内容是否多吃肉类少吃蔬果就会增加癌症风险?',\n",
       " '根据文章内容建议是吃素或吃肉来降低癌症发生率?',\n",
       " '文章中提到的动物性食品包含哪些?',\n",
       " '根据文章内容是否多吃蔬菜少吃肉会增加得到癌症的风险?',\n",
       " '根据文章内容是否多吃蔬菜少吃肉会减低得到癌症的风险?',\n",
       " '根据文章内容是否少吃蔬菜多吃肉会增加得到癌症的风险?',\n",
       " '根据文章内容是否少吃蔬菜多吃肉会减低得到癌症的风险?',\n",
       " '新闻中车祸地点发生在于哪个城市？',\n",
       " '新闻中车祸地点发生在于哪些路段？',\n",
       " '事故的肇事者姓氏为何？',\n",
       " '事故的肇事者性别为何？',\n",
       " '事故的肇事者今年几岁？',\n",
       " '事故的肇事者开著什么颜色的车子？',\n",
       " '事故的受害者姓氏为何？',\n",
       " '事故的肇事者是否酒驾？',\n",
       " '这起事件发生在何时?',\n",
       " '这起事件是否有人死亡?',\n",
       " '这起事件是否有人受伤?',\n",
       " '这起事件起火的地段在哪?',\n",
       " '前往抢救的单位是哪一个?',\n",
       " '从接获报案到火势熄灭经过了多少时间?',\n",
       " '这起事件的报案者是谁?',\n",
       " '这起事故发生地段位于哪里?',\n",
       " '这起事故有几人受害?',\n",
       " '这起事故的受害者其姓氏分别为何? ',\n",
       " '这起事故的受害者所使用的交通工具为何?',\n",
       " '这起事故的肇事者所使用的交通工具为何?',\n",
       " '这起事故的肇事者其姓氏分别为何? ',\n",
       " '这起事故的肇事者是否酒驾?',\n",
       " '这起事故的两名女生出游的出发地是哪里?',\n",
       " '屠呦呦发现了什么成份可以治疗疟疾？',\n",
       " '若要帮屠呦呦庆生，需哪一天举办?',\n",
       " '屠呦呦的名字典故出于哪一本古籍？',\n",
       " '屠呦呦籍贯哪里?',\n",
       " '屠呦呦幼年住在哪一位亲戚家中?',\n",
       " '屠呦呦的舅舅叫什么名字?',\n",
       " '屠呦呦就读哪一所大学?',\n",
       " '屠呦呦2011年时获得了哪一个奖项?',\n",
       " '王母娘娘最早被称为什么?',\n",
       " '有关王母娘娘最早记载于哪里?',\n",
       " '王母娘娘在哪一本书中被描述为带来祸患的妖怪?',\n",
       " '王母娘娘从哪一本书开始，被描述为女神？',\n",
       " '王母娘娘的生日是哪一天？',\n",
       " '王母娘娘是哪一个宗教的神祗?',\n",
       " '全台湾供奉尺寸最大王母娘娘金身是哪一间庙宇?',\n",
       " '全台湾尺寸最大王母娘娘金身位于哪一个县市?',\n",
       " '全台湾尺寸最大王母娘娘金身有多高?',\n",
       " '波音747是哪一家公司制造的?',\n",
       " '波音747第一次载客是哪一年?',\n",
       " '波音747有几部引擎?',\n",
       " '三级座舱设计的波音747客机的舱等是哪三个?',\n",
       " '三级座舱设计的波音747客机型号最大载客量是多少?',\n",
       " '你知道波音747客机最多可以搭载几人吗？',\n",
       " '哪一个型号的客机载客量最大?(本文中)',\n",
       " '高屏地区国庆烟火预计何时测试施放？',\n",
       " '高屏地区国庆烟火预计在何地测试施放？',\n",
       " '高屏地区国庆烟火正式施放的日期是？',\n",
       " '高屏地区国庆烟火预计要施放多少发以上？',\n",
       " '高屏地区国庆烟火预计要施放时间是多久？',\n",
       " '高屏地区国庆烟火试放日期是哪一天？',\n",
       " '不动产实价登录资讯是由政府哪一个部会公布?',\n",
       " '不动产实价登录率是多少?',\n",
       " '不动产实价揭露率是多少?',\n",
       " '不动产实价登录率与揭露率相差多少?',\n",
       " '不动产实价登录需在买卖完成登记后多少天以内登录?',\n",
       " '不动产实价登录不实，需缴交的罚款金额最高是多少？(单次)',\n",
       " '不动产实价登录不实，是否已犯法？',\n",
       " '克莱斯勒大厦位于哪两条街道的交叉口?',\n",
       " '克莱斯勒大厦的拥有权是否为克莱斯勒汽车公司?',\n",
       " '克莱斯勒大厦在美国纽约市的排名第几名?',\n",
       " '克莱斯勒大厦有多少高?',\n",
       " '华盛顿纪念碑是纪念哪一位美国总统?',\n",
       " '华盛顿纪念碑位于美国哪一个行政区?',\n",
       " '华盛顿纪念碑高度是几公尺?',\n",
       " '华盛顿纪念碑落成于哪一年?',\n",
       " '华盛顿纪念碑从通过建案到落成启用，历时多少年?',\n",
       " '华盛顿纪念碑的英文全名是?',\n",
       " '杰佛逊纪念堂是纪念哪一位美国总统?',\n",
       " '杰佛逊曾任美国第几任总统?',\n",
       " '杰佛逊纪念堂位于美国哪一个行政区?',\n",
       " '杰佛逊纪念堂落成于哪一年?',\n",
       " '杰佛逊纪念堂花了多少年盖好?',\n",
       " '杰佛逊纪念堂的位置邻近哪一条河?',\n",
       " '杰佛逊曾担任过政府机关的哪些职务?',\n",
       " '杰佛逊纪念堂的英文全名是?',\n",
       " '杰佛逊是哪一年出生的?',\n",
       " '杰佛逊于哪一年逝世的?',\n",
       " '杰佛逊享年几岁?',\n",
       " '三峡祖师庙历经几次建造?？',\n",
       " '三峡祖师庙第一次建造是在哪一年？',\n",
       " '三峡祖师庙最早是由哪些姓氏家族共同合建？',\n",
       " '三峡祖师庙中由福建安溪人供奉的神明，守护神为谁？',\n",
       " '现今的三峡祖师庙祖师庙是何时重建？',\n",
       " '第三次重建是由当代哪一位重要的艺术家主持？',\n",
       " '第三次的重建工作花费了多少年？',\n",
       " '祖师庙位于台湾新北市的哪一个行政区?',\n",
       " '相传被埋葬于圣彼得大教堂的十二位宗徒是哪一位?',\n",
       " '圣伯多禄的遗骸于何时被发现?',\n",
       " '罗马有四间特级宗座圣殿，分别是哪四所？',\n",
       " '「教宗宝座」位于哪一座大殿?',\n",
       " '圣彼得大教堂位于哪一个国家境内?',\n",
       " '离教宗官邸最近的圣殿是哪一座?',\n",
       " '老圣伯多禄大殿的建筑用地原本是什么用地?',\n",
       " '老圣伯多禄大殿的建筑外观是什么形状?',\n",
       " '老圣伯多禄大殿是哪一位罗马皇帝在位时建造的?',\n",
       " '老圣伯多禄大殿的建筑风格是哪一种?',\n",
       " '老圣伯多禄大殿可容纳多少人?',\n",
       " '老圣伯多禄大殿6世纪加盖可进入圣殿的入口有几个?',\n",
       " '圣伯多禄大殿于哪一年开始重建?',\n",
       " '圣伯多禄大殿于哪一年完成重建工作?',\n",
       " '圣伯多禄大殿前后花了多少年才完成重建工作?',\n",
       " '圣伯多禄大殿的重建经手了几位设计总监?',\n",
       " '哈里发塔是哪个国家的摩天大楼？\\u3000',\n",
       " '哈里发塔位于哪一个城市？',\n",
       " '世界最高的大楼是哪一个?',\n",
       " '哈里发塔高度有多少公尺?',\n",
       " '哈里发塔总长度为何?',\n",
       " '哈里发塔有多少高?',\n",
       " '哈里发塔总共有多少层?',\n",
       " '若哈里发塔每个楼层都一样高，一个楼层的高度是多少公尺？(四舍五入至小数第一位)',\n",
       " '从开始动工到正式完工，哈里发塔总共用了多少年的时间才盖好？',\n",
       " '世界最快的电梯位于哪一栋大楼内?',\n",
       " '世界最快的电梯速度有多快?',\n",
       " '世界最快的电梯速度每秒钟可上升几公尺?',\n",
       " '世界最快的电梯速度一分钟可上升几公尺?',\n",
       " '美国最高的建筑是哪一座?',\n",
       " '波兰最高的建筑是哪一座?',\n",
       " '阿拉伯联合大公国最高的建筑是哪一座?',\n",
       " '加拿大国家电视塔与美国KVLY-TV天线塔，哪一个高？',\n",
       " '加拿大国家电视塔与美国KVLY-TV天线塔，高度相差多少公尺？',\n",
       " '荆轲是哪一个朝代的人？',\n",
       " '荆轲在哪里唱了一首短歌与送行的朋友们诀别？',\n",
       " '秦舞阳是哪一国人？',\n",
       " '荆轲离别刺秦王发生在哪一个季节？',\n",
       " '前来易水河边送行的人们都穿什么颜色的衣服？',\n",
       " '文中提及，荆轲的好友为谁？',\n",
       " '高渐离用什么乐器击出音调高亢的乐曲，音乐带著生离死别的哀伤？',\n",
       " '荆轲在这场送别中，是否感到非常哀伤绝望，痛哭流涕？',\n",
       " '荆轲与秦舞阳用何种交通工具前往秦国？',\n",
       " '赖东进家中共有几名小孩？',\n",
       " '赖东进家中有几名身障人士？',\n",
       " '赖东进父母是否健在？',\n",
       " '赖东进是否有哥哥姐姐？',\n",
       " '赖东进在几岁以前一家人四处流浪居无定所？',\n",
       " '赖东进家中重度智障的成员有几名？',\n",
       " '赖东进的父亲在夜市里弹著哪种乐器，自弹自唱？',\n",
       " '赖东进是否在小学六年期间品学兼优，得奖不断？',\n",
       " '赖东进国中毕业之后是否立刻投入职场全职工作？',\n",
       " '赖东进在民国88年获得什么奖项？',\n",
       " '赖东进在哪一年获得十大杰出青年的殊荣？',\n",
       " '杨震出生于哪个朝代？',\n",
       " '杨震去山东的哪里就任太守？',\n",
       " '杨震去山东的东莱就职什么职务？',\n",
       " '昌邑县的县令是谁？',\n",
       " '王密为答谢杨震曾经提拔他，半夜里带著什么求见杨震感谢他？',\n",
       " '后人因敬佩杨震廉洁的美德，特地盖了什么来表彰他？',\n",
       " '文中提及讲究时间和效率的是哪一国人？',\n",
       " '美国人最典型的饮食是什么？',\n",
       " '文中提及法国人最爱吃什么？每人平均每年要消费20公斤',\n",
       " '每到深秋时节，韩国人家家户户最重要的大事便是腌制何种食物？',\n",
       " '韩国人都是在什么季节腌制泡菜？',\n",
       " '哪一个国家的民族最讲究礼节？',\n",
       " '泰国人认为身体的哪个部位是最高贵的，外人不能随便触摸？',\n",
       " '文中提及理发师在为顾客理发前还得先说声对不起的是哪一国的习俗？',\n",
       " '张大千是否喜爱动物呢?',\n",
       " '八十三岁的张大千历时一年半挑战一百八十公分高，十公尺又八公分长的绢画是哪一幅？',\n",
       " '八十三岁的张大千在画庐山图的时候是否神清气爽轻松的完成？',\n",
       " '张大千早年远赴何地临摹佛窟壁画？',\n",
       " '张大千将西方何种绘画风格的优点融入国画里，开创出独特的泼墨、泼彩手法？',\n",
       " '庐山图的尺寸高为多少？',\n",
       " '庐山图的尺寸长为多少？',\n",
       " '于伯伯在十几岁的时候和家人在逃难中分散了，只好一个人随国军到了哪里避难？',\n",
       " '于伯伯是否有念大学？',\n",
       " '于伯伯在学期间是否半工半读？',\n",
       " '于伯伯是否有儿女？',\n",
       " '于姐姐暑假申请到了奖学金要去哪里留学？',\n",
       " '于伯伯等了四十几年，终于可以回大陆哪里探亲了？',\n",
       " '纣王出生于哪一个朝代？',\n",
       " '因为纣王暴虐，导致哪一位决心出兵讨伐暴君？',\n",
       " '周武王的军师为谁？',\n",
       " '吕尚的姓氏为何？',\n",
       " '常常规谏商纣王且最后被杀了的叔父是谁？',\n",
       " '常常规谏商纣王且最后被关起来的叔父是谁？',\n",
       " '比干有位当君王的侄子是谁？',\n",
       " '纣王看见农民赤脚涉水，就下令抓来剖开农民的哪个部位加以研究？',\n",
       " '纣王是否对于老百姓在私下讨论他感到非常愉悦？',\n",
       " '史怀哲的职业为何？',\n",
       " '史怀哲是哪一国人？',\n",
       " '史怀哲从学校毕业后，是便到哪个荒凉的国家去创建医院？',\n",
       " '一直到史怀哲去世为止，共有五十年的光阴奉献给非洲，当地人尊称他为何？',\n",
       " '史怀哲小时候和同伴比赛什么而让他注意到，并非每个人都和他一样衣食无缺？',\n",
       " '史怀哲和同学到溪边钓鱼用什么当作鱼饵，导致他再也不跟同学们钓鱼？',\n",
       " '作者的舅父在欧洲旅游，对哪个城市印象最深刻？',\n",
       " '罗马的历史已经超过多少年了？',\n",
       " '文中提及罗马最雄伟的教堂为哪一个？',\n",
       " '义大利的首都为何？',\n",
       " '去罗马旅游的时候在中午是否有店家开门？',\n",
       " '世界上最小的国家为何？',\n",
       " '世界上天主教的中心在哪？',\n",
       " '梵蒂冈这个国家占地虽小，但人口众多，是否正确？',\n",
       " '汉武帝为了攻打哪一个外族，想联合西域的月氏？',\n",
       " '汉武帝为了攻打匈奴，想联合西域的哪一个外族？',\n",
       " '张骞家住在哪一省？',\n",
       " '张骞在哪一年带了部下一百多人上路前往月氏传旨？',\n",
       " '张骞前往西域路上的向导叫什么名字？',\n",
       " '张骞前往月氏的路上是否一路顺遂平安？',\n",
       " '张骞一行人在前往西域的路上被哪一族人俘虏？',\n",
       " '张骞在哪一年带著部属前往乌孙国联合，打算夹击匈奴？',\n",
       " '在张骞通西域的两次路程中，中国的哪些物品传到了西域外族促成中西文化的交流？',\n",
       " '在张骞通西域的两次路程中，西域的音乐和什么传到了中土，促成中西文化的交流？',\n",
       " '毕业旅行的地点投票到最后较多人投的是淡水和哪里？',\n",
       " '主张到淡水并介绍环境的同学是哪一位？',\n",
       " '主张到冬山河并介绍环境的同学是哪一位？',\n",
       " '余智慧介绍去淡水可以远眺哪一座山？',\n",
       " '余智慧介绍去淡水可以探访哪一座三百年历史的古迹？',\n",
       " '汪成文提及哪一年冬山河完成了清水大闸门，防止海水倒灌？',\n",
       " '在哪一年，冬山河开放了亲水公园，每到假日都有不少游客慕名而来？',\n",
       " '在冬山河亲水公园里是否可以划船？',\n",
       " '汪成文介绍倘若毕业旅行选在端午节去冬山河，可以看到什么竞赛？',\n",
       " '纵贯台湾的山脉是什么山？',\n",
       " '台湾的形状是否为一个南北短、东西宽的的宝岛？',\n",
       " '民国哪一年，在行政院的策划下，举行了东西横贯公路的开工典礼？',\n",
       " '参加修筑中部横贯公路的人员，是否都为现役的国军官兵？',\n",
       " '中部横贯公路修建完成，对台湾哪一区的交通带来便利？',\n",
       " '中部横贯公路的主线，是由台中的哪一个镇入山？',\n",
       " '中部横贯公路的主线经关原、天祥到太鲁阁，最后和哪一个公路衔接？',\n",
       " '中部横贯公路的全长为多少公里？',\n",
       " '中部横贯公路全长348公里，是否沿途各地荒凉贫瘠？',\n",
       " '中部横贯公路沿途各地还有很多矿产，其中是否有云母石的矿地？',\n",
       " '中部横贯公路沿线，代表我国民族精神的几项建筑，如文天祥像、岳王亭、孟母亭、慈母亭和慈母桥，在民国哪一年全部完工？',\n",
       " '是否可以在中部横贯公路沿线看到文天祥像？',\n",
       " '文中提及，表现中国书法的特点是用什么笔？',\n",
       " '用于适应现代光面的纸张，是用什么笔？',\n",
       " '文中提及，可以随时擦掉修改的是什么笔？',\n",
       " '文中提及，方便携带又书写流利的是什么笔？',\n",
       " '毛笔、钢笔、原子笔、铅笔，这四种当中谁的历史最悠久？',\n",
       " '钢笔的笔尖是用什么制成？',\n",
       " '铅笔之所以可以在写错字时擦去修改是因为笔的另一端有加什么？',\n",
       " '原子笔的笔尖是用什么代替，让字体写起来滑润而流利？',\n",
       " '王昌龄是哪一个朝代的诗人？',\n",
       " '王昌龄、高适、王之涣三个人的职业是什么？',\n",
       " '王昌龄、高适、王之涣三位是唐朝诗人的哪一派别？',\n",
       " '在旗亭唱曲宴乐的三位女子先唱了三位诗人中谁的作品？',\n",
       " '在旗亭唱曲宴乐的三位女子中是否有人唱王之涣的作品？',\n",
       " '在旗亭唱曲宴乐中最美的女子唱的是王之涣的哪个作品？',\n",
       " '梁州词是近体师的哪一种格式？',\n",
       " '在凉州词中，描述著驻守在边城将士思念家园的相情，羌笛何必再吹起哪一首引人离绪的曲子，让人更增添无限的悲愁？',\n",
       " '曹操出生于哪个朝代？',\n",
       " '刘备的军师为谁？',\n",
       " '周瑜是哪一国的人？',\n",
       " '在广阔的江面交兵，孔明认为该先用何种方式攻击？',\n",
       " '周瑜常听鲁肃称赞孔明足智多谋，是否早已景仰多年，得知要见面了内心非常喜悦？',\n",
       " '周瑜要求诸葛先生制造多少枝箭备战？',\n",
       " '孔明答应周瑜几天内可制造10万支箭备战？',\n",
       " '孔明要求鲁肃提供多少艘战船与多少名军士？',\n",
       " '诸葛先生是否在第一天就出动预备好的20艘战船？',\n",
       " '曹操听说敌人深夜进攻，是否立即下令反击开战？',\n",
       " '美国的国花为山楂花又称为什么花？',\n",
       " '美国的国花为何？',\n",
       " '当年美国的祖先到美洲开荒所乘的船，叫什么名字？',\n",
       " '法国的国花为何？',\n",
       " '法国的国花象征吉利是因为古代曾有勇士，每次都拿著几朵百合花的盾牌上阵而胜利？',\n",
       " '日本的国花为何？',\n",
       " '土耳其的国花为何？',\n",
       " '希腊的国花为何？',\n",
       " '埃及的国花为何？',\n",
       " '英国的国花为何？',\n",
       " '中华民国清朝以前的国花为何？',\n",
       " '中华民国在奠都南京之后，国花改为哪一种花？',\n",
       " '梅花是在民国几年成为中华民国的国花？',\n",
       " '梅花花朵有几瓣？',\n",
       " '是谁治平了洪水大患受到人民的爱戴，建立了夏朝？',\n",
       " '夏朝的哪一位皇帝喜欢玩乐，长期外出打猎，并请后羿做宰相？',\n",
       " '夏朝帝相时的宰相是谁？',\n",
       " '后羿得到天下后依然天天去射箭打猎，把国家大事交给了他的宠臣为谁？',\n",
       " '寒浞杀了夏朝的哪两位君王？',\n",
       " '帝相的皇后是哪一国国王的女儿？',\n",
       " '帝相是否有子女？',\n",
       " '少康的父亲为谁？',\n",
       " '帝相的儿子叫什么名字？',\n",
       " '少康长大后被寒浞追赶，逃亡到哪个国家？',\n",
       " '有虞国的国王把那一块地送给了少康？',\n",
       " '少康是否有成家？',\n",
       " '少康辛苦经营了多少年，终能一举把寒浞灭掉，恢复了夏朝？',\n",
       " '「天无三日晴，地无三里平，人无三两银。」是哪一个地区的谚语？',\n",
       " '文中提及，贵州是否是个降雨量少且生活穷困的地方？',\n",
       " '黄果树大瀑布在中国的哪一省？',\n",
       " '文中提及，在西北大漠，寸草不生的是哪个地方？',\n",
       " '文中提及，盛产葡萄的是在西北大漠的哪里？',\n",
       " '西北大漠的气候是否整天皆气候宜人，温差甚小？',\n",
       " '文中提及，做人不能忘本，要能心存感激，饮水思源的谚语是哪一句？',\n",
       " '文中提及的一句古时候谚语说：「只有上不去的天，没有过不去的山。」代表什么意思，请用四字说明？',\n",
       " '文中提及从台北坐飞机到澎湖需费时多久？',\n",
       " '澎湖是否为一个孤零零的海岛？',\n",
       " '小真的外婆是否住在澎湖？',\n",
       " '文中提及，这个澎湖旅游团共几人？',\n",
       " '澎湖旅行团的行程是安排了几天？',\n",
       " '澎湖县的县花为何？',\n",
       " '文中提及有哪三道菜是小真第一次吃到？',\n",
       " '澎湖旅行团总共安排了几个景点？',\n",
       " '澎湖旅行团安排了哪五个景点？',\n",
       " '在亲属关系中小真是作者的姪女还是外甥女?',\n",
       " '小真和作者在亲属关系中是直系血亲还是旁系血亲？',\n",
       " '文中描述，形状像倒扣的桶盘，岛的三面有柱状的玄武岩环抱，是哪一个大自然景点？',\n",
       " '澎湖跨海大桥的桥身是什么颜色？',\n",
       " '澎湖旅行团去的景点中，有三百多年历史的古老庙宇为何？',\n",
       " '珍‧古德出生在哪个国家？',\n",
       " '珍‧古德是否喜欢动物？',\n",
       " '珍‧古德在二十六岁的时候到哪里，进行对黑猩猩的长期观察？',\n",
       " '珍‧古德在二十六岁的时候到了非洲，进行对什么动物的长期观察？',\n",
       " '珍‧古德一到非洲丛林即得了什么病，饱受折磨？',\n",
       " '珍‧古德每天几点起床上山工作直到天黑才回营地？',\n",
       " '珍‧古德发现猩猩用什么来钓白蚁，完成后即能方便的放进自己嘴巴享受白蚁大餐？',\n",
       " '人类学家一直以为只有人类才会制造工具的观念是否正确？',\n",
       " '马友友在几岁开始练习巴哈的曲子？',\n",
       " '马友友在四岁就开始练习哪一位音乐家的曲子？',\n",
       " '马友友说拉琴时，一定要觉得乐器好像是你身体的一部分，声音是乐器的哪一部份？',\n",
       " '马友友说拉琴时，一定要觉得乐器好像是你身体的一部分，大提琴是身体的哪个部位？',\n",
       " '文中描述到具有草根性和生命力的台湾乡间歌谣是哪一首？',\n",
       " '名曲鳟鱼的作曲者是谁？',\n",
       " '文中描述到描写西部移民的美国民谣是哪一首？',\n",
       " '马友友最擅长且风靡世界的乐器是什么？',\n",
       " '编钟是用什么铸造的乐器？',\n",
       " '编钟是用青铜器制造的什么？',\n",
       " '我们知道的六十四口大编钟是在什么时期做出来的？',\n",
       " '六十四口大编钟是在战国时期，哪一位君主在为时期做出来的？',\n",
       " '大编钟的表面刻画了细致的花纹，还标记了什么？',\n",
       " '大编钟的正面和侧面是否可以敲击出两个不同的音高？',\n",
       " '金字塔是用来专为埃及国王设计的何种建筑物?',\n",
       " '国王一旦去世，埃及人会先把他们的遗体做防腐的处理，再用泡过香料的布条层层包裹好，制成什么？',\n",
       " '文中提及，在哪一条河的沿岸有80多座大大小小的金字塔遗址？',\n",
       " '尊贵的国王一旦去世，埃及人会先把他们的遗体做防腐的处理，再用泡过香料的布条层层包裹好，制成什么?',\n",
       " '为了防止盗墓者侵入破坏金字塔内部墓室，放了什么东西堵住通道，将整个金字塔封闭起来？',\n",
       " '文中提及由哪种雕像作为金字塔的守护神？',\n",
       " '文中提及哪一座的金字塔，面积约有五个足球场大？',\n",
       " '古夫王金字塔，总共大约使用了多少块大石头？',\n",
       " '古夫王金字塔，塔高多少公尺？',\n",
       " '古夫王金字塔的高度相当于几层楼高的摩天大楼？',\n",
       " '古夫王金字塔费时多少年才被完成？',\n",
       " '文中提及，负责该月份快乐儿童月刊的小记者有哪三位？',\n",
       " '文中提及，郑教授专门研究那一块学术领域？',\n",
       " '丁新、张玉珊、王小美负责的月刊主题为何？',\n",
       " '南极洲是否有著广大且薄的冰层？',\n",
       " '郑教授描述到地球上有百分之九十的冰都集中在哪里？',\n",
       " '南极洲是否有动物生存？',\n",
       " '在南极洲有一些科学家，正在共同研究南极洲的地质，想知道在冰层下是否蕴藏著的什么资源？',\n",
       " '南极洲上空破一个洞的是大气层中哪个部分？',\n",
       " '南极洲每年的11月到2月是什么季节？',\n",
       " '南极洲每年的九月底开始，会进入什么期，将近半年时光太阳不下山？',\n",
       " '除了南极洲会有半年永昼期，而哪个地区又会进入永夜期？',\n",
       " '『早发白帝城』是谁写的游记？',\n",
       " '白帝城在中国哪一省？',\n",
       " '文中提及，三峡是由哪三个峡谷组成？',\n",
       " '瞿塘峡、巫峡、西陵峡这几座高山中间夹著哪条大河？',\n",
       " '『早发白帝城』描写的是李白从四川白帝城上船，准备到湖北的哪里？',\n",
       " '文中提及，古代相传，江陵距离白帝城有多远？',\n",
       " '江陵在中国哪一省？',\n",
       " '李白从四川白帝城到湖北江陵所搭乘的船是否属于笨重庞大的船？',\n",
       " '丘逢甲出生于哪个朝代？',\n",
       " '丘逢甲是客家人还是闽南人？',\n",
       " '丘逢甲被称做神童是因为几岁会做诗，几岁就考上秀才？',\n",
       " '丘逢甲从彰化一路走到哪里考秀才？',\n",
       " '1894年清朝政府战败，把台湾割让给哪个国家？',\n",
       " '丘逢甲带头上书给朝廷表示反对将台湾割让给日本，并且和地方仕绅组织了什么，誓死保卫家园？',\n",
       " '文中提及，丘逢甲离台时，为斥责当政的宰相权力太大，任意割让国土，感叹身在台湾的小臣无能为力，无法挽回被割让的命运而写下了什么样的诗句？。',\n",
       " '丘逢甲出生于台湾哪里？',\n",
       " '此篇内容描述的是去台湾哪里毕业旅行二日游？',\n",
       " '文中提及，哪一条溪沿著花东纵谷向南奔流，而当年的卑南族人选择了水草风美的冲积平原定居下来？',\n",
       " '考古学家从遗址发掘中发现了用来垦地的是什么工具？',\n",
       " '考古学家从遗址发掘中发现了用来收割农作物的是什么工具？',\n",
       " '考古学家从遗址发掘中发现了人类会用什么工具来捕捞溪中的鱼蟹？',\n",
       " '在卑南公园里，耸立在遗址上，残留的半个圆孔，曾经是盖房子的基架的石柱称为什么？',\n",
       " '卑南族人的石板棺出土时，观礼死者的脚大半都朝向哪座山？',\n",
       " '这封信是文章写给谁的？',\n",
       " '卑南文化公园是现地挖掘、现地保存的「遗址公园」，经过考古学家的调查和发掘，才能拼凑出当年哪一族人的生活图像？',\n",
       " '把许多电脑集合起来,让它们彼此互相连接，结合成一张绵密的网，那么每一台电脑就可以拥有所有电脑储存的大量资料了。这样的设计，叫做什么？',\n",
       " '美国在哪一年因国防上的需要，全力进行网路实验获得成功？',\n",
       " '美国在哪一年开发了图像化的「全球网际路」，使任何一台电脑都可以和世界上任何地区的任何网址相连接，拓宽了网路的功能？',\n",
       " '台湾是在哪一年和美国的大学进行网际网路相连接？',\n",
       " '在网际网路蓬勃发展的过程中,电脑又出现了一项什么新功能，有了它我们可以利用网路，跟世界上任何地区的人通信,只要你知道那个人的网址？',\n",
       " '我们是否可以透过网路申请户口名簿？',\n",
       " '我们是否可以透过网路向银行领钱？',\n",
       " '明湖舅舅的好朋友赖教授，是研究什么的专家？',\n",
       " '赖教授认为二十一世纪的时候，汽车都靠什么行驶？',\n",
       " '文中提及，赖教授认为二十一世纪的时候，哪两种动能取代了大部分的石油燃料，减少了空气的污染？',\n",
       " '赖教授是否认为在二十一世纪的时候，人类可以搬到外太空的星球上去住？',\n",
       " '赖教授认为在二十一世纪医学界对人类生命基因的研究，让许多遗传性急病可以采用什么疗法加以根除?',\n",
       " '赖教授认为在二十一世纪乏味的家事工作可以交给谁？',\n",
       " '这一篇文章在介绍什么机器？',\n",
       " '自动贩卖机是否需要投入硬币？',\n",
       " '哪一只动物从自动贩卖机里买了绿茶？',\n",
       " '文中描述著哪一只动物是最早去用手试按贩卖机但没什么反应的？',\n",
       " '动物小学今天带班出来户外教学的是哪一位老师？',\n",
       " '山羊老师教大家哪两种类型的垃圾需要压扁或踩扁后回收丢到资源回收筒里？',\n",
       " '文中提及的自动贩卖机卖的是什么？',\n",
       " '晏子出生于哪一个朝代？',\n",
       " '晏子是春秋时代的哪一国人？',\n",
       " '文中提及，齐王派晏子出使到哪一个国家去？',\n",
       " '晏子来到楚国的时候，楚王是否下令开城门以礼相待迎接？',\n",
       " '晏子来到楚国的时候，楚王开哪个门迎接？',\n",
       " '晏子到楚国的第二天，楚王在晏子面前故意问士兵押著的犯人，是犯了什么罪？',\n",
       " '橘树种在淮水以南，结出来的是又香又甜的橘子；可是移种到淮水以北，却只能结出又小又苦的枳，是受了哪两种因素影响？',\n",
       " '文中提及，学校百周年校庆是在哪一天举行？',\n",
       " '公告内容里提及校树选拔在哪一天投票？',\n",
       " '公告内容中提及在十二月二日开放全校学生参与而举办的活动是什么？',\n",
       " '除校树选拔项目外，参加其他两项活动的人员需在哪一天以前，向各承办单位办理报名？',\n",
       " '从文中的通告可得知，『画我美丽校园』活动是否有如期举行？',\n",
       " '从文中公告得知，『校树选拔』之老榕树的得票树有几票？',\n",
       " '从文中公告得知，『校树选拔』的总票树有几票？',\n",
       " '从文中公告得知，『校树选拔』之最后赢家为谁？',\n",
       " '公告与通知，何者比较正式？',\n",
       " '苏东坡出生于哪个朝代？',\n",
       " '苏东坡除了在文学方面上很出色外，在哪一方面也有所造诣？',\n",
       " '苏东坡的家乡在哪？',\n",
       " '苏东坡是在几岁的时候挖到奇形怪状的石头，而父亲说是很好的砚石？',\n",
       " '苏东坡在十二岁时发现的上好砚石，其大体颜色为何？纹路颜色又为何？',\n",
       " '王羲之是哪个朝代的人？',\n",
       " '王羲之天天练毛笔字的时候，就在池子里洗笔、洗砚台，久而久之池子里的水都被染黑，人们称之为？',\n",
       " '怀素是出生于哪个朝代的人？',\n",
       " '唐朝的怀素最擅长于书法的何种字体？',\n",
       " '苏东坡将他捡到的上好砚石放书桌上，取名为何？',\n",
       " '谜语是中国的传统文化，有字谜、物谜，还有猜什么的？',\n",
       " '第一个抢著回答谜语的同学叫什么名字？',\n",
       " '『池里不见水，地上没有泥』，猜一个字，答案为何？',\n",
       " '提供『七十二小时』谜语的同学是谁？',\n",
       " '答对『也』字谜语的同学叫什么名字？',\n",
       " '『七十二小时』，猜一个字，答案为何？',\n",
       " '猜对『根在水中央，身材细又长，皮肤白又嫩，好吃又营养。』答案是豆芽的是哪一位同学？',\n",
       " '台湾地区排名第一的死亡原因是什么?',\n",
       " '台湾地区排名前三名的死亡原因是哪些?',\n",
       " '107年的统计资料显示国人平均寿命是几岁?',\n",
       " '哪一种疾病对国人平均寿命影响最大?',\n",
       " '从民国几年开始癌症就位居国人死因的榜首?',\n",
       " '从民国几年开始心脏疾病就位居国人死因的第二位?',\n",
       " '从民国几年开始肺炎就位居国人死因的第三位?',\n",
       " '这则新闻中的主角叫什么名字?(姓名)',\n",
       " '青河大学时代在哪一所学校念书? ',\n",
       " '青河大学主修科系为何? ',\n",
       " '青河的硕士学位在哪一个国家念的?',\n",
       " '青河攻读硕士时，是读哪一所学校?',\n",
       " '青河目前在哪一所学校念博士?',\n",
       " '青河来到台湾已经多少年了?',\n",
       " '青河结婚已经几年了?',\n",
       " '青河目前的职业为何?',\n",
       " '台湾地区人口平均寿命从民国97年到107年，增加了几岁？',\n",
       " '台湾地区的男性平均寿命比女性少几岁?',\n",
       " '台湾地区的女性平均寿命比男性多几岁?',\n",
       " '台湾地区的平均寿命，是男性或女性比较长寿?',\n",
       " '全球女性最长寿的国家是哪一个?',\n",
       " '男性平均寿命最高的国家是哪一个?',\n",
       " '女性平均寿命最高的国家是哪一个?',\n",
       " '新加坡的平均寿命，是男性或女性比较长寿?',\n",
       " '台南市市民的平均寿命是否比桃园市高?',\n",
       " '消防署提醒国人到户外游憩时要注意自身安全，特别是在哪两大地理环境要注意?',\n",
       " '根据消防署资料显示发生登山意外多发生在几岁到几岁的民众?',\n",
       " '登山事故发生率最高的地点是哪里?',\n",
       " '戏水事故发生率最高的地点是哪里?',\n",
       " '戏水事故发生率最高的时间是哪个季节?',\n",
       " '戏水事故发生率最高的时段是否在晚上?',\n",
       " '戏水事故发生率最高的时段是否在白天?',\n",
       " '在国家公园发生登山的事故是否多于中级山域?',\n",
       " '在海边发生戏水意外的机率是否多于河边?',\n",
       " '流行感冒盛行的季节是哪两季?',\n",
       " '接触传染要如何预防?',\n",
       " '飞沫传染的安全距离是多少?',\n",
       " '今年流感病毒型别为何?',\n",
       " '如果家里有就读幼稚园的小朋友，可以什么时候开始接种流感疫苗？',\n",
       " '如果家里有就读２岁的小朋友，可以什么时候开始接种流感疫苗？',\n",
       " '如果家里有８０岁老人家，可以什么时候开始接种流感疫苗？',\n",
       " '「目睭花花，匏仔看做菜瓜」是指身体哪个器官可能出了问题?',\n",
       " '眼药水广告常出现可保养眼睛的讯息是否正确?',\n",
       " '当眼睛不舒服的时候，是否可以多点几滴眼药水？',\n",
       " '当需同时使用眼药水与眼药膏时，是否要先使用眼药膏？',\n",
       " '眼药水是否需放置于阳光充足的地方?',\n",
       " '如果我使用了日本买的眼药水却发生过敏红肿，是否可以申请药害救济?',\n",
       " '如果我使用了台湾健保医师开给我的眼药水却发生过敏红肿，是否可以申请药害救济?',\n",
       " '感染肠病毒会出现哪些症状?',\n",
       " '目前在台湾出现的肠病毒有哪几型?',\n",
       " '全台在2019年九月的第二周已经有多少人因肠病毒而挂急诊?',\n",
       " '肠病毒的传染途径传染途径是接触感染还是空气传播或是两者皆有?',\n",
       " '在肠病毒型别中，最多病例是哪一型？',\n",
       " '小明感染肠病毒后痊瘉一周后是否就不会再传染给别人了?',\n",
       " '兹卡病毒是否会经由体液传染?',\n",
       " '这起诈骗案件发生于台北市哪一个行政区？',\n",
       " '这起诈骗案件发生的日期是哪一天？',\n",
       " '这起诈骗案件的受害人是男性还是女性？',\n",
       " '这起诈骗案件的受害人姓氏为何？',\n",
       " '反诈骗专线电话是几号？']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['QUESTIONS'].apply(lambda x: x[0]['QTEXT_CN']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2]).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0812 07:09:56.867145 140680368949056 tokenization_utils_base.py:1254] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /root/.cache/torch/transformers/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(data):\n",
    "    all_instances = []\n",
    "    questions = data['QUESTIONS'].apply(lambda x: [x[0]['QTEXT_CN'], len(x[0]['SHINT'][1])]).tolist()\n",
    "    sentences = [sentence['text'] for sentence_dict in data['SENTS'] for sentence in sentence_dict]\n",
    "    lengths = np.array(questions)[:, 1].astype(int).tolist()\n",
    "    indices = data['QUESTIONS'].apply(lambda x: x[0]['SHINT_']).tolist()\n",
    "    labels = [[0] * length for length in lengths]\n",
    "    all_labels = []\n",
    "    # Inpute index into labels\n",
    "    for i in range(len(labels)):\n",
    "        np_label = np.array(labels[i])\n",
    "        np_index = np.array(indices[i])\n",
    "        np_label[np_index] = 1\n",
    "        label = np_label.tolist()\n",
    "        labels[i] = label\n",
    "        all_labels = all_labels + label\n",
    "    counter = 0\n",
    "    for question in questions:\n",
    "        question_text = question[0]\n",
    "        for j in range(counter, counter + question[1]):\n",
    "            all_instances.append([question_text, sentences[j]])\n",
    "    \n",
    "    all_tokenized = []\n",
    "    for i in range(len(all_instances)):\n",
    "        tokenized = tokenizer([all_instances[i]], padding='max_length', truncation=True, max_length=512, return_tensors = 'pt')\n",
    "        tokenized['input_ids'] = tokenized['input_ids'].to(device)\n",
    "        tokenized['input_ids'] = tokenized['input_ids'].squeeze(0)\n",
    "        tokenized['token_type_ids'] = tokenized['token_type_ids'].to(device)\n",
    "        tokenized['token_type_ids'] = tokenized['token_type_ids'].squeeze(0)\n",
    "        tokenized['attention_mask'] = tokenized['attention_mask'].to(device)\n",
    "        tokenized['attention_mask'] = tokenized['attention_mask'].squeeze(0)\n",
    "        tokenized['label'] = torch.tensor(all_labels[i])\n",
    "        all_tokenized.append(tokenized)\n",
    "    return all_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dev_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-3dfcc814f556>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_all_instances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_preprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdev_all_instances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_preprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_all_instances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_preprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dev_data' is not defined"
     ]
    }
   ],
   "source": [
    "train_all_instances = data_preprocessing(training_data)\n",
    "dev_all_instances = data_preprocessing(dev_data)\n",
    "test_all_instances = data_preprocessing(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0812 02:15:41.785210 139797494843200 tokenization_utils_base.py:1254] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /root/.cache/torch/transformers/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datapreprocessing(data, return_df=False):\n",
    "    \n",
    "    # Save all the questions, potential supporting evidence and indices in three lists\n",
    "    textQ_to_be_tokenized = []\n",
    "    textA_to_be_tokenized = []\n",
    "    sp_index = []\n",
    "    max_counter = 0\n",
    "    for dictionary in data['QUESTIONS']:\n",
    "        for element in dictionary:\n",
    "            textQ_to_be_tokenized.append(element['QTEXT_CN'])\n",
    "            sp_index.append(element['SHINT_'])\n",
    "    for dictionary in data['SENTS']:\n",
    "        current_text_sentence = []\n",
    "        for element in dictionary:\n",
    "            current_text_sentence.append(element['text'])\n",
    "        textA_to_be_tokenized.append(current_text_sentence)\n",
    "    \n",
    "    QandA_label = pd.DataFrame({'Question': textQ_to_be_tokenized,\n",
    "                                'Sentence_List': textA_to_be_tokenized,\n",
    "                                'SE_Index': sp_index,\n",
    "                                'Label': sp_index})\n",
    "\n",
    "    QandA_label['Length'] = QandA_label['Sentence_List'].apply(lambda x: len(x))\n",
    "    QandA_label['SE_Index'] = QandA_label['SE_Index'].apply(lambda x: [0])\n",
    "    QandA_label['SE_Index'] = QandA_label['SE_Index'] * QandA_label['Length']\n",
    "    QandA_label['SE_Index'] = list(zip(QandA_label['SE_Index'], QandA_label['Label']))\n",
    "\n",
    "    # Extract label index\n",
    "    for row in QandA_label['SE_Index']:\n",
    "        for index in row[1]:\n",
    "            row[0][index] = 1\n",
    "        \n",
    "    indexed = [i[0] for i in list(QandA_label['SE_Index'])]\n",
    "    QandA_label['Label'] = indexed\n",
    "\n",
    "    if return_df:\n",
    "        return QandA_label\n",
    "    \n",
    "    Q_and_Sentence_all_Comb = pd.DataFrame({'Question':np.repeat(QandA_label['Question'].values, QandA_label['Sentence_List'].str.len()),\n",
    "                        'Sentence':np.concatenate(QandA_label['Sentence_List'].values)})\n",
    "    Q_and_Sentence_all_Comb['Label'] = QandA_label['Label'].sum()\n",
    "    \n",
    "            \n",
    "    # Put all question and sentence combination into a list \n",
    "    All_instances = []\n",
    "    \n",
    "        \n",
    "    for i in range(len(QandA_label)):\n",
    "        \n",
    "        for sentence in QandA_label['Sentence_List'][i]:\n",
    "            question_token = tokenizer.tokenize(QandA_label['Question'][i])\n",
    "            sentence_token = tokenizer.tokenize(sentence)\n",
    "            instance = ['[CLS]'] + question_token + ['[SEP]'] + sentence_token + ['[SEP]'] \n",
    "\n",
    "            \n",
    "            if len(instance) > 512:\n",
    "                instance = instance[:511] + ['[SEP]']\n",
    "                #max_counter += 1\n",
    "\n",
    "            #instance = instance[:100]\n",
    "            All_instances.append(instance)\n",
    "            \n",
    "    # Convert ids to segment_ids\n",
    "    segment_ids = []\n",
    "    for token in All_instances:\n",
    "        length_of_zeros = token.index('[SEP]') - token.index('[CLS]') + 1\n",
    "        length_of_ones = len(token) - length_of_zeros\n",
    "        zeros_and_ones = [0] * length_of_zeros + [1] * length_of_ones\n",
    "        segment_ids.append(zeros_and_ones)\n",
    "        \n",
    "    ids = []\n",
    "    for token in All_instances:\n",
    "        ids.append(tokenizer.convert_tokens_to_ids(token))\n",
    "        \n",
    "    mask_ids = []\n",
    "    for token in All_instances:\n",
    "        mask_ids.append([1] * len(token))\n",
    "        \n",
    "    labels = list(Q_and_Sentence_all_Comb['Label'])\n",
    "    labels = [[i] for i in labels]\n",
    "    return All_instances, ids, segment_ids, mask_ids, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_sentence(data, number_of_sentence):\n",
    "    \n",
    "    QandA_label = datapreprocessing(training_data, True)\n",
    "    \n",
    "    Q_and_Sentence_all_Comb = pd.DataFrame({'Question':np.repeat(QandA_label['Question'].values, QandA_label['Sentence_List'].str.len()),\n",
    "                        'Sentence':np.concatenate(QandA_label['Sentence_List'].values)})\n",
    "    Q_and_Sentence_all_Comb['Label'] = QandA_label['Label'].sum()\n",
    "    \n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "\n",
    "    len_array = np.cumsum(np.array(data['SENTS'].apply(lambda x: len(x))))\n",
    "\n",
    "    # Put all question and sentence combination into a list \n",
    "    All_instances = []\n",
    "    padded_zeros = [0] * 250\n",
    "    \n",
    "    for i in range(len(QandA_label)):\n",
    "        \n",
    "        for j in range(len(QandA_label['Sentence_List'][i])):\n",
    "            \n",
    "            question_token = tokenizer.tokenize(QandA_label['Question'][i])\n",
    "            q_instance = ['[CLS]'] + question_token + ['[SEP]']\n",
    "            if len(q_instance) > 250:\n",
    "                q_instance = q_instance[:249] + ['[SEP]']\n",
    "\n",
    "            sentences = []\n",
    "            \n",
    "            for k in range(j - number_of_sentence//2, j + number_of_sentence//2 + 1):\n",
    "                if k < 0 or k >= len(QandA_label['Sentence_List'][i]):\n",
    "                    sentences.append(padded_zeros)\n",
    "                else:\n",
    "                    sentence_token = tokenizer.tokenize(QandA_label['Sentence_List'][i][k])\n",
    "                    s_instance = ['[CLS]'] + sentence_token + ['[SEP]']\n",
    "                    if len(s_instance) > 250:\n",
    "                        s_instance = s_instance[:249] + ['[SEP]']\n",
    "                    sentences.append(s_instance)\n",
    "            \n",
    "                \n",
    "            # Append the target sentence\n",
    "            #question_token = tokenizer.tokenize(QandA_label['Question'][i])\n",
    "            #sentence_token = tokenizer.tokenize(QandA_label['Sentence_List'][i][j])\n",
    "            #q_instance = ['[CLS]'] + question_token + ['[SEP]']\n",
    "            #s_instance = ['[CLS]'] + sentence_token + ['[SEP]'] \n",
    "            \n",
    "            #if len(s_instance) > 250:\n",
    "                #s_instance = s_instance[:249] + ['[SEP]']\n",
    "            #if len(q_instance) > 250:\n",
    "                #question = question[:249] + ['[SEP]']\n",
    "\n",
    "            All_instances.append((q_instance, sentences))\n",
    "\n",
    "    ids = []\n",
    "    mask_ids = []\n",
    "    sentence_masks = []\n",
    "    \n",
    "    for token in All_instances:\n",
    "        \n",
    "        q_tokenized = tokenizer.convert_tokens_to_ids(token[0])\n",
    "        q_mask = [1] * 250\n",
    "        \n",
    "        if len(q_tokenized) < 250:\n",
    "            q_tokenized = q_tokenized + (250 - len(q_tokenized)) * [0]\n",
    "            q_mask = q_tokenized.index(0) * [1] + (250 - q_tokenized.index(0)) * [0]\n",
    "            \n",
    "        s_tokens = []\n",
    "        s_masks = []\n",
    "        sen_mask = []\n",
    "        for sentence in token[1]:\n",
    "            \n",
    "            if sentence == padded_zeros:\n",
    "                s_tokens.append(padded_zeros)\n",
    "                s_masks.append(padded_zeros)\n",
    "                sen_mask.append([0])\n",
    "                \n",
    "            else:\n",
    "                s_tokenized = tokenizer.convert_tokens_to_ids(sentence)\n",
    "                s_mask = [1] * 250\n",
    "        \n",
    "                if len(s_tokenized) < 250:\n",
    "                    s_tokenized = s_tokenized + (250 - len(s_tokenized)) * [0]\n",
    "                    s_mask = s_tokenized.index(0) * [1] + (250 - s_tokenized.index(0)) * [0]\n",
    "            \n",
    "                s_tokens.append(s_tokenized)\n",
    "                s_masks.append(s_mask)\n",
    "                sen_mask.append([1])\n",
    "                \n",
    "        ids.append((q_tokenized, s_tokens))\n",
    "        mask_ids.append((q_mask, s_masks))\n",
    "        sentence_masks.append(sen_mask)\n",
    "\n",
    "    labels = list(Q_and_Sentence_all_Comb['Label'])\n",
    "    labels = [[i] for i in labels]\n",
    "    return All_instances, ids, mask_ids, sentence_masks, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_sentence_preprocessing(data, dataset, number_of_sentences):\n",
    "    \n",
    "    len_array = np.cumsum(np.array(data['SENTS'].apply(lambda x: len(x))))\n",
    "    dictionary_lists = []\n",
    "    batches = []\n",
    "    \n",
    "    unit_counter = 0\n",
    "    \n",
    "    for count, instance in enumerate(dataset, 1):\n",
    "        \n",
    "        dictionary_lists.append(instance)\n",
    "        unit_counter += 1\n",
    "        \n",
    "        if (unit_counter % number_of_sentences == 0) or (count in len_array):\n",
    "            \n",
    "            padded_ids = pad_sequence([torch.tensor(instance['ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_ids = padded_ids.to(device)\n",
    "\n",
    "            padded_segment_ids = pad_sequence([torch.tensor(instance['segment_ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_segment_ids = padded_segment_ids.to(device)\n",
    "\n",
    "            padded_mask_ids = pad_sequence([torch.tensor(instance['mask_ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_mask_ids = padded_mask_ids.to(device)\n",
    "\n",
    "            labels = torch.stack([torch.tensor(instance['labels']) for instance in dictionary_lists])\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            current_dev_batch = {'ids': padded_ids, 'mask_ids': padded_mask_ids, 'segment_ids': padded_segment_ids, 'labels': labels}\n",
    "\n",
    "            batches.append(current_dev_batch)\n",
    "            dictionary_lists = []\n",
    "            unit_counter = 0\n",
    "    \n",
    "    return batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_window_sentence_preprocessing(data, dataset, number_of_sentences):\n",
    "    \n",
    "    len_array = np.cumsum(np.array(data['SENTS'].apply(lambda x: len(x))))\n",
    "    dictionary_lists = []\n",
    "    batches = []\n",
    "    \n",
    "    unit_counter = 0\n",
    "    \n",
    "    for i in range(1, len(dataset) + 1):\n",
    "        \n",
    "        # Need to pad zeros\n",
    "        dictionary_lists.append(dataset[i-1])\n",
    "        dictionary_lists\n",
    "        unit_counter += 1\n",
    "        \n",
    "        if (unit_counter % number_of_sentences == 0) or (i in len_array):\n",
    "            \n",
    "            padded_ids = pad_sequence([torch.tensor(instance['ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_ids = padded_ids.to(device)\n",
    "\n",
    "            padded_segment_ids = pad_sequence([torch.tensor(instance['segment_ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_segment_ids = padded_segment_ids.to(device)\n",
    "\n",
    "            padded_mask_ids = pad_sequence([torch.tensor(instance['mask_ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_mask_ids = padded_mask_ids.to(device)\n",
    "\n",
    "            labels = torch.stack([torch.tensor(instance['labels']) for instance in dictionary_lists])\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            current_dev_batch = {'ids': padded_ids, 'mask_ids': padded_mask_ids, 'segment_ids': padded_segment_ids, 'labels': labels}\n",
    "\n",
    "            batches.append(current_dev_batch)\n",
    "            dictionary_lists = []\n",
    "            unit_counter = 0\n",
    "    \n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_preprocessing(data, dataset):\n",
    "    \n",
    "    len_array = np.cumsum(np.array(data['SENTS'].apply(lambda x: len(x))))\n",
    "\n",
    "    dictionary_lists = []\n",
    "    batches = []\n",
    "    for i in range(len(dataset.instances)):\n",
    "        \n",
    "        instance = dataset.instances[i]\n",
    "        dictionary_lists.append(instance)\n",
    "        \n",
    "        if i in len_array - 1:\n",
    "\n",
    "            padded_ids = pad_sequence([torch.tensor(instance['ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_ids = padded_ids.to(device)\n",
    "\n",
    "            padded_segment_ids = pad_sequence([torch.tensor(instance['segment_ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_segment_ids = padded_segment_ids.to(device)\n",
    "\n",
    "            padded_mask_ids = pad_sequence([torch.tensor(instance['mask_ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_mask_ids = padded_mask_ids.to(device)\n",
    "\n",
    "            labels = torch.stack([torch.tensor(instance['labels']) for instance in dictionary_lists])\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            \n",
    "            current_dev_batch = {'ids': padded_ids, 'mask_ids': padded_mask_ids, 'segment_ids': padded_segment_ids, 'labels': labels}\n",
    "\n",
    "            batches.append(current_dev_batch)\n",
    "            dictionary_lists = []\n",
    "\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_eval_preprocessing(data, dataset): \n",
    "    \n",
    "    len_array = np.cumsum(np.array(data['SENTS'].apply(lambda x: len(x))))\n",
    "\n",
    "    dictionary_lists = []\n",
    "    batches = []\n",
    "    for i in range(len(dataset.instances)):\n",
    "        \n",
    "        instance = dataset.instances[i]\n",
    "        dictionary_lists.append(instance)\n",
    "        \n",
    "        if i in len_array - 1:\n",
    "\n",
    "            \n",
    "            padded_ids = pad_sequence([torch.tensor(instance['ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_ids = padded_ids.to(device)\n",
    "\n",
    "            #padded_segment_ids = pad_sequence([torch.tensor(instance['segment_ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            #padded_segment_ids = padded_segment_ids.to(device)\n",
    "\n",
    "            padded_mask_ids = pad_sequence([torch.tensor(instance['mask_ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_mask_ids = padded_mask_ids.to(device)\n",
    "            \n",
    "            padded_sentence_masks = pad_sequence([torch.tensor(instance['sentence_mask']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_sentence_masks = padded_sentence_masks.to(device)\n",
    "            \n",
    "            padded_q_ids = pad_sequence([torch.tensor(instance['q_ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_q_ids = padded_q_ids.to(device)\n",
    "            \n",
    "            padded_q_mask_ids = pad_sequence([torch.tensor(instance['q_mask_ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_q_mask_ids = padded_q_mask_ids.to(device)\n",
    "\n",
    "            labels = torch.stack([torch.tensor(instance['labels']) for instance in dictionary_lists])\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            \n",
    "            current_dev_batch = {'ids': padded_ids, 'mask_ids': padded_mask_ids, 'sentence_mask': padded_sentence_masks,\n",
    "                                 'labels': labels, 'q_ids': padded_q_ids, \"q_mask_ids\": padded_q_mask_ids}\n",
    "\n",
    "            batches.append(current_dev_batch)\n",
    "            dictionary_lists = []\n",
    "\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_instances, dev_ids, dev_seg_ids, dev_mask_ids, dev_labels = datapreprocessing(validation_data)\n",
    "train_instances, train_ids, train_seg_ids, train_mask_ids, train_labels = datapreprocessing(training_data)\n",
    "test_instances, test_ids, test_seg_ids, test_mask_ids, test_labels = datapreprocessing(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0811 02:29:23.051539 139897081689920 tokenization_utils.py:375] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /root/.cache/torch/transformers/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00\n"
     ]
    }
   ],
   "source": [
    "qs_instances, qs_ids, qs_mask_ids, qs_sen_mask, qs_labels = data_to_sentence(training_data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0811 02:29:56.492766 139897081689920 tokenization_utils.py:375] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /root/.cache/torch/transformers/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00\n"
     ]
    }
   ],
   "source": [
    "dev_qs_instances, dev_qs_ids, dev_qs_mask_ids, dev_qs_sen_mask, dev_qs_labels = data_to_sentence(validation_data, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, ids, segment_ids, mask_ids, labels):\n",
    "        self.instances = []\n",
    "        for ids_i, segment_ids_i, mask_ids, label in zip(ids, segment_ids, mask_ids, labels):\n",
    "            self.instances.append({\"ids\": ids_i, \"segment_ids\": segment_ids_i, \n",
    "                                   \"mask_ids\": mask_ids, \"labels\": label})  \n",
    "                                   \n",
    "    def __len__(self):\n",
    "        return len(self.instances)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.instances[idx]\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionSentenceDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, ids, mask_ids, sen_masks, labels):\n",
    "        self.instances = []\n",
    "        for ids_i, mask_ids, sen_mask, label in zip(ids, mask_ids, sen_masks, labels):\n",
    "            self.instances.append({\"ids\": torch.tensor(ids_i[1]), \"mask_ids\": torch.tensor(mask_ids[1]), \n",
    "                                   \"sentence_mask\": torch.tensor(sen_mask), \"labels\": torch.tensor(label), \n",
    "                                   \"q_ids\": torch.tensor(ids_i[0]), \"q_mask_ids\": torch.tensor(mask_ids[0])})\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.instances)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.instances[idx]\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SentenceDataset(train_ids, train_seg_ids, train_mask_ids, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset = SentenceDataset(dev_ids, dev_seg_ids, dev_mask_ids, dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SentenceDataset(test_ids, test_seg_ids, test_mask_ids, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_train_dataset = QuestionSentenceDataset(qs_ids, qs_mask_ids, qs_sen_mask, qs_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_dev_dataset = QuestionSentenceDataset(dev_qs_ids, dev_qs_mask_ids, dev_qs_sen_mask, dev_qs_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31422"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    padded_ids = pad_sequence([torch.tensor(instance['ids']) for instance in batch], batch_first=True)\n",
    "    padded_ids = padded_ids.to(device)\n",
    "    \n",
    "    padded_segment_ids = pad_sequence([torch.tensor(instance['segment_ids']) for instance in batch], batch_first=True)\n",
    "    padded_segment_ids = padded_segment_ids.to(device)\n",
    "    \n",
    "    padded_mask_ids = pad_sequence([torch.tensor(instance['mask_ids']) for instance in batch], batch_first=True)\n",
    "    padded_mask_ids = padded_mask_ids.to(device)\n",
    "    \n",
    "    labels = torch.stack([torch.tensor(instance['labels']) for instance in batch])\n",
    "    labels = labels.to(device)\n",
    "    return {'ids': padded_ids, 'mask_ids': padded_mask_ids, 'segment_ids': padded_segment_ids, 'labels': labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_3d(batch):\n",
    "    \n",
    "    batch_size = len(batch)\n",
    "    \n",
    "    max_num_sentences, max_sentence_length = find_max_dimension(batch)\n",
    "    \n",
    "    # sentence weight\n",
    "    sentence_mask = torch.zeros(batch_size, max_num_sentences)\n",
    "    \n",
    "    \n",
    "    target_ids = torch.zeros(batch_size, max_num_sentences, max_sentence_length)\n",
    "    target_segment_ids = torch.zeros(batch_size, max_num_sentences, max_sentence_length)\n",
    "    target_mask_ids = torch.zeros(batch_size, max_num_sentences, max_sentence_length)\n",
    "    target_labels = torch.zeros(batch_size, max_num_sentences, 1)\n",
    "    for i in range(len(batch)):\n",
    "        \n",
    "        source_id_dimension = batch[i]['ids'].shape\n",
    "        \n",
    "        sentence_mask[i, :source_id_dimension[0]] = 1\n",
    "        \n",
    "        target_ids[i, :source_id_dimension[0], :source_id_dimension[1]] = batch[i]['ids']\n",
    "        \n",
    "        source_segment_id_dimension = batch[i]['segment_ids'].shape\n",
    "        target_segment_ids[i, :source_segment_id_dimension[0], :source_segment_id_dimension[1]] = batch[i]['segment_ids']\n",
    "        \n",
    "        source_mask_id_dimension = batch[i]['mask_ids'].shape\n",
    "        target_mask_ids[i, :source_mask_id_dimension[0], :source_mask_id_dimension[1]] = batch[i]['mask_ids']\n",
    "        \n",
    "        source_label_dimension = batch[i]['labels'].shape\n",
    "        target_labels[i, :source_label_dimension[0], :source_label_dimension[1]] = batch[i]['labels']\n",
    "    \n",
    "    target_labels = target_labels.squeeze(-1)\n",
    "    \n",
    "    target_ids = target_ids.to(device).to(torch.long)\n",
    "    target_segment_ids = target_segment_ids.to(device).to(torch.long)\n",
    "    target_mask_ids = target_segment_ids.to(device).to(torch.long)\n",
    "    target_labels = target_labels.to(dtype=torch.float, device=device)\n",
    "    sentence_mask = sentence_mask.to(device).to(torch.float)\n",
    "    return {'ids': target_ids, 'mask_ids': target_mask_ids, 'segment_ids': target_segment_ids, 'labels': target_labels, 'sentence_mask': sentence_mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_2d(batch):\n",
    "    \n",
    "    batch_size = len(batch)\n",
    "    \n",
    "    max_num_sentences, max_sentence_length = find_max_dimension(batch)\n",
    "    \n",
    "    # sentence weight\n",
    "    #sentence_mask = torch.zeros(batch_size, max_num_sentences)\n",
    "    \n",
    "    \n",
    "    target_ids = torch.zeros(max_num_sentences, max_sentence_length)\n",
    "    target_segment_ids = torch.zeros(max_num_sentences, max_sentence_length)\n",
    "    target_mask_ids = torch.zeros(max_num_sentences, max_sentence_length)\n",
    "    target_labels = torch.zeros(max_num_sentences, 1)\n",
    "    for i in range(len(batch)):\n",
    "        \n",
    "        source_id_dimension = batch[i]['ids'].shape\n",
    "        \n",
    "        #sentence_mask[:source_id_dimension[0]] = 1\n",
    "        \n",
    "        target_ids[:source_id_dimension[0], :source_id_dimension[1]] = batch[i]['ids']\n",
    "        \n",
    "        source_segment_id_dimension = batch[i]['segment_ids'].shape\n",
    "        target_segment_ids[:source_segment_id_dimension[0], :source_segment_id_dimension[1]] = batch[i]['segment_ids']\n",
    "        \n",
    "        source_mask_id_dimension = batch[i]['mask_ids'].shape\n",
    "        target_mask_ids[:source_mask_id_dimension[0], :source_mask_id_dimension[1]] = batch[i]['mask_ids']\n",
    "        \n",
    "        source_label_dimension = batch[i]['labels'].shape\n",
    "        target_labels[:source_label_dimension[0], :source_label_dimension[1]] = batch[i]['labels']\n",
    "\n",
    "    #target_labels = target_labels.squeeze(-1)\n",
    "    \n",
    "    target_ids = target_ids.to(device).to(torch.long)\n",
    "    target_segment_ids = target_segment_ids.to(device).to(torch.long)\n",
    "    target_mask_ids = target_segment_ids.to(device).to(torch.long)\n",
    "    target_labels = target_labels.to(dtype=torch.float, device=device)\n",
    "    #sentence_mask = sentence_mask.to(device).to(torch.float)\n",
    "    return {'ids': target_ids, 'mask_ids': target_mask_ids, 'segment_ids': target_segment_ids, 'labels': target_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_dimension(batch):\n",
    "    num_sentences = []\n",
    "    sentence_lengths = []\n",
    "    for question in batch:\n",
    "        num_sentences.append(question['ids'].shape[0])\n",
    "        sentence_lengths.append(question['ids'].shape[1])\n",
    "    return max(num_sentences), max(sentence_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_train_batches = window_sentence_preprocessing(training_data, train_dataset, 10)\n",
    "#new_train_2d_batches = window_sentence_preprocessing(training_data, train_dataset, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_train_batches[4]['ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(train_dataset, batch_size=4, shuffle = True, collate_fn = collate)\n",
    "#dataloader_train_3d = DataLoader(new_train_batches, batch_size=2, shuffle = True, collate_fn = collate_3d)\n",
    "#dataloader_train_2d = DataLoader(new_train_2d_batches, batch_size=8, shuffle = True, collate_fn = collate_2d)\n",
    "#dataloader_sent_train = DataLoader(sent_train_dataset, batch_size = 4, shuffle = True)\n",
    "#dataloader_sent_train_eval = DataLoader(sent_train_dataset, batch_size = 1)\n",
    "#dataloader_sent_dev = DataLoader(sent_dev_dataset, batch_size = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentence_lengths = []\n",
    "dev_sentence_lengths = []\n",
    "test_sentence_lengths = []\n",
    "\n",
    "for instance_dict in train_dataset.instances:\n",
    "    train_sentence_lengths.append(len(instance_dict['ids']))\n",
    "    \n",
    "for instance_dict in dev_dataset.instances:\n",
    "    dev_sentence_lengths.append(len(instance_dict['ids']))\n",
    "    \n",
    "for instance_dict in test_dataset.instances:\n",
    "    test_sentence_lengths.append(len(instance_dict['ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data >512 percentage: 0.0\n",
      "dev data >512 percentage: 0.0\n",
      "test data >512 percentage: 0.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(train_sentence_lengths, bins=100)\n",
    "plt.hist(dev_sentence_lengths, bins=100)\n",
    "plt.hist(test_sentence_lengths, bins=100)\n",
    "print('train data >512 percentage:', (np.array(train_sentence_lengths) > 512).sum() / len(train_sentence_lengths))\n",
    "print('dev data >512 percentage:', (np.array(dev_sentence_lengths) > 512).sum() / len(dev_sentence_lengths))\n",
    "print('test data >512 percentage:', (np.array(test_sentence_lengths) > 512).sum() / len(test_sentence_lengths))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class baseline_model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(baseline_model, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-chinese')\n",
    "        self.linear = nn.Linear(768, 1)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        # batch['ids'] = (batch_size, sent_len)\n",
    "        # batch['segment_ids'] = (batch_size, sent_len)\n",
    "        # batch['mask_ids'] = (batch_size, sent_len)\n",
    "        # pooler_output = (batch_size, 768)\n",
    "        # output = (batch_size, 1)\n",
    "        hidden_state, pooler_output = self.bert(batch['ids'], batch['mask_ids'], batch['segment_ids'])\n",
    "        \n",
    "        linear_output = self.linear(pooler_output)\n",
    "\n",
    "        return linear_output\n",
    "\n",
    "    def loss(self, batch):\n",
    "        \n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "        output = self.forward(batch)\n",
    "        target = batch['labels'].float().to(device)\n",
    "        \n",
    "        return loss_fn(output, target)\n",
    "    \n",
    "    def _predict(self, batch):\n",
    "        \n",
    "        output = self.forward(batch)\n",
    "        scores = torch.sigmoid(output)\n",
    "        scores = scores.cpu().numpy()[:,0].tolist()\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    def predict_fgc(self, batch, threshold=0.5):\n",
    "        \n",
    "        scores = self._predict(batch)\n",
    "        max_i = 0\n",
    "        max_score = 0\n",
    "        sp = []\n",
    "        \n",
    "        for i, score in enumerate(scores):\n",
    "\n",
    "            if score > max_score:\n",
    "                max_i = i\n",
    "                max_score = score\n",
    "            if score >= threshold:\n",
    "                sp.append(i)\n",
    "\n",
    "        if not sp:\n",
    "            sp.append(max_i)\n",
    "\n",
    "        return {'sp': sp, 'sp_scores': scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0812 02:16:03.949645 139797494843200 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json from cache at /root/.cache/torch/transformers/8a3b1cfe5da58286e12a0f5d7d182b8d6eca88c08e26c332ee3817548cf7e60a.f12a4f986e43d8b328f5b067a641064d67b91597567a06c7b122d1ca7dfd9741\n",
      "I0812 02:16:03.951986 139797494843200 configuration_utils.py:300] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "I0812 02:16:04.254365 139797494843200 modeling_utils.py:666] loading weights file https://cdn.huggingface.co/bert-base-chinese-pytorch_model.bin from cache at /root/.cache/torch/transformers/a75f2e45a9463e784dfe8c1d9672440d5fc1b091d5ab104e3c2d82e90ab1b222.929717ca66a3ba9eb9ec2f85973c6398c54c38a4faa464636a491d7a705f7eb6\n",
      "I0812 02:16:07.470762 139797494843200 modeling_utils.py:764] All model checkpoint weights were used when initializing BertModel.\n",
      "\n",
      "I0812 02:16:07.472046 139797494843200 modeling_utils.py:773] All the weights of BertModel were initialized from the model checkpoint at bert-base-chinese.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "baseline_model(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline = baseline_model()\n",
    "baseline.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Baseline Model & Evaluating Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optim(nn, num_epochs, lr):\n",
    "    param_optimizer = list(nn.bert.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "    num_epochs = num_epochs\n",
    "    num_train_optimization_steps = len(dataloader_train) * num_epochs\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=lr)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                     num_warmup_steps=int(\n",
    "                                                         num_train_optimization_steps * 0.1),\n",
    "                                                     num_training_steps=num_train_optimization_steps)\n",
    "    return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _update_sp(metrics, sp_gold, sp_pred):\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "        \n",
    "    for p in sp_pred:\n",
    "        if p in sp_gold:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "    for g in sp_gold:\n",
    "        if g not in sp_pred:\n",
    "            fn += 1\n",
    "            \n",
    "    precision = 1.0 * tp / (tp + fp) if tp + fp > 0 else 0.0\n",
    "    recall = 1.0 * tp / (tp + fn) if tp + fn > 0 else 0.0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0.0\n",
    "    em = 1.0 if fp + fn == 0 else 0.0\n",
    "    \n",
    "    metrics['sp_em'] += em\n",
    "    metrics['sp_f1'] += f1\n",
    "    metrics['sp_prec'] += precision\n",
    "    metrics['sp_recall'] += recall\n",
    "    \n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_sp_fgc(sp_golds, sp_preds):\n",
    "    \n",
    "    metrics = {'sp_em': 0, 'sp_prec': 0, 'sp_recall': 0, 'sp_f1': 0}\n",
    "    \n",
    "    assert len(sp_golds) == len(sp_preds)\n",
    "    \n",
    "    for sp_gold, sp_pred in zip(sp_golds, sp_preds):\n",
    "        _update_sp(metrics, sp_gold, sp_pred)\n",
    "    \n",
    "    N = len(sp_golds)\n",
    "    for k in metrics.keys():\n",
    "        metrics[k] /= N\n",
    "        metrics[k] = round(metrics[k], 3)\n",
    "    print(metrics)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fgc_atype(atype_golds, atype_preds):\n",
    "    \n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    \n",
    "    for gold, atype in zip(atype_golds, atype_preds):\n",
    "        if atype == gold:\n",
    "            pos += 1\n",
    "        else:\n",
    "            neg += 1\n",
    "    return pos/len(atypes_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(network, dev_batches, current_epoch, sp_golds, avg_loss):\n",
    "    \n",
    "    network.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        sp_preds = []\n",
    "        for batch in tqdm(dev_batches):\n",
    "            \n",
    "            out_dct = network.predict_fgc(batch)\n",
    "            sp_preds.append(out_dct['sp'])\n",
    "                \n",
    "    metrics = eval_sp_fgc(sp_golds, sp_preds)\n",
    "    print('epoch %d eval_recall: %.3f eval_f1: %.3f loss: %.3f' % (\n",
    "            current_epoch, metrics['sp_recall'], metrics['sp_f1'], avg_loss))\n",
    "        \n",
    "    torch.save(network.state_dict(), \"Models_SEs/model_epoch{0}_eval_em:{1:.3f}_precision:{2:.3f}_recall:{3:.3f}_f1:{4:.3f}_loss:{5:.3f}.m\".format(current_epoch, metrics['sp_em'], metrics['sp_prec'], metrics['sp_recall'], metrics['sp_f1'], avg_loss))\n",
    "    \n",
    "    return sp_preds, sp_golds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(network, data, dev_batches, num_epochs, lr):\n",
    "    \n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer, scheduler = optim(network, num_epochs, lr)\n",
    "    \n",
    "    sp_golds = validation_data['QUESTIONS'].apply(lambda x: x[0]['SHINT_']).tolist()\n",
    "    \n",
    "    for current_epoch in range(num_epochs):\n",
    "        network.train()\n",
    "        running_loss = 0.0\n",
    "        for batch in tqdm(data):\n",
    "            optimizer.zero_grad()\n",
    "            current_output = network(batch)\n",
    "            current_target = batch['labels'].to(dtype=torch.float, device=device)\n",
    "            current_loss = loss_fn(current_output, current_target)\n",
    "            current_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(network.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            running_loss += current_loss.item()\n",
    "            \n",
    "        learning_rate_scalar = scheduler.get_lr()[0]\n",
    "        print('lr = %f' % learning_rate_scalar)\n",
    "        avg_loss = running_loss/len(data)\n",
    "        print('epoch %d train_loss: %.3f' % (current_epoch, avg_loss))\n",
    "        eval(network, dev_batches, current_epoch, sp_golds, avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_batches = eval_preprocessing(validation_data, dev_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "807b0fd485bf4bd9b373b96b9dca74c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000010\n",
      "epoch 0 train_loss: 0.246\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d36bc20684aa40e3b696ff12b9d42b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.18, 'sp_prec': 0.732, 'sp_recall': 0.454, 'sp_f1': 0.528}\n",
      "epoch 0 eval_recall: 0.454 eval_f1: 0.528 loss: 0.246\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32bb8eef079d4854802ef872256a43a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000020\n",
      "epoch 1 train_loss: 0.202\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80eebe9da58e406390b71596bdd0e935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.146, 'sp_prec': 0.593, 'sp_recall': 0.551, 'sp_f1': 0.523}\n",
      "epoch 1 eval_recall: 0.551 eval_f1: 0.523 loss: 0.202\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e1cfac3ff6465f84d9a2531ef423d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000019\n",
      "epoch 2 train_loss: 0.174\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b661cf89858408995e2e06056b87a17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.163, 'sp_prec': 0.648, 'sp_recall': 0.562, 'sp_f1': 0.546}\n",
      "epoch 2 eval_recall: 0.562 eval_f1: 0.546 loss: 0.174\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab4932062704c64b301edf417e2d837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000018\n",
      "epoch 3 train_loss: 0.145\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "193d73cf384744f4bf754a2130682e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.113, 'sp_prec': 0.533, 'sp_recall': 0.689, 'sp_f1': 0.538}\n",
      "epoch 3 eval_recall: 0.689 eval_f1: 0.538 loss: 0.145\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "746fd88323d54a74b932803ffb4b363f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000017\n",
      "epoch 4 train_loss: 0.115\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bec13191beb4a5e9b50cdca7cb7bcd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.134, 'sp_prec': 0.605, 'sp_recall': 0.551, 'sp_f1': 0.518}\n",
      "epoch 4 eval_recall: 0.551 eval_f1: 0.518 loss: 0.115\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58409232b48f4920970db6dbc5379628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000016\n",
      "epoch 5 train_loss: 0.101\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6d7b973c4894735a596f6e50fb17a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.126, 'sp_prec': 0.567, 'sp_recall': 0.637, 'sp_f1': 0.537}\n",
      "epoch 5 eval_recall: 0.637 eval_f1: 0.537 loss: 0.101\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f71d5cd9753041deb9b76ccf3a56f92e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000014\n",
      "epoch 6 train_loss: 0.078\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a521d98097ef46f8ba2d5aef61ed4078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.146, 'sp_prec': 0.593, 'sp_recall': 0.605, 'sp_f1': 0.541}\n",
      "epoch 6 eval_recall: 0.605 eval_f1: 0.541 loss: 0.078\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dec14f8281d49d6bb9e2577a88fc7ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000013\n",
      "epoch 7 train_loss: 0.065\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "282fc290454942d9bce148b475d8a307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.159, 'sp_prec': 0.619, 'sp_recall': 0.564, 'sp_f1': 0.54}\n",
      "epoch 7 eval_recall: 0.564 eval_f1: 0.540 loss: 0.065\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a25e79db67b4b12bd5df54477c2d1e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000012\n",
      "epoch 8 train_loss: 0.051\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "540bd1ea56b34fb2aeaee2afb05c38a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.155, 'sp_prec': 0.612, 'sp_recall': 0.562, 'sp_f1': 0.535}\n",
      "epoch 8 eval_recall: 0.562 eval_f1: 0.535 loss: 0.051\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd1a48faa654f05ad0e8049be53d543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000011\n",
      "epoch 9 train_loss: 0.046\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "864c606f38c944deb1ff7d7dba5b2881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.155, 'sp_prec': 0.604, 'sp_recall': 0.534, 'sp_f1': 0.511}\n",
      "epoch 9 eval_recall: 0.534 eval_f1: 0.511 loss: 0.046\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e67e9b28888d42d1be7a5e40d17ae2a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000010\n",
      "epoch 10 train_loss: 0.035\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50ece5481c7f401b8d242de38b2dd750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.138, 'sp_prec': 0.577, 'sp_recall': 0.646, 'sp_f1': 0.548}\n",
      "epoch 10 eval_recall: 0.646 eval_f1: 0.548 loss: 0.035\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c35517768b343d6b84ba29760bb78bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000009\n",
      "epoch 11 train_loss: 0.029\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "800df5b00254430089917bb12a269046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.172, 'sp_prec': 0.596, 'sp_recall': 0.556, 'sp_f1': 0.529}\n",
      "epoch 11 eval_recall: 0.556 eval_f1: 0.529 loss: 0.029\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee8582c5455c49f1815b38139f8d0d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000008\n",
      "epoch 12 train_loss: 0.026\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f04b670fece9444ba9bfae429a7ec798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.121, 'sp_prec': 0.552, 'sp_recall': 0.589, 'sp_f1': 0.515}\n",
      "epoch 12 eval_recall: 0.589 eval_f1: 0.515 loss: 0.026\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "191b677709a544f09cca707f37102520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000007\n",
      "epoch 13 train_loss: 0.022\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3831f991cea4c7f835722a7a3164b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.138, 'sp_prec': 0.576, 'sp_recall': 0.537, 'sp_f1': 0.505}\n",
      "epoch 13 eval_recall: 0.537 eval_f1: 0.505 loss: 0.022\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a22f4b95db0747febd036c0976e33e0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000006\n",
      "epoch 14 train_loss: 0.021\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae677d0cea4340a7b23bcfe78604c330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.167, 'sp_prec': 0.588, 'sp_recall': 0.557, 'sp_f1': 0.519}\n",
      "epoch 14 eval_recall: 0.557 eval_f1: 0.519 loss: 0.021\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cd33c43ed1543cb92f6136272d369bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000004\n",
      "epoch 15 train_loss: 0.015\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0332ad030f6486095231842780a670e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.167, 'sp_prec': 0.606, 'sp_recall': 0.578, 'sp_f1': 0.538}\n",
      "epoch 15 eval_recall: 0.578 eval_f1: 0.538 loss: 0.015\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cedff151aff4b828094bd5bdba88962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000003\n",
      "epoch 16 train_loss: 0.010\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f744c6eccaf46c38aaa75f32875215b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.167, 'sp_prec': 0.592, 'sp_recall': 0.604, 'sp_f1': 0.54}\n",
      "epoch 16 eval_recall: 0.604 eval_f1: 0.540 loss: 0.010\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a189524548243d6b76efba0a7693c7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000002\n",
      "epoch 17 train_loss: 0.006\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90666bd6e8b94bb6a251cc78e8a9923f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.163, 'sp_prec': 0.602, 'sp_recall': 0.587, 'sp_f1': 0.54}\n",
      "epoch 17 eval_recall: 0.587 eval_f1: 0.540 loss: 0.006\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2be18849b3d840be8167ef983a95ca21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000001\n",
      "epoch 18 train_loss: 0.003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54fea467db704163971b61d0b180de44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.138, 'sp_prec': 0.589, 'sp_recall': 0.61, 'sp_f1': 0.542}\n",
      "epoch 18 eval_recall: 0.610 eval_f1: 0.542 loss: 0.003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "837983e0646f4314bf319ee8061b0d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000000\n",
      "epoch 19 train_loss: 0.004\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb87fac7452b4fc5b3044ff86c9e34e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.142, 'sp_prec': 0.597, 'sp_recall': 0.608, 'sp_f1': 0.543}\n",
      "epoch 19 eval_recall: 0.608 eval_f1: 0.543 loss: 0.004\n"
     ]
    }
   ],
   "source": [
    "train(baseline, dataloader_train, dev_batches, 20, 0.00002) # if you want to run this again, rememebr to add the parameter 'batches'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0724 08:26:42.599873 140341672732480 configuration_utils.py:152] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json from cache at /root/.cache/torch/transformers/8a3b1cfe5da58286e12a0f5d7d182b8d6eca88c08e26c332ee3817548cf7e60a.f12a4f986e43d8b328f5b067a641064d67b91597567a06c7b122d1ca7dfd9741\n",
      "I0724 08:26:42.603232 140341672732480 configuration_utils.py:169] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "I0724 08:26:43.473549 140341672732480 modeling_utils.py:387] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-pytorch_model.bin from cache at /root/.cache/torch/transformers/b1b5e295889f2d0979ede9a78ad9cb5dc6a0e25ab7f9417b315f0a2c22f4683d.929717ca66a3ba9eb9ec2f85973c6398c54c38a4faa464636a491d7a705f7eb6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_baseline = baseline_model()\n",
    "trained_baseline.load_state_dict(torch.load(\"Models/baseline_models_with_scheduler/model_epoch8_eval_em:0.198_precision:0.603_recall:0.588_f1:0.545_loss:0.031.m\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dd358afcf454dbca8cc9ebb869256ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=882), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.895, 'sp_prec': 0.97, 'sp_recall': 0.955, 'sp_f1': 0.958}\n",
      "epoch 0 eval_recall: 0.955 eval_f1: 0.958 loss: 0.001\n"
     ]
    }
   ],
   "source": [
    "sp_golds = training_data['QUESTIONS'].apply(lambda x: x[0]['SHINT_']).tolist()\n",
    "batches = eval_preprocessing(training_data, train_dataset)\n",
    "\n",
    "trained_network.to(\"cuda\")\n",
    "train_pred, train_obs = eval(trained_network, batches, 0, sp_golds, 0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14706ff3ce654779a0bf43f754162b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=247), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.194, 'sp_prec': 0.599, 'sp_recall': 0.584, 'sp_f1': 0.541}\n",
      "epoch 0 eval_recall: 0.584 eval_f1: 0.541 loss: 0.001\n"
     ]
    }
   ],
   "source": [
    "sp_golds = validation_data['QUESTIONS'].apply(lambda x: x[0]['SHINT_']).tolist()\n",
    "dev_batches = eval_preprocessing(validation_data, dev_dataset)\n",
    "dev_preds, dev_obs = eval(trained_network, dev_batches, 0, sp_golds, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d31d52a9c5467fbd6374a5c131ccc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=193), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.212, 'sp_prec': 0.643, 'sp_recall': 0.553, 'sp_f1': 0.55}\n",
      "epoch 0 eval_recall: 0.553 eval_f1: 0.550 loss: 0.001\n"
     ]
    }
   ],
   "source": [
    "sp_golds = test_data['QUESTIONS'].apply(lambda x: x[0]['SHINT_']).tolist()\n",
    "test_batches = eval_preprocessing(test_data, test_dataset)\n",
    "test_preds, test_obds = eval(trained_network, test_batches, 0, sp_golds, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data_with_performance = datapreprocessing(validation_data, True)\n",
    "training_data_with_performance = datapreprocessing(training_data, True)\n",
    "test_data_with_performance = datapreprocessing(test_data, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_with_performance['train_pred'] = train_pred\n",
    "training_data_with_performance['train_obs'] = train_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_sp = []\n",
    "for i in range(training_data_with_performance.shape[0]):\n",
    "    para = training_data_with_performance['Sentence_List'][i]\n",
    "    sen = []\n",
    "    for index in training_data_with_performance['train_pred'][i]:\n",
    "        sen.append(para[index])\n",
    "    correct_sp.append(sen)\n",
    "training_data_with_performance['Pred_List'] = correct_sp\n",
    "correct_sp = []\n",
    "for i in range(training_data_with_performance.shape[0]):\n",
    "    para = training_data_with_performance['Sentence_List'][i]\n",
    "    sen = []\n",
    "    for index in training_data_with_performance['train_obs'][i]:\n",
    "        sen.append(para[index])\n",
    "    correct_sp.append(sen)\n",
    "training_data_with_performance['Obs_List'] = correct_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_with_performance.drop(['SE_Index', 'Label', 'train_pred', 'train_obs'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Sentence_List</th>\n",
       "      <th>Length</th>\n",
       "      <th>Pred_List</th>\n",
       "      <th>Obs_List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>苏东坡出生于哪一年?</td>\n",
       "      <td>[嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...</td>\n",
       "      <td>35</td>\n",
       "      <td>[苏轼才20岁，]</td>\n",
       "      <td>[嘉佑二年（1057年），, 苏轼才20岁，]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>苏东坡和谁一起进京参加会考?</td>\n",
       "      <td>[嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...</td>\n",
       "      <td>35</td>\n",
       "      <td>[与弟弟苏辙一同进京参加会考，]</td>\n",
       "      <td>[苏轼才20岁，, 与弟弟苏辙一同进京参加会考，]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>在苏东坡被王安石诬陷时，谁为他说话？</td>\n",
       "      <td>[嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...</td>\n",
       "      <td>35</td>\n",
       "      <td>[范镇极辩苏轼贩盐之诬，]</td>\n",
       "      <td>[范镇极辩苏轼贩盐之诬，, 并愿意退休负责。]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>苏东坡哪一年离开海南岛?</td>\n",
       "      <td>[元祐元年（1086年），, 宋哲宗即位，, 高太皇太后垂帘听政，, 回朝任礼部郎中、中书舍...</td>\n",
       "      <td>32</td>\n",
       "      <td>[\\n绍圣元年（1094年）被哲宗贬谪至惠州、儋州（海南岛）。, 下诏让苏轼北还。]</td>\n",
       "      <td>[\\n绍圣元年（1094年）被哲宗贬谪至惠州、儋州（海南岛）。, \\n元符三年（1100年）...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>苏东坡死于哪一年?</td>\n",
       "      <td>[元祐元年（1086年），, 宋哲宗即位，, 高太皇太后垂帘听政，, 回朝任礼部郎中、中书舍...</td>\n",
       "      <td>32</td>\n",
       "      <td>[七月二十八日于常州孙氏馆病卒，]</td>\n",
       "      <td>[\\n建中靖国元年（1101年），, 七月二十八日于常州孙氏馆病卒，]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>829</td>\n",
       "      <td>青河大学时代在哪一所学校念书?</td>\n",
       "      <td>[为倾听新住民心声，, 内政部移民署今(18)日下午，, 在台南市举办新住民座谈会，, 有2...</td>\n",
       "      <td>56</td>\n",
       "      <td>[青河毕业于越南河内国家大学法文系，, 青河得以持续进修，]</td>\n",
       "      <td>[青河毕业于越南河内国家大学法文系，, 青河得以持续进修，, 她不仅取得国立成功大学硕士学位，]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>831</td>\n",
       "      <td>青河的硕士学位在哪一个国家念的?</td>\n",
       "      <td>[为倾听新住民心声，, 内政部移民署今(18)日下午，, 在台南市举办新住民座谈会，, 有2...</td>\n",
       "      <td>56</td>\n",
       "      <td>[青河毕业于越南河内国家大学法文系，, 青河得以持续进修，]</td>\n",
       "      <td>[青河毕业于越南河内国家大学法文系，, 青河得以持续进修，, 她不仅取得国立成功大学硕士学位，]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>867</td>\n",
       "      <td>如果我使用了日本买的眼药水却发生过敏红肿，是否可以申请药害救济?</td>\n",
       "      <td>[「目睭花花，匏仔看做菜瓜」，, 许多民众如果觉得眼睛雾雾时，, 常常会自行购买眼药水来缓解...</td>\n",
       "      <td>39</td>\n",
       "      <td>[透过网购或国外带回的眼药水，, 并不属于我国合法药物，, 并不适用我国药害救济制度喔!\\n...</td>\n",
       "      <td>[透过网购或国外带回的眼药水，, 并不适用我国药害救济制度喔!\\n\\n       食药署为...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>目前在台湾出现的肠病毒有哪几型?</td>\n",
       "      <td>[国内肠病毒轻症疫情持续上升，, 另新增1例肠病毒71型并发重症病例。, 疾病管制署再次呼吁...</td>\n",
       "      <td>42</td>\n",
       "      <td>[以感染肠病毒71型为多(28例)，, 其他分别感染肠病毒D68型、克沙奇A6型、A10型(...</td>\n",
       "      <td>[今(2019)年累计37例肠病毒并发重症病例，, 以感染肠病毒71型为多(28例)，, 其...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>874</td>\n",
       "      <td>要如何降低肠病毒的传播风险？</td>\n",
       "      <td>[国内肠病毒轻症疫情持续上升，, 另新增1例肠病毒71型并发重症病例。, 疾病管制署再次呼吁...</td>\n",
       "      <td>42</td>\n",
       "      <td>[疾病管制署再次呼吁，]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Question  \\\n",
       "1                          苏东坡出生于哪一年?   \n",
       "2                      苏东坡和谁一起进京参加会考?   \n",
       "8                  在苏东坡被王安石诬陷时，谁为他说话？   \n",
       "12                       苏东坡哪一年离开海南岛?   \n",
       "13                          苏东坡死于哪一年?   \n",
       "..                                ...   \n",
       "829                  青河大学时代在哪一所学校念书?    \n",
       "831                  青河的硕士学位在哪一个国家念的?   \n",
       "867  如果我使用了日本买的眼药水却发生过敏红肿，是否可以申请药害救济?   \n",
       "870                  目前在台湾出现的肠病毒有哪几型?   \n",
       "874                    要如何降低肠病毒的传播风险？   \n",
       "\n",
       "                                         Sentence_List  Length  \\\n",
       "1    [嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...      35   \n",
       "2    [嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...      35   \n",
       "8    [嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...      35   \n",
       "12   [元祐元年（1086年），, 宋哲宗即位，, 高太皇太后垂帘听政，, 回朝任礼部郎中、中书舍...      32   \n",
       "13   [元祐元年（1086年），, 宋哲宗即位，, 高太皇太后垂帘听政，, 回朝任礼部郎中、中书舍...      32   \n",
       "..                                                 ...     ...   \n",
       "829  [为倾听新住民心声，, 内政部移民署今(18)日下午，, 在台南市举办新住民座谈会，, 有2...      56   \n",
       "831  [为倾听新住民心声，, 内政部移民署今(18)日下午，, 在台南市举办新住民座谈会，, 有2...      56   \n",
       "867  [「目睭花花，匏仔看做菜瓜」，, 许多民众如果觉得眼睛雾雾时，, 常常会自行购买眼药水来缓解...      39   \n",
       "870  [国内肠病毒轻症疫情持续上升，, 另新增1例肠病毒71型并发重症病例。, 疾病管制署再次呼吁...      42   \n",
       "874  [国内肠病毒轻症疫情持续上升，, 另新增1例肠病毒71型并发重症病例。, 疾病管制署再次呼吁...      42   \n",
       "\n",
       "                                             Pred_List  \\\n",
       "1                                            [苏轼才20岁，]   \n",
       "2                                     [与弟弟苏辙一同进京参加会考，]   \n",
       "8                                        [范镇极辩苏轼贩盐之诬，]   \n",
       "12          [\\n绍圣元年（1094年）被哲宗贬谪至惠州、儋州（海南岛）。, 下诏让苏轼北还。]   \n",
       "13                                   [七月二十八日于常州孙氏馆病卒，]   \n",
       "..                                                 ...   \n",
       "829                     [青河毕业于越南河内国家大学法文系，, 青河得以持续进修，]   \n",
       "831                     [青河毕业于越南河内国家大学法文系，, 青河得以持续进修，]   \n",
       "867  [透过网购或国外带回的眼药水，, 并不属于我国合法药物，, 并不适用我国药害救济制度喔!\\n...   \n",
       "870  [以感染肠病毒71型为多(28例)，, 其他分别感染肠病毒D68型、克沙奇A6型、A10型(...   \n",
       "874                                       [疾病管制署再次呼吁，]   \n",
       "\n",
       "                                              Obs_List  \n",
       "1                              [嘉佑二年（1057年），, 苏轼才20岁，]  \n",
       "2                            [苏轼才20岁，, 与弟弟苏辙一同进京参加会考，]  \n",
       "8                              [范镇极辩苏轼贩盐之诬，, 并愿意退休负责。]  \n",
       "12   [\\n绍圣元年（1094年）被哲宗贬谪至惠州、儋州（海南岛）。, \\n元符三年（1100年）...  \n",
       "13                 [\\n建中靖国元年（1101年），, 七月二十八日于常州孙氏馆病卒，]  \n",
       "..                                                 ...  \n",
       "829   [青河毕业于越南河内国家大学法文系，, 青河得以持续进修，, 她不仅取得国立成功大学硕士学位，]  \n",
       "831   [青河毕业于越南河内国家大学法文系，, 青河得以持续进修，, 她不仅取得国立成功大学硕士学位，]  \n",
       "867  [透过网购或国外带回的眼药水，, 并不适用我国药害救济制度喔!\\n\\n       食药署为...  \n",
       "870  [今(2019)年累计37例肠病毒并发重症病例，, 以感染肠病毒71型为多(28例)，, 其...  \n",
       "874                                                 []  \n",
       "\n",
       "[93 rows x 5 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mismatch = training_data_with_performance[training_data_with_performance['Pred_List'] != training_data_with_performance['Obs_List']]\n",
    "train_mismatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "#20 (Pred:[9], Actual:[])\n",
    "\n",
    "Question:「阿拉伯之春」运动中，走上街头的民众的诉求为何? <br>\n",
    "Predicted SP: 只有突尼西亚成为阿拉伯之春中，<br>\n",
    "Actual: None\n",
    "\n",
    "Comment: While the predicted SP is incorrect, I found out that there is supporting evidence in the paragraph. (...要求推翻本国的专制政体的行动)This might be a case of incorrect input.\n",
    "\n",
    "#70 (Pred:[11], Actual:[])\n",
    "\n",
    "Question: 第二次签订的北美贸易协定从签署至生效过了几日? <br>\n",
    "Predicted SP: 美国、墨西哥和加拿大就更新北美自由贸易协定达成一致，<br>\n",
    "Actual: None\n",
    "\n",
    "Comment: Same as #20. (美国、加拿大及墨西哥在1992年8月12日签署了关于三国间全面贸易的协议。...，北美自由贸易协议于1994年1月1日正式生效。)\n",
    "\n",
    "#156 (Pred:[1], Actual:[])\n",
    "\n",
    "Question: 聊天机器人仰赖哪些方法让回答愈来愈准确? <br>\n",
    "Predicted SP: 麻省理工学院（MIT）人工智慧实验室早在1966年即研发出名为「Eliza」的机器人， <br>\n",
    "Actual: None <br>\n",
    "\n",
    "Comment: Same (聊天机器人的作答准确度要透过程式化的方法改善)\n",
    "\n",
    "#284 (Pred:[3], Actual:[])\n",
    "\n",
    "Question: 不可再生能源的意义是什么？ <br>\n",
    "Predicted SP: 许多这些形式可以很容易转化为另一种的帮助下， <br>\n",
    "Actual: None <br>\n",
    "\n",
    "Comment: Same (是无法经过短时间内再生的能源，而且它们的消耗速度远远超过它们再生的速度)\n",
    "\n",
    "#324 (Pred:[4], Actual:[])\n",
    "\n",
    "Question: 伊甸基金會成立的宗旨為何? <br>\n",
    "Predicted SP: 因著上帝的呼召及一颗爱身心障碍者的同理心，<br>\n",
    "Actual: None <br>\n",
    "\n",
    "Comment: No SP in the paragraph. But I think SP is pretty close to being a supporting evidence. This \n",
    "must be a borderline case.\n",
    "\n",
    "#370 (Pred:[12,25], Actual:[25])\n",
    "\n",
    "Question: 三大健康照护体系保险制度中，政府涉入程度低的是哪一种？<br>\n",
    "Predicted SP: 公医制（政府介入最多）：以英国为代表。 AND 自由市场（政府一般不介入）：以2013年前的美国为代表。<br>\n",
    "Actual: 公医制（政府介入最多）：以英国为代表。<br>\n",
    "\n",
    "Comment: I think this is a very reasonable mismatch. As two supporting evidences are very similar\n",
    "syntax-wise but drastically different in meaning.\n",
    "\n",
    "#371 (Pred:[12,25], Actual:[12])\n",
    "\n",
    "Question: 三大健康照護體系保險制度中，政府涉入程度高的是哪一種？ <br>\n",
    "Predicted SP: 公医制（政府介入最多）：以英国为代表。 AND 自由市场（政府一般不介入）：以2013年前的美国为代表。<br>\n",
    "Actual: 公医制（政府介入最多）：以英国为代表。<br>\n",
    "\n",
    "Comment: Same as #370\n",
    "\n",
    "#395 (Pred:[10], Actual:[])\n",
    "\n",
    "Question: 熬夜是否能减低得到癌症的风险? <br>\n",
    "Predicted SP: 皆强烈建议减少或避免动物性食品摄取， <br>\n",
    "Actual: None <br>\n",
    "\n",
    "Comment: Another potential case of incorrect input. In the paragraph I found this sentence (所以防癌守则：...，注重睡眠品质)\n",
    "\n",
    "#449 (Pred:[2], Actual:[])\n",
    "\n",
    "Question: 高屏地区国庆烟火试放管制时间是从晚上几点开始？ <br>\n",
    "Predicted SP: 屏东县政府表示24号当天屏东河滨公园将管制不开放， <br>\n",
    "Actual: None <br>\n",
    "\n",
    "Comment: Another similar case. This time I strongly believe this is an incorrect input. \n",
    "当晚7时并会进行全面清场 <- This is sufficient to be a supporting evidence\n",
    "\n",
    "#502 (Pred:[7], Actual:[])\n",
    "\n",
    "Question: 为何圣伯多禄大殿只能重建不能整修就好? <br>\n",
    "Predicted SP: 教宗犹利二世决定重建圣伯多禄大殿 <br>\n",
    "Actual: None \n",
    "\n",
    "Comment: Another similar case. (无疑再改动有机会让建筑倒塌)\n",
    "\n",
    "#630 (Pred:[62], Actual:[])\n",
    "\n",
    "Question: 毛笔、铅笔、钢笔，这三种笔中哪个笔尖的硬度高？ <br>\n",
    "Predicted SP: 更进一步看：我们无论使用那一种笔，<br>\n",
    "Actual: None <br>\n",
    "\n",
    "Comment: Again, I think this counts as a supporting evidence (钢笔的笔尖用金属制成，弹性大，硬度高)\n",
    "\n",
    "#731 (Pred:[9], Actual:[])\n",
    "\n",
    "Question: 为什么古埃及人要把死人做成木乃伊? <br>\n",
    "Predicted SP: 是做什么用的呢？ <br>\n",
    "Actual: None <br>\n",
    "\n",
    "Comment: I think this counts (古埃及人相信：人死后只要把遗体保存好，就可以在另一个世界得到永生。)\n",
    "\n",
    "#874 (Pred:[22], Actual:[])\n",
    "\n",
    "Question: 要如何降低肠病毒的传播风险？\n",
    "Predicted SP: 今(2019)年累计37例肠病毒并发重症病例，\n",
    "Actual: None\n",
    "\n",
    "Comment: No doubt, these are supporting evidences (应加强居家环境、教室及游乐设施等的通风、整洁与消毒，并教导学童落实「湿、搓、冲、捧、擦」正确洗手步骤，及生病在家休息等良好卫生观念，)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Data Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data_with_performance['dev_pred'] = dev_preds\n",
    "validation_data_with_performance['dev_obs'] = dev_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_sp = []\n",
    "for i in range(validation_data_with_performance.shape[0]):\n",
    "    para = validation_data_with_performance['Sentence_List'][i]\n",
    "    sen = []\n",
    "    for index in validation_data_with_performance['dev_pred'][i]:\n",
    "        sen.append(para[index])\n",
    "    correct_sp.append(sen)\n",
    "validation_data_with_performance['Pred_List'] = correct_sp\n",
    "correct_sp = []\n",
    "for i in range(validation_data_with_performance.shape[0]):\n",
    "    para = validation_data_with_performance['Sentence_List'][i]\n",
    "    sen = []\n",
    "    for index in validation_data_with_performance['dev_obs'][i]:\n",
    "        sen.append(para[index])\n",
    "    correct_sp.append(sen)\n",
    "validation_data_with_performance['Obs_List'] = correct_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data_with_performance.drop(['SE_Index', 'Label'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data_with_performance.drop(['Sentence_List', 'dev_pred', 'dev_obs'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_mismatch = validation_data_with_performance[validation_data_with_performance['Obs_List'] != validation_data_with_performance['Pred_List']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Length</th>\n",
       "      <th>Pred_List</th>\n",
       "      <th>Obs_List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>苏东坡在中国历史上，是哪一个朝代的人？</td>\n",
       "      <td>36</td>\n",
       "      <td>[苏轼（1037年1月8日－1101年8月24日），]</td>\n",
       "      <td>[苏轼（1037年1月8日－1101年8月24日），, 北宋时著名的文学家、政治家、艺术家、...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>苏东坡是中国哪个省份的人？</td>\n",
       "      <td>36</td>\n",
       "      <td>[苏轼（1037年1月8日－1101年8月24日），, 眉州眉山（今四川省眉山市）人，]</td>\n",
       "      <td>[苏轼（1037年1月8日－1101年8月24日），, 眉州眉山（今四川省眉山市）人，, 号...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>苏东坡的爸爸叫什么名字?</td>\n",
       "      <td>36</td>\n",
       "      <td>[苏轼（1037年1月8日－1101年8月24日），]</td>\n",
       "      <td>[苏轼（1037年1月8日－1101年8月24日），, 号东坡居士、铁冠道人。, 苏轼的散文...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>苏文忠公指的是谁?</td>\n",
       "      <td>36</td>\n",
       "      <td>[苏轼（1037年1月8日－1101年8月24日），]</td>\n",
       "      <td>[苏轼（1037年1月8日－1101年8月24日），, 加赐谥号文忠，]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>《苏文忠公全集》是由何人编纂？</td>\n",
       "      <td>36</td>\n",
       "      <td>[苏轼（1037年1月8日－1101年8月24日），, 编有《苏文忠公全集》。]</td>\n",
       "      <td>[宋人王宗稷收其作品，, 编有《苏文忠公全集》。]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>237</td>\n",
       "      <td>内政部消防署提出防范纵火方法「三从四得」，请问是哪「三从」?</td>\n",
       "      <td>33</td>\n",
       "      <td>[可以依照「三从四得」的方法防范纵火，, 民众可以依照「三从四得」的方法，, 防范居家或社区...</td>\n",
       "      <td>[\\n内政部表示，, 民众可以依照「三从四得」的方法，, 三从就是「从消除死角做起」、「从守...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>238</td>\n",
       "      <td>内政部消防署提出防范纵火方法「三从四得」，请问是哪「四得」?</td>\n",
       "      <td>33</td>\n",
       "      <td>[可以依照「三从四得」的方法防范纵火，, 民众可以依照「三从四得」的方法，, 防范居家或社区...</td>\n",
       "      <td>[\\n内政部表示，, 民众可以依照「三从四得」的方法，, 四得就是「可疑状况要认得」、「大门...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>244</td>\n",
       "      <td>这起诈骗案件的受害人是男性还是女性？</td>\n",
       "      <td>39</td>\n",
       "      <td>[经查系单身女子曾女数月前上网至「异性」交友网站，, 被骗曾姓女子信以为真，, 遂依指示至南...</td>\n",
       "      <td>[南港分局南港派出所于108年11月5日接获民众报案称其友人疑似遭受诈骗案件，, 经查系单身...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245</td>\n",
       "      <td>这起诈骗案件的诈骗金额是多少？</td>\n",
       "      <td>39</td>\n",
       "      <td>[警方查证后确认系一椿网路交友爱情诈骗案件，]</td>\n",
       "      <td>[南港分局南港派出所于108年11月5日接获民众报案称其友人疑似遭受诈骗案件，, 当日接获该...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246</td>\n",
       "      <td>这起诈骗案件中受害人与诈骗者是否见过面？</td>\n",
       "      <td>39</td>\n",
       "      <td>[南港分局南港派出所于108年11月5日接获民众报案称其友人疑似遭受诈骗案件，, 经查系单身...</td>\n",
       "      <td>[南港分局南港派出所于108年11月5日接获民众报案称其友人疑似遭受诈骗案件，, 结识不详外...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Question  Length  \\\n",
       "0               苏东坡在中国历史上，是哪一个朝代的人？      36   \n",
       "1                     苏东坡是中国哪个省份的人？      36   \n",
       "2                      苏东坡的爸爸叫什么名字?      36   \n",
       "3                         苏文忠公指的是谁?      36   \n",
       "4                   《苏文忠公全集》是由何人编纂？      36   \n",
       "..                              ...     ...   \n",
       "237  内政部消防署提出防范纵火方法「三从四得」，请问是哪「三从」?      33   \n",
       "238  内政部消防署提出防范纵火方法「三从四得」，请问是哪「四得」?      33   \n",
       "244              这起诈骗案件的受害人是男性还是女性？      39   \n",
       "245                 这起诈骗案件的诈骗金额是多少？      39   \n",
       "246            这起诈骗案件中受害人与诈骗者是否见过面？      39   \n",
       "\n",
       "                                             Pred_List  \\\n",
       "0                          [苏轼（1037年1月8日－1101年8月24日），]   \n",
       "1         [苏轼（1037年1月8日－1101年8月24日），, 眉州眉山（今四川省眉山市）人，]   \n",
       "2                          [苏轼（1037年1月8日－1101年8月24日），]   \n",
       "3                          [苏轼（1037年1月8日－1101年8月24日），]   \n",
       "4             [苏轼（1037年1月8日－1101年8月24日），, 编有《苏文忠公全集》。]   \n",
       "..                                                 ...   \n",
       "237  [可以依照「三从四得」的方法防范纵火，, 民众可以依照「三从四得」的方法，, 防范居家或社区...   \n",
       "238  [可以依照「三从四得」的方法防范纵火，, 民众可以依照「三从四得」的方法，, 防范居家或社区...   \n",
       "244  [经查系单身女子曾女数月前上网至「异性」交友网站，, 被骗曾姓女子信以为真，, 遂依指示至南...   \n",
       "245                            [警方查证后确认系一椿网路交友爱情诈骗案件，]   \n",
       "246  [南港分局南港派出所于108年11月5日接获民众报案称其友人疑似遭受诈骗案件，, 经查系单身...   \n",
       "\n",
       "                                              Obs_List  \n",
       "0    [苏轼（1037年1月8日－1101年8月24日），, 北宋时著名的文学家、政治家、艺术家、...  \n",
       "1    [苏轼（1037年1月8日－1101年8月24日），, 眉州眉山（今四川省眉山市）人，, 号...  \n",
       "2    [苏轼（1037年1月8日－1101年8月24日），, 号东坡居士、铁冠道人。, 苏轼的散文...  \n",
       "3                 [苏轼（1037年1月8日－1101年8月24日），, 加赐谥号文忠，]  \n",
       "4                            [宋人王宗稷收其作品，, 编有《苏文忠公全集》。]  \n",
       "..                                                 ...  \n",
       "237  [\\n内政部表示，, 民众可以依照「三从四得」的方法，, 三从就是「从消除死角做起」、「从守...  \n",
       "238  [\\n内政部表示，, 民众可以依照「三从四得」的方法，, 四得就是「可疑状况要认得」、「大门...  \n",
       "244  [南港分局南港派出所于108年11月5日接获民众报案称其友人疑似遭受诈骗案件，, 经查系单身...  \n",
       "245  [南港分局南港派出所于108年11月5日接获民众报案称其友人疑似遭受诈骗案件，, 当日接获该...  \n",
       "246  [南港分局南港派出所于108年11月5日接获民众报案称其友人疑似遭受诈骗案件，, 结识不详外...  \n",
       "\n",
       "[199 rows x 4 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'dev_mismatch' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store dev_mismatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT+LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FGC_LSTM_Network(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        \n",
    "        super(FGC_LSTM_Network, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-chinese')\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.h0 = nn.Parameter(torch.FloatTensor(hidden_size).uniform_(-0.1, 0.1))\n",
    "        self.c0 = nn.Parameter(torch.FloatTensor(hidden_size).uniform_(-0.1, 0.1))\n",
    "        self.linear = nn.Linear(hidden_size*2, 1) \n",
    "        # (H-state and c_state must be converted into 3d in forward function)\n",
    "        \n",
    "    def forward_nn(self, batch):    \n",
    "        # batch['ids'] = (batch_size*number of sentence, sent_len)\n",
    "        # batch['segment_ids'] = (batch_size*number of sentence, sent_len)\n",
    "        # batch['mask_ids'] = (batch_size*number of sentence, sent_len)\n",
    "        # pooler_output = (batch_size, 768)\n",
    "        # hidden_state = (batch_size, sent_len, 768)\n",
    "        # output = (batch_size, 1)\n",
    "        \n",
    "        #h0 = torch.zeros(self.num_layers*2, batch['ids'].shape[0], self.hidden_size).to(device)\n",
    "        #c0 = torch.zeros(self.num_layers*2, batch['ids'].shape[0], self.hidden_size).to(device)\n",
    "        \n",
    "        \n",
    "        batch_size = batch['ids'].shape[0]\n",
    "        max_sent_size = batch['ids'].shape[2]\n",
    "        \n",
    "        #h0 = self.h0.expand(batch_size, self.num_layers*2, -1)\n",
    "        #c0 = self.c0.expand(batch_size, self.num_layers*2, -1)\n",
    "        ids = batch['ids'].view(-1, max_sent_size)\n",
    "        mask_ids = batch['mask_ids'].view(-1, max_sent_size)\n",
    "        segment_ids = batch['segment_ids'].view(-1, max_sent_size)\n",
    "        \n",
    "        hidden_state, pooler_output = self.bert(ids, mask_ids, segment_ids)   \n",
    "        \n",
    "        hidden_state = hidden_state[:,0].view(batch_size, -1, 768)\n",
    "        \n",
    "        lstm_output, (hn, cn) = self.lstm(hidden_state)\n",
    "        \n",
    "        linear_output = self.linear(lstm_output).squeeze(-1)\n",
    "        \n",
    "        return linear_output\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        output = self.forward_nn(batch)\n",
    "        labels = batch['labels']\n",
    "        loss_fn = nn.BCEWithLogitsLoss(weight=batch['sentence_mask'])\n",
    "        loss = loss_fn(output, labels)\n",
    "        return loss\n",
    "     \n",
    "    \"\"\"\n",
    "    def loss_fn(self, batch):\n",
    "        \n",
    "        batch_size = batch['ids'].shape[0]\n",
    "        \n",
    "        if torch.zeros(max(size_list) - min(size_list), batch.shape[2]) in batch:\n",
    "            loss_fn = nn.BCEWithLogitsLoss(w)\n",
    "            \n",
    "        else:\n",
    "            loss_fn = nn.BCEWithLogitsLoss()\n",
    "        output = self.forward(batch)\n",
    "        target = batch['labels'].float().to(device)\n",
    "        \n",
    "        return loss_fn(output, target)\n",
    "    \"\"\"\n",
    "    \n",
    "    def _predict(self, batch):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = self.forward_nn(batch)\n",
    "            scores = torch.sigmoid(output)\n",
    "            scores = scores.cpu().numpy().tolist()\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    def predict_fgc(self, batch, threshold=0.5):\n",
    "        scores = self._predict(batch)\n",
    "        max_i = 0\n",
    "        max_score = 0\n",
    "        sp = []\n",
    "\n",
    "        for i, score in enumerate(scores[0]):\n",
    "\n",
    "            if score > max_score:\n",
    "                max_i = i\n",
    "                max_score = score\n",
    "            if score >= threshold:\n",
    "                sp.append(i)\n",
    "\n",
    "        # This is to ensure there's no empty supporting evidences\n",
    "        if not sp:\n",
    "            sp.append(max_i)\n",
    "        return {'sp': sp, 'sp_scores': scores}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT+Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bertAgg(nn.Module):\n",
    "    \n",
    "    def __init__(self, number_of_sentence, max_sentence_length, baseline):\n",
    "        \n",
    "        super(bertAgg, self).__init__()\n",
    "        self.max_sentence_length = max_sentence_length\n",
    "        self.number_of_sentence = number_of_sentence\n",
    "        baseline.load_state_dict(torch.load(\"Models/baseline_models_with_scheduler/model_epoch8_eval_em:0.198_precision:0.603_recall:0.588_f1:0.545_loss:0.031.m\"))\n",
    "        self.baseline = baseline\n",
    "        self.bert = BertModel.from_pretrained('bert-base-chinese')\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.linearAgg = nn.Linear(1536, 1)\n",
    "        self.qsLinear = nn.Linear(1536, 1)\n",
    "        \n",
    "    def forward_nn(self, batch):\n",
    "        \n",
    "        # Sent objects into CUDA\n",
    "        for key in batch:\n",
    "            if key == 'labels':\n",
    "                batch[key] = batch[key].to(device).to(torch.float)\n",
    "            else:\n",
    "                batch[key] = batch[key].to(device).to(torch.long)\n",
    "\n",
    "        batch_size = batch['ids'].shape[0]\n",
    "        padded_zeros = torch.tensor([0] * self.number_of_sentence)\n",
    "        \n",
    "        \n",
    "        # Sent sentences into BERT embeddings\n",
    "        sentence_ids = batch['ids'].view(-1, self.max_sentence_length)\n",
    "        sentence_mask_ids = batch['mask_ids'].view(-1, self.max_sentence_length) #(batch, 5)\n",
    "        sentence_hidden_state, sentence_pooler_output = self.baseline.bert(sentence_ids, sentence_mask_ids)   \n",
    "        \n",
    "        # Sent question into BERT embeddings\n",
    "        question_ids = batch['q_ids']\n",
    "        question_mask_ids = batch['q_mask_ids']\n",
    "        question_hidden_state, question_pooler_output = self.baseline.bert(question_ids, question_mask_ids) # (batch, 768)\n",
    "      \n",
    "        sentence_mask = batch['sentence_mask']\n",
    "        sentence_mask = sentence_mask.type(torch.float)\n",
    "        \n",
    "        # Aggregate\n",
    "        sentence_pooler_output = sentence_pooler_output.view(batch_size, -1, 768) # (batch, 5, 768)\n",
    "        \n",
    "        target_sentence = sentence_pooler_output[:, self.number_of_sentence // 2, :].unsqueeze(1) # (batch, 1, 768)\n",
    "        target_sentence = target_sentence.expand(-1, self.number_of_sentence, -1) # (batch, 5, 768)\n",
    "        \n",
    "        concatenated = torch.cat((target_sentence, sentence_pooler_output), dim=-1) # (batch, 5, 768*2)\n",
    "        att_weight = self.linearAgg(concatenated) + (1.0 - sentence_mask) * -10000 #\n",
    "        #if sentence_pooler_output\n",
    "        att_weight = self.softmax(att_weight) # (batch, 5)\n",
    "        aggregated_sentence = torch.matmul(att_weight.transpose(1,2), sentence_pooler_output) # (batch, 1, 768)\n",
    "        aggregated_sentence = aggregated_sentence.squeeze(1) # (batch, 768)\n",
    "\n",
    "        # Concatenate question to aggregated sentence\n",
    "        qs_concatenated = torch.cat((aggregated_sentence, question_pooler_output), dim=-1) # (batch, 1536)\n",
    "        final_output = self.qsLinear(qs_concatenated) # (batch, 1)\n",
    "        return final_output, att_weight#final_output, att_weight\n",
    "        \n",
    "        \n",
    "        \n",
    "#         for i in range(batch_size):\n",
    "            \n",
    "#             mini_batch = sentence_pooler_output[i]\n",
    "#             # Aggregate sentence weights\n",
    "#             target_sentence = sentence_pooler_output[i, self.number_of_sentence // 2, :]\n",
    "#             target_sentence_clone = target_sentence.expand(self.number_of_sentence, 768)\n",
    "#             concatenated = torch.cat((mini_batch, target_sentence_clone), dim=1)\n",
    "#             target_sentence_aggregated = torch.sum(self.linearAgg(concatenated) * mini_batch, dim=0)\n",
    "            \n",
    "#             # Question sentence feedforward\n",
    "#             question_to_concat = question_pooler_output[i]\n",
    "#             qs_concatenated = torch.cat((target_sentence_aggregated, question_to_concat))\n",
    "#             final_output = self.linearAgg(qs_concatenated).squeeze(-1)\n",
    "#             batch_output.append(final_output)\n",
    "        \n",
    "        \n",
    "#         return torch.tensor(batch_output).reshape(batch_size, 1).to(device)\n",
    "        \n",
    "        \n",
    "    def forward(self, batch):\n",
    "        \n",
    "        output, _ = self.forward_nn(batch)\n",
    "        labels = batch['labels']\n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "        loss = loss_fn(output, labels)\n",
    "        #print(batch['ids'], output, _)\n",
    "        #print(tokenizer.convert_ids_to_tokens(batch['ids'][0][2].tolist()))\n",
    "        #print(tokenizer.convert_ids_to_tokens(batch['ids'][1][2].tolist()))\n",
    "        #print(batch['ids'])\n",
    "        #print(output, labels)\n",
    "        #print(loss)\n",
    "        return loss\n",
    "    \n",
    "    def _predict(self, batch):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            output, att_weight = self.forward_nn(batch)\n",
    "            scores = torch.sigmoid(output)\n",
    "            scores = scores.cpu().numpy().tolist()\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    def predict_fgc(self, batch, threshold=0.5):\n",
    "        scores = self._predict(batch)\n",
    "        max_i = 0\n",
    "        max_score = 0\n",
    "        sp = []\n",
    "\n",
    "        for i, score in enumerate(scores[0]):\n",
    "\n",
    "            if score > max_score:\n",
    "                max_i = i\n",
    "                max_score = score\n",
    "            if score >= threshold:\n",
    "                sp.append(i)\n",
    "\n",
    "        # This is to ensure there's no empty supporting evidences\n",
    "        if not sp:\n",
    "            sp.append(max_i)\n",
    "        return {'sp': sp, 'sp_scores': scores}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline+Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-122-139763ecbec2>, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-122-139763ecbec2>\"\u001b[0;36m, line \u001b[0;32m22\u001b[0m\n\u001b[0;31m    mask_ids =\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class baselineAgg(nn.Module):\n",
    "\n",
    "    def __init__(self, number_of_sentence, max_sentence_length, BMPATH):\n",
    "        \n",
    "        super(bertAgg, self).__init__()\n",
    "        self.max_sentence_length = max_sentence_length\n",
    "        self.number_of_sentence = number_of_sentence\n",
    "        self.baseline = baseline_model().load_state_dict(torch.load(BMPATH))\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward_nn(self, batch):\n",
    "        # batch = (batch_size, sentence length)\n",
    "        # pooler_output = (batch_size, 768)\n",
    "        # Sent objects into CUDA\n",
    "        for key in batch:\n",
    "            if key == 'labels':\n",
    "                batch[key] = batch[key].to(device).to(torch.float)\n",
    "            else:\n",
    "                batch[key] = batch[key].to(device).to(torch.long)\n",
    "\n",
    "        ids = batch['ids'].view(-1, self.max_sentence_length)\n",
    "        mask_ids = \n",
    "        hidden_state, pooler_output = self.baseline.bert(batch['ids'], batch['mask_ids'], batch['segment_ids'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0811 07:59:12.381575 139897081689920 configuration_utils.py:152] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json from cache at /root/.cache/torch/transformers/8a3b1cfe5da58286e12a0f5d7d182b8d6eca88c08e26c332ee3817548cf7e60a.f12a4f986e43d8b328f5b067a641064d67b91597567a06c7b122d1ca7dfd9741\n",
      "I0811 07:59:12.386453 139897081689920 configuration_utils.py:169] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "I0811 07:59:13.261365 139897081689920 modeling_utils.py:387] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-pytorch_model.bin from cache at /root/.cache/torch/transformers/b1b5e295889f2d0979ede9a78ad9cb5dc6a0e25ab7f9417b315f0a2c22f4683d.929717ca66a3ba9eb9ec2f85973c6398c54c38a4faa464636a491d7a705f7eb6\n"
     ]
    }
   ],
   "source": [
    "new_network = bertAgg(3, 250, baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bertAgg(\n",
       "  (baseline): baseline_model(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (linear): Linear(in_features=768, out_features=1, bias=True)\n",
       "  )\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (softmax): Softmax()\n",
       "  (linearAgg): Linear(in_features=1536, out_features=1, bias=True)\n",
       "  (qsLinear): Linear(in_features=1536, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_network.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_val_batches = eval_preprocessing(validation_data, dev_dataset)\n",
    "for data in test_val_batches:\n",
    "    data['ids'] = data['ids'].unsqueeze(0)\n",
    "    data['mask_ids'] = data['mask_ids'].unsqueeze(0)\n",
    "    data['segment_ids'] = data['segment_ids'].unsqueeze(0)\n",
    "    data['labels'] = data['labels'].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_model_eval(new_network, test_val_batches, 0, validation_data['QUESTIONS'].apply(lambda x: x[0]['SHINT_']).tolist(), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Improved Model & Evaluating Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_model_optim(nn, num_epochs, lr, dataloader):\n",
    "    param_optimizer = list(nn.bert.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "    num_epochs = num_epochs\n",
    "    num_train_optimization_steps = len(dataloader) * num_epochs\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=lr)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                     num_warmup_steps=int(\n",
    "                                                         num_train_optimization_steps * 0.1),\n",
    "                                                     num_training_steps=num_train_optimization_steps)\n",
    "    return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _update_sp(metrics, sp_gold, sp_pred):\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "        \n",
    "    for p in sp_pred:\n",
    "        if p in sp_gold:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "    for g in sp_gold:\n",
    "        if g not in sp_pred:\n",
    "            fn += 1\n",
    "            \n",
    "    precision = 1.0 * tp / (tp + fp) if tp + fp > 0 else 0.0\n",
    "    recall = 1.0 * tp / (tp + fn) if tp + fn > 0 else 0.0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0.0\n",
    "    em = 1.0 if fp + fn == 0 else 0.0\n",
    "    \n",
    "    metrics['sp_em'] += em\n",
    "    metrics['sp_f1'] += f1\n",
    "    metrics['sp_prec'] += precision\n",
    "    metrics['sp_recall'] += recall\n",
    "    \n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_sp_fgc(sp_golds, sp_preds):\n",
    "    \n",
    "    metrics = {'sp_em': 0, 'sp_prec': 0, 'sp_recall': 0, 'sp_f1': 0}\n",
    "    \n",
    "    assert len(sp_golds) == len(sp_preds)\n",
    "    \n",
    "    for sp_gold, sp_pred in zip(sp_golds, sp_preds):\n",
    "        _update_sp(metrics, sp_gold, sp_pred)\n",
    "    \n",
    "    N = len(sp_golds)\n",
    "    for k in metrics.keys():\n",
    "        metrics[k] /= N\n",
    "        metrics[k] = round(metrics[k], 3)\n",
    "    print(metrics)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_model_eval(network, train_batches, dev_batches, current_epoch, train_sp_golds, dev_sp_golds, avg_loss):\n",
    "    \n",
    "    network.eval()\n",
    "    with torch.no_grad():\n",
    "        dev_sp_preds = []\n",
    "        train_sp_preds = []\n",
    "        \n",
    "        for batch in tqdm(dev_batches):\n",
    "            out_dct= network.predict_fgc(batch)\n",
    "    \n",
    "            dev_sp_preds.append(out_dct['sp'])\n",
    "            print(out_dct['sp'])\n",
    "        \n",
    "        for batch in tqdm(train_batches):\n",
    "            train_dct = network.predict_fgc(batch)\n",
    "            train_sp_preds.append(train_dct['sp'])\n",
    "            print(train_dct['sp'])\n",
    "            \n",
    "    dev_metrics = eval_sp_fgc(dev_sp_golds, dev_sp_preds)\n",
    "    train_metrics = eval_sp_fgc(train_sp_golds, train_sp_preds)\n",
    "    \n",
    "    print('epoch %d eval_recall: %.3f eval_f1: %.3f loss: %.3f' % (\n",
    "            current_epoch, dev_metrics['sp_recall'], dev_metrics['sp_f1'], avg_loss))\n",
    "    \n",
    "    print('epoch %d eval_recall: %.3f eval_f1: %.3f loss: %.3f' % (\n",
    "            current_epoch, train_metrics['sp_recall'], train_metrics['sp_f1'], avg_loss))\n",
    "    #torch.save(network.state_dict(), \"New_Models/model_epoch{0}_eval_em:{1:.3f}_precision:{2:.3f}_recall:{3:.3f}_f1:{4:.3f}_loss:{5:.3f}.m\".format(current_epoch, metrics['sp_em'], metrics['sp_prec'], metrics['sp_recall'], metrics['sp_f1'], avg_loss))\n",
    "    \n",
    "    return #sp_preds, sp_golds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_model_train(network, dataloader, train_batches, dev_batches, num_epochs, lr):\n",
    "    \n",
    "    optimizer, scheduler = new_model_optim(network, num_epochs, lr, dataloader)\n",
    "    \n",
    "    train_sp_golds = training_data['QUESTIONS'].apply(lambda x: x[0]['SHINT_']).tolist()\n",
    "    dev_sp_golds = validation_data['QUESTIONS'].apply(lambda x: x[0]['SHINT_']).tolist()\n",
    "    \n",
    "    for current_epoch in range(num_epochs):\n",
    "        network.train()\n",
    "        running_loss = 0.0\n",
    "        for batch in tqdm(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            current_loss = network(batch)\n",
    "\n",
    "            current_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(network.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            running_loss += current_loss.item()\n",
    "            \n",
    "        learning_rate_scalar = scheduler.get_lr()[0]\n",
    "        print('lr = %f' % learning_rate_scalar)\n",
    "        avg_loss = running_loss/len(dataloader)\n",
    "        print('epoch %d train_loss: %.3f' % (current_epoch, avg_loss))\n",
    "        new_model_eval(network, train_batches, dev_batches, current_epoch, train_sp_golds, dev_sp_golds, avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "sent_dev_batches = sent_eval_preprocessing(validation_data, sent_dev_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "sent_train_batches = sent_eval_preprocessing(training_data, sent_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e618ea52fd478c9802b9b3cc463bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=247), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30a7561b02f8484faa3ca704eb4f1430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=882), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-7e3b2badd48c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_sp_golds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'QUESTIONS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SHINT_'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdev_sp_golds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'QUESTIONS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SHINT_'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnew_model_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_train_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_dev_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_sp_golds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_sp_golds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-101-2d3751a0ad8f>\u001b[0m in \u001b[0;36mnew_model_eval\u001b[0;34m(network, train_batches, dev_batches, current_epoch, train_sp_golds, dev_sp_golds, avg_loss)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mtrain_dct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_fgc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mtrain_sp_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-121-f8c5729b8a9e>\u001b[0m in \u001b[0;36mpredict_fgc\u001b[0;34m(self, batch, threshold)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_fgc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mmax_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mmax_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-121-f8c5729b8a9e>\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matt_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_sp_golds = training_data['QUESTIONS'].apply(lambda x: x[0]['SHINT_']).tolist()\n",
    "dev_sp_golds = validation_data['QUESTIONS'].apply(lambda x: x[0]['SHINT_']).tolist()\n",
    "new_model_eval(new_network, sent_train_batches, sent_dev_batches, 0, dev_sp_golds, train_sp_golds, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45844c6668d94bf38862eb09e96b00a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7856), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr = 0.000010\n",
      "epoch 0 train_loss: 0.267\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1f26adb820349d88ad8ce5cd578d36b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=247), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00748c1af8a2445b9311b180080a7a64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=882), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sp_em': 0.04, 'sp_prec': 0.259, 'sp_recall': 0.132, 'sp_f1': 0.168}\n",
      "{'sp_em': 0.065, 'sp_prec': 0.279, 'sp_recall': 0.151, 'sp_f1': 0.185}\n",
      "epoch 0 eval_recall: 0.132 eval_f1: 0.168 loss: 0.267\n",
      "epoch 0 eval_recall: 0.151 eval_f1: 0.185 loss: 0.267\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84f6064981cf4f3d91346f1b1ab776f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7856), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr = 0.000020\n",
      "epoch 1 train_loss: 0.270\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4bc7c7332c9417b8739766bc5ec0bf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=247), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70dae450b515485aafbae14c7b531f6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=882), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sp_em': 0.04, 'sp_prec': 0.259, 'sp_recall': 0.132, 'sp_f1': 0.168}\n",
      "{'sp_em': 0.065, 'sp_prec': 0.279, 'sp_recall': 0.151, 'sp_f1': 0.185}\n",
      "epoch 1 eval_recall: 0.132 eval_f1: 0.168 loss: 0.270\n",
      "epoch 1 eval_recall: 0.151 eval_f1: 0.185 loss: 0.270\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e90bef4e0ca6407ca7d24a1b6f420327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7856), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-176ad9f60736>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_model_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_sent_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_train_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_dev_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.00002\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-69-f84f64c20588>\u001b[0m in \u001b[0;36mnew_model_train\u001b[0;34m(network, dataloader, train_batches, dev_batches, num_epochs, lr)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mcurrent_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "new_model_train(new_network, dataloader_sent_train, sent_train_batches, sent_dev_batches, 20, 0.00002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dev_batches = window_sentence_preprocessing(validation_data, dev_dataset, 10)\n",
    "testing_dev_batches = DataLoader(new_dev_batches, batch_size=2, shuffle = False, collate_fn = collate_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MUST DO THIS BEFORE EVALUATING \n",
    "eval_train_batches = eval_preprocessing(training_data, train_dataset)\n",
    "for data in eval_train_batches:\n",
    "    data['ids'] = data['ids'].unsqueeze(0)\n",
    "    data['mask_ids'] = data['mask_ids'].unsqueeze(0)\n",
    "    data['segment_ids'] = data['segment_ids'].unsqueeze(0)\n",
    "    data['labels'] = data['labels'].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cdcac7fd2374199b4951e8018a587f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=882), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.085, 'sp_prec': 0.3, 'sp_recall': 0.172, 'sp_f1': 0.206}\n",
      "epoch 0 eval_recall: 0.172 eval_f1: 0.206 loss: 0.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[18],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [5],\n",
       " [7, 8, 9, 10, 11, 12, 13, 14],\n",
       " [22, 23],\n",
       " [27],\n",
       " [26, 30],\n",
       " [33, 34],\n",
       " [1, 3, 4, 5, 6],\n",
       " [5, 7],\n",
       " [7],\n",
       " [7, 8, 11],\n",
       " [12, 17],\n",
       " [11, 17],\n",
       " [11, 19],\n",
       " [23],\n",
       " [25, 28, 30],\n",
       " [25, 28],\n",
       " [16, 17],\n",
       " [],\n",
       " [9, 10],\n",
       " [9, 11, 13],\n",
       " [0, 2, 6],\n",
       " [0],\n",
       " [0, 14, 16],\n",
       " [0, 14, 16],\n",
       " [0, 14, 16, 17, 20, 21, 24, 25, 27, 29],\n",
       " [0, 14, 17],\n",
       " [0, 14, 20, 21],\n",
       " [0, 14, 24, 25],\n",
       " [0, 14, 27],\n",
       " [0, 14, 29],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [0, 1, 8, 11],\n",
       " [0, 1, 8, 11, 12, 14],\n",
       " [15],\n",
       " [5, 6],\n",
       " [9, 16],\n",
       " [11, 16],\n",
       " [11, 16],\n",
       " [11, 16],\n",
       " [0, 2],\n",
       " [8, 9],\n",
       " [8, 9],\n",
       " [0],\n",
       " [0, 1],\n",
       " [0, 4],\n",
       " [0, 6, 7, 8, 9],\n",
       " [0, 6, 7, 8, 9],\n",
       " [18, 21],\n",
       " [14],\n",
       " [14, 15],\n",
       " [21, 23, 24],\n",
       " [0, 2],\n",
       " [3],\n",
       " [0, 4, 5],\n",
       " [0, 4],\n",
       " [6],\n",
       " [11, 12],\n",
       " [11, 12],\n",
       " [11, 12],\n",
       " [11],\n",
       " [0],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [10, 11],\n",
       " [11, 12, 13, 14],\n",
       " [],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [0, 4],\n",
       " [0, 41],\n",
       " [0, 41],\n",
       " [0, 25, 41],\n",
       " [0, 5, 7],\n",
       " [0, 8],\n",
       " [0, 7],\n",
       " [0, 8],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [3, 4],\n",
       " [3, 4],\n",
       " [5, 6, 7, 8],\n",
       " [5, 6, 8],\n",
       " [9, 10],\n",
       " [9, 10],\n",
       " [9, 10],\n",
       " [9, 10],\n",
       " [11, 12, 13],\n",
       " [11, 12, 14],\n",
       " [2, 3],\n",
       " [2, 3],\n",
       " [4, 5],\n",
       " [6, 8, 9],\n",
       " [6, 8, 9],\n",
       " [5, 6, 8, 9],\n",
       " [12, 14, 15],\n",
       " [12, 14, 15],\n",
       " [0, 1, 2],\n",
       " [3, 4],\n",
       " [3, 4, 5],\n",
       " [7, 11],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [21],\n",
       " [20, 21],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [7, 8],\n",
       " [8, 9],\n",
       " [9, 10],\n",
       " [10, 11],\n",
       " [11, 12],\n",
       " [12, 13],\n",
       " [13, 14],\n",
       " [14, 15],\n",
       " [0, 1, 3, 4],\n",
       " [6, 7],\n",
       " [0, 4],\n",
       " [0, 5],\n",
       " [0],\n",
       " [0, 1],\n",
       " [5],\n",
       " [5],\n",
       " [5],\n",
       " [5],\n",
       " [9],\n",
       " [9, 10, 11, 27],\n",
       " [10, 12],\n",
       " [0, 10, 13],\n",
       " [27],\n",
       " [0, 1, 22],\n",
       " [16],\n",
       " [32],\n",
       " [0, 5],\n",
       " [5, 6],\n",
       " [10],\n",
       " [1, 3],\n",
       " [1, 4],\n",
       " [5, 30, 33, 37],\n",
       " [9],\n",
       " [10, 13],\n",
       " [0, 1, 23, 24, 26],\n",
       " [1, 4],\n",
       " [1, 4],\n",
       " [1, 2, 4],\n",
       " [5, 6],\n",
       " [1, 23, 24],\n",
       " [24],\n",
       " [],\n",
       " [7, 8],\n",
       " [9, 10],\n",
       " [16, 17],\n",
       " [18, 19],\n",
       " [25, 26],\n",
       " [27, 28],\n",
       " [25, 26],\n",
       " [25, 26],\n",
       " [27, 28],\n",
       " [27, 28],\n",
       " [8, 10, 11, 12],\n",
       " [30, 32, 33],\n",
       " [32, 33],\n",
       " [30, 31],\n",
       " [30],\n",
       " [32, 33],\n",
       " [30, 31],\n",
       " [0],\n",
       " [7, 8],\n",
       " [0],\n",
       " [6, 7, 10],\n",
       " [7],\n",
       " [0, 1, 5],\n",
       " [0, 1, 5, 7],\n",
       " [0, 18, 19],\n",
       " [0, 1, 5, 18, 19],\n",
       " [0],\n",
       " [0, 5],\n",
       " [0, 39],\n",
       " [33, 35],\n",
       " [0, 43, 44, 45, 48],\n",
       " [0, 9],\n",
       " [0, 39],\n",
       " [22, 23, 24],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [46, 49],\n",
       " [0],\n",
       " [0],\n",
       " [0, 11],\n",
       " [0, 11, 12],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [1, 3],\n",
       " [1, 6],\n",
       " [1, 8, 9, 11],\n",
       " [0, 1],\n",
       " [0, 1, 5],\n",
       " [0, 1],\n",
       " [8, 9],\n",
       " [8, 9],\n",
       " [0, 9, 12],\n",
       " [0, 6],\n",
       " [0],\n",
       " [0],\n",
       " [0, 10],\n",
       " [0, 12, 13],\n",
       " [0, 32, 33],\n",
       " [0, 32, 33],\n",
       " [0, 32, 33],\n",
       " [0, 14],\n",
       " [39],\n",
       " [0, 40],\n",
       " [0],\n",
       " [39, 43],\n",
       " [39, 40],\n",
       " [0, 35],\n",
       " [39, 42],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0, 1],\n",
       " [8, 9],\n",
       " [19],\n",
       " [21, 26, 34],\n",
       " [40, 41, 42, 43],\n",
       " [0],\n",
       " [9, 11, 12],\n",
       " [9, 12],\n",
       " [0, 1],\n",
       " [1, 9, 13],\n",
       " [19, 20, 31],\n",
       " [19],\n",
       " [19],\n",
       " [0, 2, 3, 4],\n",
       " [0, 34, 35],\n",
       " [0, 1, 21],\n",
       " [0, 3, 21, 22],\n",
       " [0, 4],\n",
       " [0, 21, 22, 24],\n",
       " [0, 1, 12, 15],\n",
       " [0, 1, 11, 12],\n",
       " [20],\n",
       " [27, 28],\n",
       " [27, 28],\n",
       " [27, 28],\n",
       " [0],\n",
       " [0, 1],\n",
       " [2, 3],\n",
       " [9, 10],\n",
       " [11, 12],\n",
       " [18, 19],\n",
       " [27, 28],\n",
       " [29, 30],\n",
       " [18, 19, 20, 21],\n",
       " [0],\n",
       " [1, 2],\n",
       " [0, 9, 10],\n",
       " [6],\n",
       " [0, 12],\n",
       " [1, 14, 15],\n",
       " [14, 16],\n",
       " [0, 1],\n",
       " [1],\n",
       " [11],\n",
       " [11],\n",
       " [2, 3],\n",
       " [4],\n",
       " [11],\n",
       " [11],\n",
       " [15],\n",
       " [11],\n",
       " [0, 1, 2],\n",
       " [6],\n",
       " [],\n",
       " [12],\n",
       " [16, 20],\n",
       " [12],\n",
       " [16, 17, 20],\n",
       " [0, 6],\n",
       " [0, 10],\n",
       " [0, 10, 34, 38, 40],\n",
       " [17, 21],\n",
       " [12, 13, 17],\n",
       " [14, 15],\n",
       " [35, 37],\n",
       " [4, 15],\n",
       " [31],\n",
       " [56],\n",
       " [49, 55],\n",
       " [11, 15],\n",
       " [1],\n",
       " [2, 4],\n",
       " [2, 7],\n",
       " [2, 8],\n",
       " [10, 12],\n",
       " [14],\n",
       " [15, 16],\n",
       " [16],\n",
       " [28, 29, 30],\n",
       " [29],\n",
       " [30],\n",
       " [35, 37, 49],\n",
       " [2, 3, 5, 6, 13, 14],\n",
       " [9, 10],\n",
       " [9, 10],\n",
       " [9, 10],\n",
       " [9, 10],\n",
       " [9, 10],\n",
       " [9, 10],\n",
       " [22, 28],\n",
       " [35],\n",
       " [35],\n",
       " [50],\n",
       " [],\n",
       " [3, 7],\n",
       " [7],\n",
       " [0, 1, 15, 16, 17, 18, 19],\n",
       " [7],\n",
       " [24],\n",
       " [14, 15],\n",
       " [29, 30, 35, 36, 39],\n",
       " [0, 3],\n",
       " [19, 20],\n",
       " [0, 4, 39],\n",
       " [4],\n",
       " [2],\n",
       " [0],\n",
       " [22],\n",
       " [0, 15, 16],\n",
       " [0, 16],\n",
       " [0, 17],\n",
       " [0],\n",
       " [5],\n",
       " [0, 15],\n",
       " [0, 15],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [1, 13],\n",
       " [12],\n",
       " [17],\n",
       " [0, 4],\n",
       " [0, 20, 21],\n",
       " [21, 27],\n",
       " [43, 44, 45, 48],\n",
       " [0, 43, 44],\n",
       " [0],\n",
       " [0, 1],\n",
       " [8, 9],\n",
       " [6, 8, 10, 14, 16],\n",
       " [32, 33],\n",
       " [34, 35],\n",
       " [14, 15],\n",
       " [23, 24],\n",
       " [1, 2, 12, 25],\n",
       " [2, 12, 25],\n",
       " [2],\n",
       " [2, 3, 4],\n",
       " [12, 15],\n",
       " [25, 26],\n",
       " [25],\n",
       " [12],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0, 2, 4, 5],\n",
       " [11],\n",
       " [12, 14],\n",
       " [18, 19],\n",
       " [16, 17],\n",
       " [12],\n",
       " [12],\n",
       " [14],\n",
       " [0, 1, 2],\n",
       " [3],\n",
       " [4],\n",
       " [10, 11],\n",
       " [10, 11],\n",
       " [11],\n",
       " [7, 8],\n",
       " [11],\n",
       " [11],\n",
       " [11],\n",
       " [11],\n",
       " [],\n",
       " [0, 1, 4],\n",
       " [7, 12],\n",
       " [13],\n",
       " [4, 6],\n",
       " [4, 6],\n",
       " [4, 6],\n",
       " [4, 8],\n",
       " [19],\n",
       " [0, 7],\n",
       " [17, 18, 19],\n",
       " [3],\n",
       " [7, 9],\n",
       " [7, 8],\n",
       " [7, 14],\n",
       " [20, 21],\n",
       " [8, 9],\n",
       " [0, 3, 4],\n",
       " [3, 9],\n",
       " [1, 3],\n",
       " [1, 2, 3],\n",
       " [15, 17],\n",
       " [16],\n",
       " [4, 6, 9],\n",
       " [0, 5],\n",
       " [0, 9],\n",
       " [10, 11],\n",
       " [0, 1],\n",
       " [9, 12],\n",
       " [9, 12],\n",
       " [17],\n",
       " [0, 28, 29],\n",
       " [0, 1, 2, 5, 9],\n",
       " [0, 1, 5, 9],\n",
       " [4, 5, 6, 7],\n",
       " [14, 15, 18],\n",
       " [22],\n",
       " [9],\n",
       " [27, 28],\n",
       " [27, 28, 29],\n",
       " [27, 28],\n",
       " [0, 2],\n",
       " [0, 5],\n",
       " [8],\n",
       " [12, 13],\n",
       " [12, 13],\n",
       " [12, 13, 14],\n",
       " [13, 14],\n",
       " [0],\n",
       " [0, 2],\n",
       " [0, 8],\n",
       " [5],\n",
       " [5, 6],\n",
       " [0],\n",
       " [],\n",
       " [0, 1, 7, 12],\n",
       " [3, 4],\n",
       " [9],\n",
       " [4, 9],\n",
       " [2, 3],\n",
       " [19, 20],\n",
       " [27, 28],\n",
       " [0, 1],\n",
       " [21, 22],\n",
       " [9, 10],\n",
       " [2],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [0, 22],\n",
       " [19],\n",
       " [10, 19],\n",
       " [0],\n",
       " [0, 2],\n",
       " [2],\n",
       " [0, 1],\n",
       " [0, 7],\n",
       " [0, 4, 6, 7],\n",
       " [0, 4],\n",
       " [2],\n",
       " [0],\n",
       " [2],\n",
       " [2],\n",
       " [2],\n",
       " [3, 8, 14, 20],\n",
       " [0, 3],\n",
       " [2, 3],\n",
       " [3, 4],\n",
       " [3, 20, 22],\n",
       " [27],\n",
       " [20, 22, 31],\n",
       " [3, 31, 33],\n",
       " [1],\n",
       " [10, 12, 13, 17],\n",
       " [3],\n",
       " [7],\n",
       " [3, 4],\n",
       " [8, 9],\n",
       " [0, 6, 9],\n",
       " [0, 3, 9],\n",
       " [0, 6, 7, 9],\n",
       " [0, 9, 11],\n",
       " [0, 9, 20],\n",
       " [0, 9, 27],\n",
       " [7, 9],\n",
       " [7, 10],\n",
       " [11, 16, 17, 18],\n",
       " [7, 12, 13, 14, 15, 17],\n",
       " [],\n",
       " [0, 2],\n",
       " [0, 2],\n",
       " [0, 1, 3],\n",
       " [0],\n",
       " [0, 4],\n",
       " [0, 4],\n",
       " [0, 5],\n",
       " [0, 4, 5],\n",
       " [0, 7, 10, 11],\n",
       " [11, 13],\n",
       " [11, 13],\n",
       " [11, 13],\n",
       " [11, 13],\n",
       " [5],\n",
       " [6],\n",
       " [0],\n",
       " [4, 5],\n",
       " [4, 5],\n",
       " [0],\n",
       " [0],\n",
       " [10],\n",
       " [1, 10, 11],\n",
       " [4, 7],\n",
       " [8],\n",
       " [15],\n",
       " [14],\n",
       " [10, 18],\n",
       " [0],\n",
       " [0, 1],\n",
       " [13],\n",
       " [2],\n",
       " [3],\n",
       " [1],\n",
       " [4, 5],\n",
       " [8],\n",
       " [9],\n",
       " [11, 12],\n",
       " [11, 12],\n",
       " [0],\n",
       " [0, 2],\n",
       " [0, 2],\n",
       " [3],\n",
       " [4, 5],\n",
       " [6],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [2],\n",
       " [2, 3],\n",
       " [5],\n",
       " [0, 13],\n",
       " [14, 15],\n",
       " [3],\n",
       " [3],\n",
       " [1, 2, 3, 4],\n",
       " [23],\n",
       " [5, 11, 12],\n",
       " [23, 24, 25, 26],\n",
       " [46, 47],\n",
       " [48, 49],\n",
       " [0],\n",
       " [0, 1],\n",
       " [2, 3, 5],\n",
       " [2, 4],\n",
       " [9],\n",
       " [12],\n",
       " [0, 1, 9],\n",
       " [12],\n",
       " [16],\n",
       " [0],\n",
       " [0, 1],\n",
       " [0, 2, 4],\n",
       " [0, 12],\n",
       " [14, 23],\n",
       " [39, 40, 41, 50],\n",
       " [0, 1],\n",
       " [7],\n",
       " [7, 9],\n",
       " [15],\n",
       " [16],\n",
       " [30, 31],\n",
       " [30, 39],\n",
       " [30, 36, 37],\n",
       " [0, 1, 2, 6, 7],\n",
       " [0, 1, 2, 6, 7],\n",
       " [8],\n",
       " [13, 16, 17],\n",
       " [17, 18, 19],\n",
       " [17, 19, 20],\n",
       " [17, 20],\n",
       " [38, 39, 40, 41],\n",
       " [44, 45],\n",
       " [46, 47],\n",
       " [1, 4, 13],\n",
       " [14],\n",
       " [14],\n",
       " [15, 16],\n",
       " [15, 16],\n",
       " [18],\n",
       " [18],\n",
       " [18],\n",
       " [18],\n",
       " [0, 2, 3, 4],\n",
       " [0],\n",
       " [12, 13, 14],\n",
       " [16, 17],\n",
       " [15, 23, 24],\n",
       " [27, 28],\n",
       " [15, 27, 34],\n",
       " [15, 27, 37],\n",
       " [46, 52],\n",
       " [27, 38, 42, 43],\n",
       " [57, 58, 59],\n",
       " [46, 58],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [2, 3],\n",
       " [3, 4],\n",
       " [4, 5],\n",
       " [17],\n",
       " [22, 23, 24, 25],\n",
       " [26],\n",
       " [],\n",
       " [0, 2],\n",
       " [2],\n",
       " [2],\n",
       " [3, 8],\n",
       " [19, 23],\n",
       " [18, 23, 24],\n",
       " [24],\n",
       " [32, 33],\n",
       " [0],\n",
       " [2, 3],\n",
       " [7],\n",
       " [13],\n",
       " [7, 8],\n",
       " [14],\n",
       " [16, 18, 19],\n",
       " [22, 23],\n",
       " [24, 25],\n",
       " [36, 37],\n",
       " [5],\n",
       " [5],\n",
       " [5, 6, 7],\n",
       " [12, 13],\n",
       " [9, 10, 11],\n",
       " [13],\n",
       " [14],\n",
       " [15],\n",
       " [16],\n",
       " [17],\n",
       " [19, 20, 21],\n",
       " [29, 31],\n",
       " [29, 30, 31],\n",
       " [32],\n",
       " [0],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2, 4],\n",
       " [8, 11, 12, 13],\n",
       " [13, 14, 15, 17, 18],\n",
       " [20],\n",
       " [20, 21, 22, 24],\n",
       " [20, 24, 25],\n",
       " [20, 24, 25],\n",
       " [30, 31, 33],\n",
       " [30, 35, 37],\n",
       " [30, 36],\n",
       " [56, 59, 60],\n",
       " [11],\n",
       " [12],\n",
       " [8, 9],\n",
       " [13, 14],\n",
       " [13, 15],\n",
       " [17],\n",
       " [33, 34, 35, 36],\n",
       " [36],\n",
       " [0, 1],\n",
       " [2],\n",
       " [9, 10],\n",
       " [2, 3],\n",
       " [2, 5, 6],\n",
       " [14],\n",
       " [19],\n",
       " [22, 23, 26, 29, 33, 37],\n",
       " [22, 23, 26, 29, 33, 37],\n",
       " [2],\n",
       " [2],\n",
       " [37, 38],\n",
       " [29, 31],\n",
       " [23],\n",
       " [0],\n",
       " [0],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 3, 4, 5],\n",
       " [14, 15, 16],\n",
       " [0, 2, 26, 29, 30],\n",
       " [31, 32, 33, 34],\n",
       " [0, 2],\n",
       " [0, 2],\n",
       " [13],\n",
       " [13],\n",
       " [16],\n",
       " [22],\n",
       " [30],\n",
       " [38, 39],\n",
       " [0],\n",
       " [0],\n",
       " [5, 7, 9, 13],\n",
       " [5, 7, 9, 13],\n",
       " [23, 24],\n",
       " [26, 27],\n",
       " [8, 10],\n",
       " [13, 14, 15, 16],\n",
       " [24, 25, 26],\n",
       " [13, 14, 15, 16],\n",
       " [20, 21, 22],\n",
       " [27, 28],\n",
       " [33, 34],\n",
       " [33, 35],\n",
       " [33, 37],\n",
       " [33, 37, 38],\n",
       " [39, 40, 41],\n",
       " [],\n",
       " [0, 1, 10],\n",
       " [7],\n",
       " [0, 1, 10],\n",
       " [10],\n",
       " [10],\n",
       " [10],\n",
       " [10],\n",
       " [10],\n",
       " [10],\n",
       " [10],\n",
       " [10],\n",
       " [0],\n",
       " [2],\n",
       " [20],\n",
       " [20, 21, 22],\n",
       " [0, 2],\n",
       " [36],\n",
       " [2, 17],\n",
       " [46, 47, 48, 49, 62, 63, 64],\n",
       " [0],\n",
       " [0, 1],\n",
       " [0, 5, 6, 7],\n",
       " [8, 9],\n",
       " [21, 22],\n",
       " [22, 24, 25, 26],\n",
       " [29, 30, 31, 32, 33],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [14, 15, 16, 17],\n",
       " [20],\n",
       " [20],\n",
       " [22, 23, 25, 26],\n",
       " [29, 30, 31, 32],\n",
       " [47, 48],\n",
       " [0],\n",
       " [51, 52, 53],\n",
       " [1, 2, 3, 5, 6],\n",
       " [7, 8, 9],\n",
       " [9, 11, 12],\n",
       " [22, 23, 26, 27, 28],\n",
       " [31, 32, 33],\n",
       " [39, 42],\n",
       " [39, 44],\n",
       " [0, 5, 6],\n",
       " [11, 19, 20],\n",
       " [21, 22, 23],\n",
       " [11, 30],\n",
       " [11, 40, 41, 42],\n",
       " [11, 52, 53, 54],\n",
       " [1, 11, 13, 28],\n",
       " [13, 14],\n",
       " [0, 13, 14, 22, 25, 26],\n",
       " [8, 9, 11, 13],\n",
       " [0, 27, 31],\n",
       " [31, 32],\n",
       " [27, 28],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [1],\n",
       " [2, 5],\n",
       " [7, 8, 9],\n",
       " [18, 20, 21],\n",
       " [24],\n",
       " [0, 5, 6, 7],\n",
       " [5, 9],\n",
       " [5, 9],\n",
       " [9, 10, 11],\n",
       " [12, 13, 14],\n",
       " [24, 25],\n",
       " [24, 25],\n",
       " [24, 25],\n",
       " [33],\n",
       " [0],\n",
       " [0, 1, 2],\n",
       " [0],\n",
       " [0, 10, 12, 15, 17],\n",
       " [10, 15, 17, 18, 19, 20],\n",
       " [24],\n",
       " [24],\n",
       " [24],\n",
       " [24],\n",
       " [17, 24, 25, 26],\n",
       " [4],\n",
       " [4, 5],\n",
       " [5],\n",
       " [6],\n",
       " [5],\n",
       " [6],\n",
       " [6],\n",
       " [1],\n",
       " [1, 5, 7],\n",
       " [2, 3],\n",
       " [1, 2, 3, 4],\n",
       " [0, 1],\n",
       " [0, 5],\n",
       " [0, 7],\n",
       " [6, 9, 10, 19, 25, 31, 35],\n",
       " [10, 19, 20],\n",
       " [10],\n",
       " [10, 19, 20],\n",
       " [19, 20],\n",
       " [19, 20, 21],\n",
       " [10, 12],\n",
       " [10, 12, 14],\n",
       " [19, 23],\n",
       " [13, 14],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [1, 2, 7, 8, 10],\n",
       " [1, 2, 7, 8, 9],\n",
       " [1, 2, 7, 8, 10],\n",
       " [9, 10],\n",
       " [25, 26, 27],\n",
       " [0, 1, 3],\n",
       " [9, 12, 13],\n",
       " [9, 15],\n",
       " [21, 24],\n",
       " [27, 28, 29],\n",
       " [27, 28],\n",
       " [27, 28],\n",
       " [9, 14, 15, 16],\n",
       " [21, 24],\n",
       " [19, 30, 31],\n",
       " [5, 6, 7, 9, 10, 11, 15],\n",
       " [15, 16],\n",
       " [18, 19],\n",
       " [35, 37],\n",
       " [35, 37],\n",
       " [35, 37],\n",
       " [0, 1],\n",
       " [3],\n",
       " [6, 7],\n",
       " [16, 17, 18],\n",
       " [20, 21],\n",
       " [29, 32],\n",
       " [30, 32],\n",
       " [39, 40],\n",
       " [22, 23, 24, 25],\n",
       " [18],\n",
       " [32],\n",
       " [23],\n",
       " [],\n",
       " [34],\n",
       " [0, 4, 9, 31, 32],\n",
       " [0, 5],\n",
       " [2, 5],\n",
       " [5, 6],\n",
       " [5, 6],\n",
       " [30, 31]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model_eval(new_network, eval_train_batches, 0, training_data['QUESTIONS'].apply(lambda x: x[0]['SHINT_']).tolist(), 0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a53720000ed403c8b8eb8573ff7b626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1807), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000005\n",
      "epoch 0 train_loss: 0.122\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57a2168935514ff29a673e445e8104b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-155-41a2b2197348>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_train_3d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.00002\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-108-292a0695e69a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(network, data, dev_batches, num_epochs, lr)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunning_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch %d train_loss: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcurrent_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mnew_model_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp_golds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-107-b9b4ee56998e>\u001b[0m in \u001b[0;36mnew_model_eval\u001b[0;34m(network, dev_batches, current_epoch, sp_golds, avg_loss)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mout_dct\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_fgc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0msp_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_dct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-aa65ccc0f9ec>\u001b[0m in \u001b[0;36mpredict_fgc\u001b[0;34m(self, batch, threshold)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_fgc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0mmax_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mmax_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-aa65ccc0f9ec>\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-aa65ccc0f9ec>\u001b[0m in \u001b[0;36mforward_nn\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mmax_sent_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "train(new_network, dataloader_train_3d, a, 20, 0.00002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 768])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Parameter(torch.FloatTensor(768).uniform_(-0.1, 0.1)).expand(2, 10, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 7, 68])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = iter(dataloader_train_3d).next()['ids']\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 4397,  342, 1367, 2548, 1355, 4385, 4342, 4342, 4500,  784,  720,\n",
       "         3341, 7157, 4635, 6009, 8024, 2130, 2768, 1400, 1315, 5543, 3175,  912,\n",
       "         4638, 3123, 6822, 5632, 2346, 1673, 2349,  775, 1358, 4635, 6009, 1920,\n",
       "         7623, 8043,  102, 7479, 5865, 6814,  782, 4638, 2608, 2552,  680, 3675,\n",
       "         1213, 8024,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 101, 4397,  342, 1367, 2548, 1355, 4385, 4342, 4342, 4500,  784,  720,\n",
       "         3341, 7157, 4635, 6009, 8024, 2130, 2768, 1400, 1315, 5543, 3175,  912,\n",
       "         4638, 3123, 6822, 5632, 2346, 1673, 2349,  775, 1358, 4635, 6009, 1920,\n",
       "         7623, 8043,  102, 4397,  679,  852, 2868, 2245,  749,  782, 5102, 4638,\n",
       "         4761, 6399, 7566, 1818, 8024,  102,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 101, 4397,  342, 1367, 2548, 1355, 4385, 4342, 4342, 4500,  784,  720,\n",
       "         3341, 7157, 4635, 6009, 8024, 2130, 2768, 1400, 1315, 5543, 3175,  912,\n",
       "         4638, 3123, 6822, 5632, 2346, 1673, 2349,  775, 1358, 4635, 6009, 1920,\n",
       "         7623, 8043,  102,  738, 3136, 2193, 2769,  812, 8024,  102,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 101, 4397,  342, 1367, 2548, 1355, 4385, 4342, 4342, 4500,  784,  720,\n",
       "         3341, 7157, 4635, 6009, 8024, 2130, 2768, 1400, 1315, 5543, 3175,  912,\n",
       "         4638, 3123, 6822, 5632, 2346, 1673, 2349,  775, 1358, 4635, 6009, 1920,\n",
       "         7623, 8043,  102, 6206,  809, 3291,  711,  782, 6887, 4638, 5125, 4868,\n",
       "         3341, 2190, 2521, 1220, 4289,  511,  102,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]], device='cuda:0')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_network.loss(iter(dataloader_train_3d).next())[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_network.loss(iter(dataloader_train_3d).next())[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': tensor([[[ 101, 1380, 2577,  ...,    0,    0,    0],\n",
       "          [ 101, 1380, 2577,  ...,    0,    0,    0],\n",
       "          [ 101, 1380, 2577,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 101, 1380, 2577,  ...,    0,    0,    0],\n",
       "          [ 101, 1380, 2577,  ...,    0,    0,    0],\n",
       "          [ 101, 1380, 2577,  ...,    0,    0,    0]],\n",
       " \n",
       "         [[ 101, 5018,  671,  ...,    0,    0,    0],\n",
       "          [ 101, 5018,  671,  ...,    0,    0,    0],\n",
       "          [ 101, 5018,  671,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 101, 5018,  671,  ...,    0,    0,    0],\n",
       "          [ 101, 5018,  671,  ...,    0,    0,    0],\n",
       "          [ 101, 5018,  671,  ...,    0,    0,    0]]], device='cuda:0'),\n",
       " 'mask_ids': tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]]], device='cuda:0'),\n",
       " 'segment_ids': tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]]], device='cuda:0'),\n",
       " 'labels': tensor([[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]], device='cuda:0')}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter(dataloader_train_3d).next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Improved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data_with_performance_0 = datapreprocessing(validation_data, True)\n",
    "training_data_with_performance_0 = datapreprocessing(training_data, True)\n",
    "test_data_with_performance_0 = datapreprocessing(test_data, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a07dee24f94334b3b836ebff3d932e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=882), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.18, 'sp_prec': 0.573, 'sp_recall': 0.381, 'sp_f1': 0.43}\n",
      "epoch 0 eval_recall: 0.381 eval_f1: 0.430 loss: 0.001\n"
     ]
    }
   ],
   "source": [
    "train_pred_0, train_obs_0 = new_model_eval(new_network, b, 0, training_data['QUESTIONS'].apply(lambda x: x[0]['SHINT_']).tolist()\n",
    ", 0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_with_performance_0['train_pred'] = train_pred_0\n",
    "training_data_with_performance_0['train_obs'] = train_obs_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_sp = []\n",
    "for i in range(training_data_with_performance_0.shape[0]):\n",
    "    para = training_data_with_performance_0['Sentence_List'][i]\n",
    "    sen = []\n",
    "    for index in training_data_with_performance_0['train_pred'][i]:\n",
    "        sen.append(para[index])\n",
    "    correct_sp.append(sen)\n",
    "training_data_with_performance_0['Pred_List'] = correct_sp\n",
    "correct_sp = []\n",
    "for i in range(training_data_with_performance_0.shape[0]):\n",
    "    para = training_data_with_performance_0['Sentence_List'][i]\n",
    "    sen = []\n",
    "    for index in training_data_with_performance_0['train_obs'][i]:\n",
    "        sen.append(para[index])\n",
    "    correct_sp.append(sen)\n",
    "training_data_with_performance_0['Obs_List'] = correct_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_with_performance_0.drop(['SE_Index', 'Label', 'train_pred', 'train_obs'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Sentence_List</th>\n",
       "      <th>Length</th>\n",
       "      <th>Pred_List</th>\n",
       "      <th>Obs_List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>苏东坡的老家在哪?</td>\n",
       "      <td>[嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...</td>\n",
       "      <td>35</td>\n",
       "      <td>[苏轼才20岁，]</td>\n",
       "      <td>[苏轼回蜀守丧，]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>苏东坡出生于哪一年?</td>\n",
       "      <td>[嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...</td>\n",
       "      <td>35</td>\n",
       "      <td>[苏轼才20岁，]</td>\n",
       "      <td>[嘉佑二年（1057年），, 苏轼才20岁，]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>苏东坡和谁一起进京参加会考?</td>\n",
       "      <td>[嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...</td>\n",
       "      <td>35</td>\n",
       "      <td>[苏轼才20岁，]</td>\n",
       "      <td>[苏轼才20岁，, 与弟弟苏辙一同进京参加会考，]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>苏东坡与曾巩是否同为欧阳修的学生?</td>\n",
       "      <td>[嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...</td>\n",
       "      <td>35</td>\n",
       "      <td>[苏轼以一篇《刑赏忠厚之至论》的论文得到考官梅尧臣的青睐，]</td>\n",
       "      <td>[欧阳修亦十分赞赏，, 原本欲拔擢为第一，, 但又怕该文为自己的门生曾巩所作，, 为了避嫌，...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>苏东坡与王安石在职场上是否理念相同?</td>\n",
       "      <td>[嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...</td>\n",
       "      <td>35</td>\n",
       "      <td>[苏轼以一篇《刑赏忠厚之至论》的论文得到考官梅尧臣的青睐，]</td>\n",
       "      <td>[反对王安石变法中的一些作为，, 王安石于是屡次在神宗面前诋毁苏轼，]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>小明感染肠病毒后痊瘉一周后是否就不会再传染给别人了?</td>\n",
       "      <td>[国内肠病毒轻症疫情持续上升，, 另新增1例肠病毒71型并发重症病例。, 疾病管制署再次呼吁...</td>\n",
       "      <td>42</td>\n",
       "      <td>[请尽速送大医院接受治疗。]</td>\n",
       "      <td>[痊愈后肠病毒会随著粪便排出达8到12周之久。]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>877</td>\n",
       "      <td>这起诈骗案件发生于台北市哪一个行政区？</td>\n",
       "      <td>[松山分局三民派出所警员白小帆，, 警员张秀秀。, 于一百零八年十月三十一日十五时至十七时，...</td>\n",
       "      <td>32</td>\n",
       "      <td>[松山分局三民派出所警员白小帆，, 于一百零八年十月三十一日十五时至十七时，, 疑似遭到诈骗...</td>\n",
       "      <td>[松山分局三民派出所警员白小帆，, 疑似遭到诈骗两元，]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>878</td>\n",
       "      <td>这起诈骗案件发生的日期是哪一天？</td>\n",
       "      <td>[松山分局三民派出所警员白小帆，, 警员张秀秀。, 于一百零八年十月三十一日十五时至十七时，...</td>\n",
       "      <td>32</td>\n",
       "      <td>[疑似遭到诈骗两元，, 到场后，发现系一名年约八十二岁陈姓妇人\\n欲提领新台币三十三万元。]</td>\n",
       "      <td>[于一百零八年十月三十一日十五时至十七时，, 疑似遭到诈骗两元，]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>这起诈骗案件的受害人姓氏为何？</td>\n",
       "      <td>[松山分局三民派出所警员白小帆，, 警员张秀秀。, 于一百零八年十月三十一日十五时至十七时，...</td>\n",
       "      <td>32</td>\n",
       "      <td>[疑似遭到诈骗两元，]</td>\n",
       "      <td>[疑似遭到诈骗两元，, 到场后，发现系一名年约八十二岁陈姓妇人\\n欲提领新台币三十三万元。]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>881</td>\n",
       "      <td>反诈骗专线电话是几号？</td>\n",
       "      <td>[松山分局三民派出所警员白小帆，, 警员张秀秀。, 于一百零八年十月三十一日十五时至十七时，...</td>\n",
       "      <td>32</td>\n",
       "      <td>[避免遭诈骗。]</td>\n",
       "      <td>[也可拨打一六五求证，, 避免遭诈骗。]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>723 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Question  \\\n",
       "0                     苏东坡的老家在哪?   \n",
       "1                    苏东坡出生于哪一年?   \n",
       "2                苏东坡和谁一起进京参加会考?   \n",
       "4             苏东坡与曾巩是否同为欧阳修的学生?   \n",
       "5            苏东坡与王安石在职场上是否理念相同?   \n",
       "..                          ...   \n",
       "875  小明感染肠病毒后痊瘉一周后是否就不会再传染给别人了?   \n",
       "877         这起诈骗案件发生于台北市哪一个行政区？   \n",
       "878            这起诈骗案件发生的日期是哪一天？   \n",
       "880             这起诈骗案件的受害人姓氏为何？   \n",
       "881                 反诈骗专线电话是几号？   \n",
       "\n",
       "                                         Sentence_List  Length  \\\n",
       "0    [嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...      35   \n",
       "1    [嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...      35   \n",
       "2    [嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...      35   \n",
       "4    [嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...      35   \n",
       "5    [嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...      35   \n",
       "..                                                 ...     ...   \n",
       "875  [国内肠病毒轻症疫情持续上升，, 另新增1例肠病毒71型并发重症病例。, 疾病管制署再次呼吁...      42   \n",
       "877  [松山分局三民派出所警员白小帆，, 警员张秀秀。, 于一百零八年十月三十一日十五时至十七时，...      32   \n",
       "878  [松山分局三民派出所警员白小帆，, 警员张秀秀。, 于一百零八年十月三十一日十五时至十七时，...      32   \n",
       "880  [松山分局三民派出所警员白小帆，, 警员张秀秀。, 于一百零八年十月三十一日十五时至十七时，...      32   \n",
       "881  [松山分局三民派出所警员白小帆，, 警员张秀秀。, 于一百零八年十月三十一日十五时至十七时，...      32   \n",
       "\n",
       "                                             Pred_List  \\\n",
       "0                                            [苏轼才20岁，]   \n",
       "1                                            [苏轼才20岁，]   \n",
       "2                                            [苏轼才20岁，]   \n",
       "4                       [苏轼以一篇《刑赏忠厚之至论》的论文得到考官梅尧臣的青睐，]   \n",
       "5                       [苏轼以一篇《刑赏忠厚之至论》的论文得到考官梅尧臣的青睐，]   \n",
       "..                                                 ...   \n",
       "875                                     [请尽速送大医院接受治疗。]   \n",
       "877  [松山分局三民派出所警员白小帆，, 于一百零八年十月三十一日十五时至十七时，, 疑似遭到诈骗...   \n",
       "878     [疑似遭到诈骗两元，, 到场后，发现系一名年约八十二岁陈姓妇人\\n欲提领新台币三十三万元。]   \n",
       "880                                        [疑似遭到诈骗两元，]   \n",
       "881                                           [避免遭诈骗。]   \n",
       "\n",
       "                                              Obs_List  \n",
       "0                                            [苏轼回蜀守丧，]  \n",
       "1                              [嘉佑二年（1057年），, 苏轼才20岁，]  \n",
       "2                            [苏轼才20岁，, 与弟弟苏辙一同进京参加会考，]  \n",
       "4    [欧阳修亦十分赞赏，, 原本欲拔擢为第一，, 但又怕该文为自己的门生曾巩所作，, 为了避嫌，...  \n",
       "5                  [反对王安石变法中的一些作为，, 王安石于是屡次在神宗面前诋毁苏轼，]  \n",
       "..                                                 ...  \n",
       "875                           [痊愈后肠病毒会随著粪便排出达8到12周之久。]  \n",
       "877                       [松山分局三民派出所警员白小帆，, 疑似遭到诈骗两元，]  \n",
       "878                  [于一百零八年十月三十一日十五时至十七时，, 疑似遭到诈骗两元，]  \n",
       "880     [疑似遭到诈骗两元，, 到场后，发现系一名年约八十二岁陈姓妇人\\n欲提领新台币三十三万元。]  \n",
       "881                               [也可拨打一六五求证，, 避免遭诈骗。]  \n",
       "\n",
       "[723 rows x 5 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mismatch = training_data_with_performance_0[training_data_with_performance_0['Pred_List'] != training_data_with_performance_0['Obs_List']]\n",
    "train_mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 17\n",
    "print(train_mismatch.loc[i]['Question'])\n",
    "print(train_mismatch.loc[i]['Pred_List'])\n",
    "print(train_mismatch.loc[i]['Obs_List'])\n",
    "train_mismatch.loc[i]['Sentence_List']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0724 09:52:32.290062 140341672732480 tokenization_utils.py:375] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /root/.cache/torch/transformers/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for a in dataloader_train_3d:\n",
    "    for b in a['']:\n",
    "        for c in b:\n",
    "            print(c)\n",
    "            #print(tokenizer.convert_ids_to_tokens(c.tolist()))\n",
    "    counter += 1\n",
    "    if counter == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
