{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0827 08:11:36.531327 139749014460224 file_utils.py:39] PyTorch version 1.2.0+cu92 available.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM, BertForNextSentencePrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence \n",
    "import torchvision\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.optimization import AdamW\n",
    "from transformers.optimization import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = pd.read_json(\"data/FGC/FGC_release_1.7.13/FGC_release_all_dev.json\")\n",
    "training_data = pd.read_json(\"data/FGC/FGC_release_1.7.13/FGC_release_all_train.json\")\n",
    "test_data = pd.read_json(\"data/FGC/FGC_release_1.7.13/FGC_release_all_test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all the questions where there's no supporting evidence to it\n",
    "training_data = training_data[training_data['QUESTIONS'].apply(lambda x: len(x[0]['SHINT_']) > 0)]\n",
    "dev_data = dev_data[dev_data['QUESTIONS'].apply(lambda x: len(x[0]['SHINT_']) > 0)]\n",
    "test_data = test_data[test_data['QUESTIONS'].apply(lambda x: len(x[0]['SHINT_']) > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "berts_dev_golds = [[0, 2, 4], [0, 1, 4], [0, 4, 17, 20], [0, 8], [11, 12], [18], [0, 2, 4, 18], [0, 4, 6, 7], [27], [0, 2, 18], [0, 2], [0, 2], [0, 3], [0, 7, 11], [0, 12, 13, 15, 16], [0, 17, 18], [0, 6], [0, 7], [0, 4, 7], [0, 7], [0, 2, 16, 18], [10, 11], [10, 11], [0, 18], [18], [19, 20], [20, 21, 22], [7, 14], [7, 14], [7], [0, 1], [15], [17], [15], [17], [0, 2], [3, 6], [15], [17], [17], [17], [15], [17], [15], [15], [17], [17], [26], [20, 23, 26], [11, 12, 13, 17, 29], [11, 12, 13, 17], [0, 5], [0, 1], [0, 3, 20, 21], [0, 3, 21], [0], [0], [16, 17], [0, 1], [21], [0, 11], [21, 22], [6, 8], [5, 6], [0], [0, 1], [0, 5], [0, 5], [8, 9], [21], [14, 15, 16, 17], [18, 19, 20], [22, 24, 25, 26], [22], [24], [20, 22, 23], [27, 29], [35, 36], [42, 45], [0, 2], [0, 1, 12, 13, 14], [13, 14], [11, 12, 13, 14], [11, 12, 13, 14], [11, 12], [8, 9, 11], [3, 4], [0, 1], [35, 36], [2, 3], [37, 38], [27, 28], [27, 28], [29, 30], [2, 3], [37, 38], [0, 1], [0, 2], [13, 15], [3], [2, 3], [2, 3], [16, 17], [20, 21], [21, 22], [0], [0], [0], [2], [2, 4], [2, 5], [11, 12], [2, 4], [2, 4], [6, 7, 9, 10], [5, 6, 8, 9, 10], [9, 10, 11, 13], [9, 10, 11], [18, 20], [18, 22], [5], [13], [5], [5, 6, 7], [0], [5], [15, 16, 17], [8, 9], [21, 22], [21, 22], [26], [23, 24], [28, 29], [5], [0], [5, 6], [5, 6], [0, 10], [0, 3], [0, 3], [1, 3], [0, 1, 3], [0, 3, 10], [3, 4], [3, 7], [0, 3, 11], [0, 3, 11], [5, 36, 37, 38, 39, 40, 41], [9, 10], [15], [24], [5, 7], [15, 24], [15, 24], [0, 1, 37, 38, 39], [5, 38, 39, 40, 41], [0, 1], [0, 2], [0, 2], [5], [4, 5, 6], [5], [7, 8], [7], [7], [12], [15], [15], [0, 1], [0, 1], [0, 1], [1, 2, 5], [1, 4], [1, 6, 7], [7, 10], [10, 11, 12], [10, 11, 12, 13, 14], [2, 16, 17], [24, 25, 26, 27, 28], [16, 18, 19], [16, 20], [16, 21], [16, 23, 24, 25], [16, 28, 29], [41, 48], [6], [16], [24, 25, 26], [24, 28], [37], [37, 38, 39], [37, 39, 41], [2, 4, 5, 7, 9, 10], [11], [11], [11, 18, 19], [18], [18], [23, 25], [23], [50, 53, 54, 55, 56, 57], [56, 58], [17, 20], [26, 28], [17, 25], [34, 35, 36], [39, 40], [39, 41, 42], [39, 41, 42, 43, 44, 45], [45, 47], [60, 61, 62, 63], [0], [0, 1], [10, 11], [22, 24, 25], [1, 22, 26, 27], [22, 34], [22, 34], [22, 34, 36], [22, 34, 37], [22, 34, 38], [53, 54, 56, 57, 58, 59], [0, 1], [1, 5, 8], [1, 5, 12, 13], [1, 12, 13], [1, 5, 12, 13, 18, 19], [44, 46], [26, 27, 28, 29, 30], [15, 16, 18], [15, 16, 19], [7, 14], [7, 14], [7, 14], [7, 14], [0], [0, 1], [0, 8, 9, 10], [0, 2, 5]]\n",
    "berts_dev_preds = [[0], [0, 1], [0], [0], [12], [], [0], [0, 2, 5, 6, 7], [27], [0], [0, 11], [0, 2], [], [0, 11], [], [0, 2, 10, 18], [0, 6], [0, 2, 7], [0, 2, 7], [0, 7], [0, 2, 3, 16, 18], [0, 11], [], [0, 2, 6, 9, 10, 18], [0, 2, 3, 10, 16, 18], [19, 20], [0, 3, 10, 20, 21, 24], [11], [11], [], [1, 5, 6, 12, 13, 14], [15, 17], [6, 17], [6, 15, 17], [28, 29], [0, 3, 4], [0, 3, 4, 17], [15], [17], [], [17], [6, 15, 17, 19, 21, 28, 29], [15, 17, 19, 21, 28, 29], [15, 17], [15, 17], [15, 17], [15, 17], [26], [26], [26], [26], [0, 5], [], [0, 5, 11], [5], [0], [], [], [0, 5], [], [3, 11], [0, 3, 10], [], [0, 14], [0, 1], [0, 1, 3], [0, 1, 2, 5], [0, 1, 2, 5], [0, 9], [0, 1, 3, 14, 21], [0, 1, 3, 8, 16, 20, 21], [0, 1, 3, 11, 14, 18, 19, 20, 21], [0, 22], [0, 22], [0], [], [26, 33], [35], [28, 35, 48], [0, 2, 4], [0, 1, 2, 4, 9, 12], [0, 4, 14], [0, 2, 4, 13], [0, 4], [12], [8, 15], [0, 1, 2, 3, 4], [], [], [], [], [27, 28], [27, 28], [], [37], [37], [0, 1, 11, 12], [0, 2, 3], [1, 11, 15], [3], [3], [3], [0, 3, 18, 28], [0, 3, 21, 22], [0, 3], [0, 1], [0], [0], [0], [4, 16], [5, 16], [11, 18, 21], [], [], [7, 9], [9], [11], [], [3], [], [0], [], [5], [5, 6], [0], [0], [15], [8, 9, 13, 14], [8, 22], [22], [0, 8, 25], [], [28], [5], [0], [8], [8], [0], [0, 3], [0, 3], [1, 3], [1, 3], [0, 3, 10], [3], [0, 3], [3, 11, 12], [3], [], [], [], [24], [], [24], [24], [31], [], [0, 1], [2], [2], [], [0], [], [7, 15], [], [7], [12], [15], [15], [0, 1, 7], [1, 7], [0, 1, 7], [], [1, 4, 5], [1, 6, 35], [10], [0, 7, 10, 11, 12], [0, 7, 10, 11, 12, 14], [], [24, 26, 27, 28], [19], [16], [16, 21], [23, 25], [28], [16, 41, 48], [6], [], [25, 26], [], [37], [25, 39], [39, 41], [2, 4, 5, 7, 9], [], [11], [], [18], [], [16], [57], [17, 53, 54, 55, 56, 57], [7, 58], [17, 20, 60], [21, 22, 26, 29, 38], [], [34, 35, 39], [40], [39, 41], [44, 57], [22, 29], [17, 60, 61, 62], [0], [1], [0, 11, 36, 37, 38], [14, 24], [26, 27], [6], [], [36, 37, 38], [36, 37, 38], [0, 11, 36, 37, 38], [7, 57], [1], [8, 36], [13], [13, 14], [1, 18, 19], [1, 8, 46], [27, 28, 29, 30], [3, 15, 17, 23], [3, 15, 17, 23], [7, 14], [7, 14], [7, 14], [7, 14], [0], [0, 1, 9, 12, 14, 21], [], [0, 9, 12, 17, 21]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0827 03:04:51.281675 139796948760384 tokenization_utils_base.py:1254] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /root/.cache/torch/transformers/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(data):\n",
    "    all_instances = []\n",
    "    questions = data['QUESTIONS'].apply(lambda x: [x[0]['QTEXT_CN'], len(x[0]['SHINT'][1])]).tolist()\n",
    "    sentences = [sentence['text'] for sentence_dict in data['SENTS'] for sentence in sentence_dict]\n",
    "    lengths = np.array(questions)[:, 1].astype(int).tolist()\n",
    "    indices = data['QUESTIONS'].apply(lambda x: x[0]['SHINT_']).tolist()\n",
    "    labels = [[0] * length for length in lengths]\n",
    "    all_labels = []\n",
    "    # Inpute index into labels\n",
    "    for i in range(len(labels)):\n",
    "        np_label = np.array(labels[i])\n",
    "        np_index = np.array(indices[i])\n",
    "        np_label[np_index] = 1\n",
    "        label = np_label.tolist()\n",
    "        labels[i] = label\n",
    "        all_labels = all_labels + label\n",
    "    counter = 0\n",
    "    for question in questions:\n",
    "        question_text = question[0]\n",
    "        for j in range(counter, counter + question[1]):\n",
    "            all_instances.append([question_text, sentences[j]])\n",
    "    \n",
    "    all_tokenized = []\n",
    "    for i in range(len(all_instances)):\n",
    "        tokenized = tokenizer([all_instances[i]], padding='max_length', truncation=True, max_length=512, return_tensors = 'pt')\n",
    "        tokenized['input_ids'] = tokenized['input_ids'].to(device)\n",
    "        tokenized['input_ids'] = tokenized['input_ids'].squeeze(0)\n",
    "        tokenized['token_type_ids'] = tokenized['token_type_ids'].to(device)\n",
    "        tokenized['token_type_ids'] = tokenized['token_type_ids'].squeeze(0)\n",
    "        tokenized['attention_mask'] = tokenized['attention_mask'].to(device)\n",
    "        tokenized['attention_mask'] = tokenized['attention_mask'].squeeze(0)\n",
    "        tokenized['label'] = torch.tensor(all_labels[i])\n",
    "        all_tokenized.append(tokenized)\n",
    "    return all_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_instances = data_preprocessing(training_data)\n",
    "dev_all_instances = data_preprocessing(dev_data)\n",
    "test_all_instances = data_preprocessing(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiBERTsModel(nn.Module):\n",
    "\n",
    "    def __init__(self, number_of_sentence, adjust_weight, trained_baseline_model=None, transform=True):\n",
    "        super(MultiBERTsModel, self).__init__()\n",
    "        self.number_of_sentence = number_of_sentence\n",
    "        self.adjust_weight = adjust_weight\n",
    "        self.bertNSP = BertForNextSentencePrediction.from_pretrained('bert-base-chinese')\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        if trained_baseline_model:\n",
    "            self.bert = trained_baseline_model.bert\n",
    "            self.sp_linear = trained_baseline_model.linear\n",
    "        else:\n",
    "            self.bert = BertModel.from_pretrained('bert-base-chinese')\n",
    "            self.sp_linear = nn.Linear(768, 1)\n",
    "        if transform:\n",
    "            self.transform = nn.Linear(768, 768, bias=False)\n",
    "\n",
    "    def forward_nn(self, batch):\n",
    "        batch_size = batch['input_ids'].shape[0]\n",
    "        max_sentence_length = batch['input_ids'].shape[2]\n",
    "\n",
    "        # BERT input\n",
    "        input_ids = batch['input_ids'].view(-1, max_sentence_length)\n",
    "        token_type_ids = batch['token_type_ids'].view(-1, max_sentence_length)\n",
    "        attention_mask = batch['attention_mask'].view(-1, max_sentence_length)\n",
    "    \n",
    "        hidden_state, pooler_output = self.bert(input_ids=input_ids,\n",
    "                                                         attention_mask=attention_mask,\n",
    "                                                         token_type_ids=token_type_ids)\n",
    "        # BERT NSP input\n",
    "        nsp_input_ids = batch['nsp_input_ids'].view(-1, max_sentence_length)\n",
    "        \n",
    "        nsp_token_type_ids = batch['nsp_token_type_ids'].view(-1, max_sentence_length)\n",
    "        nsp_attention_mask = batch['nsp_attention_mask'].view(-1, max_sentence_length)\n",
    "        \n",
    "        sentence_mask = batch['sentence_mask'].type(torch.float)\n",
    "        nsp_scores = self.bertNSP(input_ids=nsp_input_ids, \n",
    "                           attention_mask=nsp_attention_mask,\n",
    "                           token_type_ids=nsp_token_type_ids)\n",
    "        \n",
    "        nsp_scores = nsp_scores[0].view(batch_size, -1, 2)\n",
    "        # Aggregate\n",
    "        pooler_output = pooler_output.view(batch_size, -1, 768)  # (batch, 3, 768)\n",
    "        \n",
    "        if self.adjust_weight:\n",
    "            if hasattr(self, 'transform'):\n",
    "                pooler_output = self.transform(pooler_output) # (batch, 3, 768) \n",
    "            nsp_scores = nsp_scores + (1.0 - sentence_mask) * -10000\n",
    "            weight = self.softmax(nsp_scores[:, :, 0]).unsqueeze(1)\n",
    "        else:\n",
    "            weight = torch.tensor([[[0.0], [1.0], [0.0]]], device=device)\n",
    "        \n",
    "        print(weight)\n",
    "        aggregated_sentence = torch.matmul(weight, pooler_output)  # (batch, 1, 768)\n",
    "        aggregated_sentence = aggregated_sentence.squeeze(1)  # (batch, 768)\n",
    "\n",
    "        final_output = self.sp_linear(aggregated_sentence)  # (batch, 1)\n",
    "\n",
    "        return final_output\n",
    "\n",
    "    def forward(self, batch):\n",
    "\n",
    "        output = self.forward_nn(batch)\n",
    "        labels = batch['label'].type(torch.float)\n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "        loss = loss_fn(output, labels)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def predict(self, batch, threshold=0.5):\n",
    "        output = self.forward_nn(batch)\n",
    "        score = torch.sigmoid(output).cpu()\n",
    "        predict_label = torch.where(score > threshold, torch.ones(len(score),1), torch.zeros(len(score), 1))\n",
    "        predict_label = predict_label.numpy().astype(int).tolist()\n",
    "        return predict_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0827 07:12:57.355679 140639700354880 tokenization_utils_base.py:1254] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /root/.cache/torch/transformers/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datapreprocessing(data, return_df=False):\n",
    "    \n",
    "    # Save all the questions, potential supporting evidence and indices in three lists\n",
    "    textQ_to_be_tokenized = []\n",
    "    textA_to_be_tokenized = []\n",
    "    sp_index = []\n",
    "    max_counter = 0\n",
    "    for dictionary in data['QUESTIONS']:\n",
    "        for element in dictionary:\n",
    "            textQ_to_be_tokenized.append(element['QTEXT_CN'])\n",
    "            sp_index.append(element['SHINT_'])\n",
    "    for dictionary in data['SENTS']:\n",
    "        current_text_sentence = []\n",
    "        for element in dictionary:\n",
    "            current_text_sentence.append(element['text'])\n",
    "        textA_to_be_tokenized.append(current_text_sentence)\n",
    "    \n",
    "    QandA_label = pd.DataFrame({'Question': textQ_to_be_tokenized,\n",
    "                                'Sentence_List': textA_to_be_tokenized,\n",
    "                                'SE_Index': sp_index,\n",
    "                                'Label': sp_index})\n",
    "\n",
    "    QandA_label['Length'] = QandA_label['Sentence_List'].apply(lambda x: len(x))\n",
    "    QandA_label['SE_Index'] = QandA_label['SE_Index'].apply(lambda x: [0])\n",
    "    QandA_label['SE_Index'] = QandA_label['SE_Index'] * QandA_label['Length']\n",
    "    QandA_label['SE_Index'] = list(zip(QandA_label['SE_Index'], QandA_label['Label']))\n",
    "\n",
    "    # Extract label index\n",
    "    for row in QandA_label['SE_Index']:\n",
    "        for index in row[1]:\n",
    "            row[0][index] = 1\n",
    "        \n",
    "    indexed = [i[0] for i in list(QandA_label['SE_Index'])]\n",
    "    QandA_label['Label'] = indexed\n",
    "\n",
    "    if return_df:\n",
    "        return QandA_label\n",
    "    \n",
    "    Q_and_Sentence_all_Comb = pd.DataFrame({'Question':np.repeat(QandA_label['Question'].values, QandA_label['Sentence_List'].str.len()),\n",
    "                        'Sentence':np.concatenate(QandA_label['Sentence_List'].values)})\n",
    "    Q_and_Sentence_all_Comb['Label'] = QandA_label['Label'].sum()\n",
    "    \n",
    "            \n",
    "    # Put all question and sentence combination into a list \n",
    "    All_instances = []\n",
    "    \n",
    "        \n",
    "    for i in range(len(QandA_label)):\n",
    "        \n",
    "        for sentence in QandA_label['Sentence_List'][i]:\n",
    "            question_token = tokenizer.tokenize(QandA_label['Question'][i])\n",
    "            sentence_token = tokenizer.tokenize(sentence)\n",
    "            instance = ['[CLS]'] + question_token + ['[SEP]'] + sentence_token + ['[SEP]'] \n",
    "\n",
    "            \n",
    "            if len(instance) > 512:\n",
    "                instance = instance[:511] + ['[SEP]']\n",
    "                #max_counter += 1\n",
    "\n",
    "            #instance = instance[:100]\n",
    "            All_instances.append(instance)\n",
    "            \n",
    "    # Convert ids to segment_ids\n",
    "    segment_ids = []\n",
    "    for token in All_instances:\n",
    "        length_of_zeros = token.index('[SEP]') - token.index('[CLS]') + 1\n",
    "        length_of_ones = len(token) - length_of_zeros\n",
    "        zeros_and_ones = [0] * length_of_zeros + [1] * length_of_ones\n",
    "        segment_ids.append(zeros_and_ones)\n",
    "        \n",
    "    ids = []\n",
    "    for token in All_instances:\n",
    "        ids.append(tokenizer.convert_tokens_to_ids(token))\n",
    "        \n",
    "    mask_ids = []\n",
    "    for token in All_instances:\n",
    "        mask_ids.append([1] * len(token))\n",
    "        \n",
    "    labels = list(Q_and_Sentence_all_Comb['Label'])\n",
    "    labels = [[i] for i in labels]\n",
    "    return All_instances, ids, segment_ids, mask_ids, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_sentence(data, number_of_sentence):\n",
    "    \n",
    "    QandA_label = datapreprocessing(training_data, True)\n",
    "    \n",
    "    Q_and_Sentence_all_Comb = pd.DataFrame({'Question':np.repeat(QandA_label['Question'].values, QandA_label['Sentence_List'].str.len()),\n",
    "                        'Sentence':np.concatenate(QandA_label['Sentence_List'].values)})\n",
    "    Q_and_Sentence_all_Comb['Label'] = QandA_label['Label'].sum()\n",
    "    \n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "\n",
    "    len_array = np.cumsum(np.array(data['SENTS'].apply(lambda x: len(x))))\n",
    "\n",
    "    # Put all question and sentence combination into a list \n",
    "    All_instances = []\n",
    "    padded_zeros = [0] * 250\n",
    "    \n",
    "    for i in range(len(QandA_label)):\n",
    "        \n",
    "        for j in range(len(QandA_label['Sentence_List'][i])):\n",
    "            \n",
    "            question_token = tokenizer.tokenize(QandA_label['Question'][i])\n",
    "            q_instance = ['[CLS]'] + question_token + ['[SEP]']\n",
    "            if len(q_instance) > 250:\n",
    "                q_instance = q_instance[:249] + ['[SEP]']\n",
    "\n",
    "            sentences = []\n",
    "            \n",
    "            for k in range(j - number_of_sentence//2, j + number_of_sentence//2 + 1):\n",
    "                if k < 0 or k >= len(QandA_label['Sentence_List'][i]):\n",
    "                    sentences.append(padded_zeros)\n",
    "                else:\n",
    "                    sentence_token = tokenizer.tokenize(QandA_label['Sentence_List'][i][k])\n",
    "                    s_instance = ['[CLS]'] + sentence_token + ['[SEP]']\n",
    "                    if len(s_instance) > 250:\n",
    "                        s_instance = s_instance[:249] + ['[SEP]']\n",
    "                    sentences.append(s_instance)\n",
    "            \n",
    "                \n",
    "            # Append the target sentence\n",
    "            #question_token = tokenizer.tokenize(QandA_label['Question'][i])\n",
    "            #sentence_token = tokenizer.tokenize(QandA_label['Sentence_List'][i][j])\n",
    "            #q_instance = ['[CLS]'] + question_token + ['[SEP]']\n",
    "            #s_instance = ['[CLS]'] + sentence_token + ['[SEP]'] \n",
    "            \n",
    "            #if len(s_instance) > 250:\n",
    "                #s_instance = s_instance[:249] + ['[SEP]']\n",
    "            #if len(q_instance) > 250:\n",
    "                #question = question[:249] + ['[SEP]']\n",
    "\n",
    "            All_instances.append((q_instance, sentences))\n",
    "\n",
    "    ids = []\n",
    "    mask_ids = []\n",
    "    sentence_masks = []\n",
    "    \n",
    "    for token in All_instances:\n",
    "        \n",
    "        q_tokenized = tokenizer.convert_tokens_to_ids(token[0])\n",
    "        q_mask = [1] * 250\n",
    "        \n",
    "        if len(q_tokenized) < 250:\n",
    "            q_tokenized = q_tokenized + (250 - len(q_tokenized)) * [0]\n",
    "            q_mask = q_tokenized.index(0) * [1] + (250 - q_tokenized.index(0)) * [0]\n",
    "            \n",
    "        s_tokens = []\n",
    "        s_masks = []\n",
    "        sen_mask = []\n",
    "        for sentence in token[1]:\n",
    "            \n",
    "            if sentence == padded_zeros:\n",
    "                s_tokens.append(padded_zeros)\n",
    "                s_masks.append(padded_zeros)\n",
    "                sen_mask.append([0])\n",
    "                \n",
    "            else:\n",
    "                s_tokenized = tokenizer.convert_tokens_to_ids(sentence)\n",
    "                s_mask = [1] * 250\n",
    "        \n",
    "                if len(s_tokenized) < 250:\n",
    "                    s_tokenized = s_tokenized + (250 - len(s_tokenized)) * [0]\n",
    "                    s_mask = s_tokenized.index(0) * [1] + (250 - s_tokenized.index(0)) * [0]\n",
    "            \n",
    "                s_tokens.append(s_tokenized)\n",
    "                s_masks.append(s_mask)\n",
    "                sen_mask.append([1])\n",
    "                \n",
    "        ids.append((q_tokenized, s_tokens))\n",
    "        mask_ids.append((q_mask, s_masks))\n",
    "        sentence_masks.append(sen_mask)\n",
    "\n",
    "    labels = list(Q_and_Sentence_all_Comb['Label'])\n",
    "    labels = [[i] for i in labels]\n",
    "    return All_instances, ids, mask_ids, sentence_masks, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_sentence_preprocessing(data, dataset, number_of_sentences):\n",
    "    \n",
    "    len_array = np.cumsum(np.array(data['SENTS'].apply(lambda x: len(x))))\n",
    "    dictionary_lists = []\n",
    "    batches = []\n",
    "    \n",
    "    unit_counter = 0\n",
    "    \n",
    "    for count, instance in enumerate(dataset, 1):\n",
    "        \n",
    "        dictionary_lists.append(instance)\n",
    "        unit_counter += 1\n",
    "        \n",
    "        if (unit_counter % number_of_sentences == 0) or (count in len_array):\n",
    "            \n",
    "            padded_ids = pad_sequence([torch.tensor(instance['ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_ids = padded_ids.to(device)\n",
    "\n",
    "            padded_segment_ids = pad_sequence([torch.tensor(instance['segment_ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_segment_ids = padded_segment_ids.to(device)\n",
    "\n",
    "            padded_mask_ids = pad_sequence([torch.tensor(instance['mask_ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_mask_ids = padded_mask_ids.to(device)\n",
    "\n",
    "            labels = torch.stack([torch.tensor(instance['labels']) for instance in dictionary_lists])\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            current_dev_batch = {'ids': padded_ids, 'mask_ids': padded_mask_ids, 'segment_ids': padded_segment_ids, 'labels': labels}\n",
    "\n",
    "            batches.append(current_dev_batch)\n",
    "            dictionary_lists = []\n",
    "            unit_counter = 0\n",
    "    \n",
    "    return batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_window_sentence_preprocessing(data, dataset, number_of_sentences):\n",
    "    \n",
    "    len_array = np.cumsum(np.array(data['SENTS'].apply(lambda x: len(x))))\n",
    "    dictionary_lists = []\n",
    "    batches = []\n",
    "    \n",
    "    unit_counter = 0\n",
    "\n",
    "    for i in range(1, len(dataset) + 1):\n",
    "        \n",
    "        # Need to pad zeros\n",
    "        dictionary_lists.append(dataset[i-1])\n",
    "        dictionary_lists\n",
    "        unit_counter += 1\n",
    "        \n",
    "        if (unit_counter % number_of_sentences == 0) or (i in len_array):\n",
    "            \n",
    "            padded_ids = pad_sequence([torch.tensor(instance['ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_ids = padded_ids.to(device)\n",
    "\n",
    "            padded_segment_ids = pad_sequence([torch.tensor(instance['segment_ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_segment_ids = padded_segment_ids.to(device)\n",
    "\n",
    "            padded_mask_ids = pad_sequence([torch.tensor(instance['mask_ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_mask_ids = padded_mask_ids.to(device)\n",
    "\n",
    "            labels = torch.stack([torch.tensor(instance['labels']) for instance in dictionary_lists])\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            current_dev_batch = {'ids': padded_ids, 'mask_ids': padded_mask_ids, 'segment_ids': padded_segment_ids, 'labels': labels}\n",
    "\n",
    "            batches.append(current_dev_batch)\n",
    "            dictionary_lists = []\n",
    "            unit_counter = 0\n",
    "    \n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_preprocessing(data, dataset):\n",
    "    \n",
    "    len_array = np.cumsum(np.array(data['SENTS'].apply(lambda x: len(x))))\n",
    "\n",
    "    dictionary_lists = []\n",
    "    batches = []\n",
    "    for i in range(len(dataset.instances)):\n",
    "        \n",
    "        instance = dataset.instances[i]\n",
    "        dictionary_lists.append(instance)\n",
    "        \n",
    "        if i in len_array - 1:\n",
    "\n",
    "            padded_ids = pad_sequence([torch.tensor(instance['ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_ids = padded_ids.to(device)\n",
    "\n",
    "            padded_segment_ids = pad_sequence([torch.tensor(instance['segment_ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_segment_ids = padded_segment_ids.to(device)\n",
    "\n",
    "            padded_mask_ids = pad_sequence([torch.tensor(instance['mask_ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_mask_ids = padded_mask_ids.to(device)\n",
    "\n",
    "            labels = torch.stack([torch.tensor(instance['labels']) for instance in dictionary_lists])\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            \n",
    "            current_dev_batch = {'ids': padded_ids, 'mask_ids': padded_mask_ids, 'segment_ids': padded_segment_ids, 'labels': labels}\n",
    "\n",
    "            batches.append(current_dev_batch)\n",
    "            dictionary_lists = []\n",
    "\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_eval_preprocessing(data, dataset): \n",
    "    \n",
    "    len_array = np.cumsum(np.array(data['SENTS'].apply(lambda x: len(x))))\n",
    "\n",
    "    dictionary_lists = []\n",
    "    batches = []\n",
    "    for i in range(len(dataset.instances)):\n",
    "        \n",
    "        instance = dataset.instances[i]\n",
    "        dictionary_lists.append(instance)\n",
    "        \n",
    "        if i in len_array - 1:\n",
    "\n",
    "            \n",
    "            padded_ids = pad_sequence([torch.tensor(instance['ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_ids = padded_ids.to(device)\n",
    "\n",
    "            #padded_segment_ids = pad_sequence([torch.tensor(instance['segment_ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            #padded_segment_ids = padded_segment_ids.to(device)\n",
    "\n",
    "            padded_mask_ids = pad_sequence([torch.tensor(instance['mask_ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_mask_ids = padded_mask_ids.to(device)\n",
    "            \n",
    "            padded_sentence_masks = pad_sequence([torch.tensor(instance['sentence_mask']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_sentence_masks = padded_sentence_masks.to(device)\n",
    "            \n",
    "            padded_q_ids = pad_sequence([torch.tensor(instance['q_ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_q_ids = padded_q_ids.to(device)\n",
    "            \n",
    "            padded_q_mask_ids = pad_sequence([torch.tensor(instance['q_mask_ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_q_mask_ids = padded_q_mask_ids.to(device)\n",
    "\n",
    "            labels = torch.stack([torch.tensor(instance['labels']) for instance in dictionary_lists])\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            \n",
    "            current_dev_batch = {'ids': padded_ids, 'mask_ids': padded_mask_ids, 'sentence_mask': padded_sentence_masks,\n",
    "                                 'labels': labels, 'q_ids': padded_q_ids, \"q_mask_ids\": padded_q_mask_ids}\n",
    "\n",
    "            batches.append(current_dev_batch)\n",
    "            dictionary_lists = []\n",
    "\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_instances, dev_ids, dev_seg_ids, dev_mask_ids, dev_labels = datapreprocessing(dev_data)\n",
    "train_instances, train_ids, train_seg_ids, train_mask_ids, train_labels = datapreprocessing(training_data)\n",
    "test_instances, test_ids, test_seg_ids, test_mask_ids, test_labels = datapreprocessing(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0811 02:29:23.051539 139897081689920 tokenization_utils.py:375] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /root/.cache/torch/transformers/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00\n"
     ]
    }
   ],
   "source": [
    "qs_instances, qs_ids, qs_mask_ids, qs_sen_mask, qs_labels = data_to_sentence(training_data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0811 02:29:56.492766 139897081689920 tokenization_utils.py:375] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /root/.cache/torch/transformers/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00\n"
     ]
    }
   ],
   "source": [
    "dev_qs_instances, dev_qs_ids, dev_qs_mask_ids, dev_qs_sen_mask, dev_qs_labels = data_to_sentence(validation_data, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, ids, segment_ids, mask_ids, labels):\n",
    "        self.instances = []\n",
    "        for ids_i, segment_ids_i, mask_ids, label in zip(ids, segment_ids, mask_ids, labels):\n",
    "            self.instances.append({\"ids\": ids_i, \"segment_ids\": segment_ids_i, \n",
    "                                   \"mask_ids\": mask_ids, \"labels\": label})  \n",
    "                                   \n",
    "    def __len__(self):\n",
    "        return len(self.instances)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.instances[idx]\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionSentenceDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, ids, mask_ids, sen_masks, labels):\n",
    "        self.instances = []\n",
    "        for ids_i, mask_ids, sen_mask, label in zip(ids, mask_ids, sen_masks, labels):\n",
    "            self.instances.append({\"ids\": torch.tensor(ids_i[1]), \"mask_ids\": torch.tensor(mask_ids[1]), \n",
    "                                   \"sentence_mask\": torch.tensor(sen_mask), \"labels\": torch.tensor(label), \n",
    "                                   \"q_ids\": torch.tensor(ids_i[0]), \"q_mask_ids\": torch.tensor(mask_ids[0])})\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.instances)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.instances[idx]\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SentenceDataset(train_ids, train_seg_ids, train_mask_ids, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset = SentenceDataset(dev_ids, dev_seg_ids, dev_mask_ids, dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SentenceDataset(test_ids, test_seg_ids, test_mask_ids, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_train_dataset = QuestionSentenceDataset(qs_ids, qs_mask_ids, qs_sen_mask, qs_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_dev_dataset = QuestionSentenceDataset(dev_qs_ids, dev_qs_mask_ids, dev_qs_sen_mask, dev_qs_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    padded_ids = pad_sequence([torch.tensor(instance['ids']) for instance in batch], batch_first=True)\n",
    "    padded_ids = padded_ids.to(device)\n",
    "    \n",
    "    padded_segment_ids = pad_sequence([torch.tensor(instance['segment_ids']) for instance in batch], batch_first=True)\n",
    "    padded_segment_ids = padded_segment_ids.to(device)\n",
    "    \n",
    "    padded_mask_ids = pad_sequence([torch.tensor(instance['mask_ids']) for instance in batch], batch_first=True)\n",
    "    padded_mask_ids = padded_mask_ids.to(device)\n",
    "    \n",
    "    labels = torch.stack([torch.tensor(instance['labels']) for instance in batch])\n",
    "    labels = labels.to(device)\n",
    "    return {'ids': padded_ids, 'mask_ids': padded_mask_ids, 'segment_ids': padded_segment_ids, 'labels': labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_3d(batch):\n",
    "    \n",
    "    batch_size = len(batch)\n",
    "    \n",
    "    max_num_sentences, max_sentence_length = find_max_dimension(batch)\n",
    "    \n",
    "    # sentence weight\n",
    "    sentence_mask = torch.zeros(batch_size, max_num_sentences)\n",
    "    \n",
    "    \n",
    "    target_ids = torch.zeros(batch_size, max_num_sentences, max_sentence_length)\n",
    "    target_segment_ids = torch.zeros(batch_size, max_num_sentences, max_sentence_length)\n",
    "    target_mask_ids = torch.zeros(batch_size, max_num_sentences, max_sentence_length)\n",
    "    target_labels = torch.zeros(batch_size, max_num_sentences, 1)\n",
    "    for i in range(len(batch)):\n",
    "        \n",
    "        source_id_dimension = batch[i]['ids'].shape\n",
    "        \n",
    "        sentence_mask[i, :source_id_dimension[0]] = 1\n",
    "        \n",
    "        target_ids[i, :source_id_dimension[0], :source_id_dimension[1]] = batch[i]['ids']\n",
    "        \n",
    "        source_segment_id_dimension = batch[i]['segment_ids'].shape\n",
    "        target_segment_ids[i, :source_segment_id_dimension[0], :source_segment_id_dimension[1]] = batch[i]['segment_ids']\n",
    "        \n",
    "        source_mask_id_dimension = batch[i]['mask_ids'].shape\n",
    "        target_mask_ids[i, :source_mask_id_dimension[0], :source_mask_id_dimension[1]] = batch[i]['mask_ids']\n",
    "        \n",
    "        source_label_dimension = batch[i]['labels'].shape\n",
    "        target_labels[i, :source_label_dimension[0], :source_label_dimension[1]] = batch[i]['labels']\n",
    "    \n",
    "    target_labels = target_labels.squeeze(-1)\n",
    "    \n",
    "    target_ids = target_ids.to(device).to(torch.long)\n",
    "    target_segment_ids = target_segment_ids.to(device).to(torch.long)\n",
    "    target_mask_ids = target_segment_ids.to(device).to(torch.long)\n",
    "    target_labels = target_labels.to(dtype=torch.float, device=device)\n",
    "    sentence_mask = sentence_mask.to(device).to(torch.float)\n",
    "    return {'ids': target_ids, 'mask_ids': target_mask_ids, 'segment_ids': target_segment_ids, 'labels': target_labels, 'sentence_mask': sentence_mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_2d(batch):\n",
    "    \n",
    "    batch_size = len(batch)\n",
    "    \n",
    "    max_num_sentences, max_sentence_length = find_max_dimension(batch)\n",
    "    \n",
    "    # sentence weight\n",
    "    #sentence_mask = torch.zeros(batch_size, max_num_sentences)\n",
    "    \n",
    "    \n",
    "    target_ids = torch.zeros(max_num_sentences, max_sentence_length)\n",
    "    target_segment_ids = torch.zeros(max_num_sentences, max_sentence_length)\n",
    "    target_mask_ids = torch.zeros(max_num_sentences, max_sentence_length)\n",
    "    target_labels = torch.zeros(max_num_sentences, 1)\n",
    "    for i in range(len(batch)):\n",
    "        \n",
    "        source_id_dimension = batch[i]['ids'].shape\n",
    "        \n",
    "        #sentence_mask[:source_id_dimension[0]] = 1\n",
    "        \n",
    "        target_ids[:source_id_dimension[0], :source_id_dimension[1]] = batch[i]['ids']\n",
    "        \n",
    "        source_segment_id_dimension = batch[i]['segment_ids'].shape\n",
    "        target_segment_ids[:source_segment_id_dimension[0], :source_segment_id_dimension[1]] = batch[i]['segment_ids']\n",
    "        \n",
    "        source_mask_id_dimension = batch[i]['mask_ids'].shape\n",
    "        target_mask_ids[:source_mask_id_dimension[0], :source_mask_id_dimension[1]] = batch[i]['mask_ids']\n",
    "        \n",
    "        source_label_dimension = batch[i]['labels'].shape\n",
    "        target_labels[:source_label_dimension[0], :source_label_dimension[1]] = batch[i]['labels']\n",
    "\n",
    "    #target_labels = target_labels.squeeze(-1)\n",
    "    \n",
    "    target_ids = target_ids.to(device).to(torch.long)\n",
    "    target_segment_ids = target_segment_ids.to(device).to(torch.long)\n",
    "    target_mask_ids = target_segment_ids.to(device).to(torch.long)\n",
    "    target_labels = target_labels.to(dtype=torch.float, device=device)\n",
    "    #sentence_mask = sentence_mask.to(device).to(torch.float)\n",
    "    return {'ids': target_ids, 'mask_ids': target_mask_ids, 'segment_ids': target_segment_ids, 'labels': target_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_dimension(batch):\n",
    "    num_sentences = []\n",
    "    sentence_lengths = []\n",
    "    for question in batch:\n",
    "        num_sentences.append(question['ids'].shape[0])\n",
    "        sentence_lengths.append(question['ids'].shape[1])\n",
    "    return max(num_sentences), max(sentence_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_train_batches = window_sentence_preprocessing(training_data, train_dataset, 10)\n",
    "#new_train_2d_batches = window_sentence_preprocessing(training_data, train_dataset, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_train_batches[4]['ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(train_dataset, batch_size=8, shuffle = True, collate_fn = collate)\n",
    "dataloader_dev = DataLoader(dev_dataset, batch_size=4, collate_fn = collate)\n",
    "#dataloader_train_3d = DataLoader(new_train_batches, batch_size=2, shuffle = True, collate_fn = collate_3d)\n",
    "#dataloader_train_2d = DataLoader(new_train_2d_batches, batch_size=8, shuffle = True, collate_fn = collate_2d)\n",
    "#dataloader_sent_train = DataLoader(sent_train_dataset, batch_size = 4, shuffle = True)\n",
    "#dataloader_sent_train_eval = DataLoader(sent_train_dataset, batch_size = 1)\n",
    "#dataloader_sent_dev = DataLoader(sent_dev_dataset, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_data['QUESTIONS'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0820 08:07:05.706097 140476680402752 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json from cache at /root/.cache/torch/transformers/8a3b1cfe5da58286e12a0f5d7d182b8d6eca88c08e26c332ee3817548cf7e60a.f12a4f986e43d8b328f5b067a641064d67b91597567a06c7b122d1ca7dfd9741\n",
      "I0820 08:07:05.708496 140476680402752 configuration_utils.py:300] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "I0820 08:07:06.022052 140476680402752 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-chinese-pytorch_model.bin from cache at /root/.cache/torch/transformers/a75f2e45a9463e784dfe8c1d9672440d5fc1b091d5ab104e3c2d82e90ab1b222.929717ca66a3ba9eb9ec2f85973c6398c54c38a4faa464636a491d7a705f7eb6\n",
      "W0820 08:07:08.422382 140476680402752 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForNextSentencePrediction: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "I0820 08:07:08.423488 140476680402752 modeling_utils.py:774] All the weights of BertForNextSentencePrediction were initialized from the model checkpoint at bert-base-chinese.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertForNextSentencePrediction for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bertnsp = BertForNextSentencePrediction.from_pretrained('bert-base-chinese')\n",
    "bertnsp.to(device)\n",
    "a = iter(dataloader_train).next()\n",
    "nsp_output = bertnsp(a['ids'].to(device), a['mask_ids'].to(device), a['segment_ids'].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1., 0.]]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[[0.0], [1.0], [0.0]]]).transpose(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "#print(nsp_output[0])\n",
    "softmax(nsp_output[0][:, 0].unsqueeze(0)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentence_lengths = []\n",
    "dev_sentence_lengths = []\n",
    "test_sentence_lengths = []\n",
    "\n",
    "for instance_dict in train_dataset.instances:\n",
    "    train_sentence_lengths.append(len(instance_dict['ids']))\n",
    "    \n",
    "for instance_dict in dev_dataset.instances:\n",
    "    dev_sentence_lengths.append(len(instance_dict['ids']))\n",
    "    \n",
    "for instance_dict in test_dataset.instances:\n",
    "    test_sentence_lengths.append(len(instance_dict['ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data >512 percentage: 0.0\n",
      "dev data >512 percentage: 0.0\n",
      "test data >512 percentage: 0.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(train_sentence_lengths, bins=100)\n",
    "plt.hist(dev_sentence_lengths, bins=100)\n",
    "plt.hist(test_sentence_lengths, bins=100)\n",
    "print('train data >512 percentage:', (np.array(train_sentence_lengths) > 512).sum() / len(train_sentence_lengths))\n",
    "print('dev data >512 percentage:', (np.array(dev_sentence_lengths) > 512).sum() / len(dev_sentence_lengths))\n",
    "print('test data >512 percentage:', (np.array(test_sentence_lengths) > 512).sum() / len(test_sentence_lengths))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class baseline_model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(baseline_model, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-chinese')\n",
    "        self.linear = nn.Linear(768, 1)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        # batch['ids'] = (batch_size, sent_len)\n",
    "        # batch['segment_ids'] = (batch_size, sent_len)\n",
    "        # batch['mask_ids'] = (batch_size, sent_len)\n",
    "        # pooler_output = (batch_size, 768)\n",
    "        # output = (batch_size, 1)\n",
    "        hidden_state, pooler_output = self.bert(batch['ids'], batch['mask_ids'], batch['segment_ids'])\n",
    "        \n",
    "        \n",
    "        linear_output = self.linear(pooler_output)\n",
    "\n",
    "        return linear_output\n",
    "\n",
    "    def loss(self, batch):\n",
    "        \n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "        output = self.forward(batch)\n",
    "        target = batch['labels'].float().to(device)\n",
    "        return loss_fn(output, target)\n",
    "    \n",
    "    def _predict(self, batch):\n",
    "        \n",
    "        output = self.forward(batch)\n",
    "        scores = torch.sigmoid(output)\n",
    "        scores = scores.cpu().numpy()[:,0].tolist()\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    def predict_fgc(self, batch, threshold=0.5):\n",
    "        \n",
    "        scores = self._predict(batch)\n",
    "        max_i = 0\n",
    "        max_score = 0\n",
    "        sp = []\n",
    "        \n",
    "        for i, score in enumerate(scores):\n",
    "\n",
    "            if score > max_score:\n",
    "                max_i = i\n",
    "                max_score = score\n",
    "            if score >= threshold:\n",
    "                sp.append(i)\n",
    "\n",
    "        #if not sp:\n",
    "            #sp.append(max_i)\n",
    "\n",
    "        return {'sp': sp, 'sp_scores': scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0827 07:13:30.841258 140639700354880 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json from cache at /root/.cache/torch/transformers/8a3b1cfe5da58286e12a0f5d7d182b8d6eca88c08e26c332ee3817548cf7e60a.f12a4f986e43d8b328f5b067a641064d67b91597567a06c7b122d1ca7dfd9741\n",
      "I0827 07:13:30.843287 140639700354880 configuration_utils.py:300] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "I0827 07:13:30.891120 140639700354880 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-chinese-pytorch_model.bin from cache at /root/.cache/torch/transformers/a75f2e45a9463e784dfe8c1d9672440d5fc1b091d5ab104e3c2d82e90ab1b222.929717ca66a3ba9eb9ec2f85973c6398c54c38a4faa464636a491d7a705f7eb6\n",
      "I0827 07:13:32.566750 140639700354880 modeling_utils.py:765] All model checkpoint weights were used when initializing BertModel.\n",
      "\n",
      "I0827 07:13:32.567798 140639700354880 modeling_utils.py:774] All the weights of BertModel were initialized from the model checkpoint at bert-base-chinese.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "baseline_model(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline = baseline_model()\n",
    "baseline.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Baseline Model & Evaluating Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optim(nn, num_epochs, lr):\n",
    "    param_optimizer = list(nn.bert.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "    num_epochs = num_epochs\n",
    "    num_train_optimization_steps = len(dataloader_train) * num_epochs\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=lr)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                     num_warmup_steps=int(\n",
    "                                                         num_train_optimization_steps * 0.1),\n",
    "                                                     num_training_steps=num_train_optimization_steps)\n",
    "    return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _update_sp(metrics, sp_gold, sp_pred):\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "        \n",
    "    for p in sp_pred:\n",
    "        if p in sp_gold:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "    for g in sp_gold:\n",
    "        if g not in sp_pred:\n",
    "            fn += 1\n",
    "            \n",
    "    precision = 1.0 * tp / (tp + fp) if tp + fp > 0 else 0.0\n",
    "    recall = 1.0 * tp / (tp + fn) if tp + fn > 0 else 0.0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0.0\n",
    "    em = 1.0 if fp + fn == 0 else 0.0\n",
    "    \n",
    "    metrics['sp_em'] += em\n",
    "    metrics['sp_f1'] += f1\n",
    "    metrics['sp_prec'] += precision\n",
    "    metrics['sp_recall'] += recall\n",
    "    \n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_sp_fgc(sp_golds, sp_preds):\n",
    "    \n",
    "    metrics = {'sp_em': 0, 'sp_prec': 0, 'sp_recall': 0, 'sp_f1': 0}\n",
    "    \n",
    "    assert len(sp_golds) == len(sp_preds)\n",
    "    \n",
    "    for sp_gold, sp_pred in zip(sp_golds, sp_preds):\n",
    "        _update_sp(metrics, sp_gold, sp_pred)\n",
    "    \n",
    "    N = len(sp_golds)\n",
    "    for k in metrics.keys():\n",
    "        metrics[k] /= N\n",
    "        metrics[k] = round(metrics[k], 3)\n",
    "    print(metrics)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fgc_atype(atype_golds, atype_preds):\n",
    "    \n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    \n",
    "    for gold, atype in zip(atype_golds, atype_preds):\n",
    "        if atype == gold:\n",
    "            pos += 1\n",
    "        else:\n",
    "            neg += 1\n",
    "    return pos/len(atypes_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(network, dev_batches, current_epoch, sp_golds, avg_loss):\n",
    "    \n",
    "    network.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        sp_preds = []\n",
    "        sp_scores = []\n",
    "        for batch in tqdm(dev_batches):\n",
    "            \n",
    "            out_dct = network.predict_fgc(batch)\n",
    "            sp_preds.append(out_dct['sp'])\n",
    "            sp_scores.append(out_dct['sp_scores'])\n",
    "    metrics = eval_sp_fgc(sp_golds, sp_preds)\n",
    "    print('epoch %d eval_recall: %.3f eval_f1: %.3f loss: %.3f' % (\n",
    "            current_epoch, metrics['sp_recall'], metrics['sp_f1'], avg_loss))\n",
    "        \n",
    "    torch.save(network.state_dict(), \"Models_SEs/baseline_batchsize_8/model_epoch{0}_eval_em:{1:.3f}_precision:{2:.3f}_recall:{3:.3f}_f1:{4:.3f}_loss:{5:.3f}.m\".format(current_epoch, metrics['sp_em'], metrics['sp_prec'], metrics['sp_recall'], metrics['sp_f1'], avg_loss))\n",
    "    \n",
    "    return sp_preds, sp_golds, sp_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(network, data, dev_batches, num_epochs, lr):\n",
    "    \n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer, scheduler = optim(network, num_epochs, lr)\n",
    "    \n",
    "    sp_golds = dev_data['QUESTIONS'].apply(lambda x: x[0]['SHINT_']).tolist()\n",
    "    \n",
    "    for current_epoch in range(num_epochs):\n",
    "        network.train()\n",
    "        running_loss = 0.0\n",
    "        for batch in tqdm(data):\n",
    "            optimizer.zero_grad()\n",
    "            current_output = network(batch)\n",
    "            current_target = batch['labels'].to(dtype=torch.float, device=device)\n",
    "            current_loss = loss_fn(current_output, current_target)\n",
    "            current_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(network.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            running_loss += current_loss.item()\n",
    "            \n",
    "        learning_rate_scalar = scheduler.get_lr()[0]\n",
    "        print('lr = %f' % learning_rate_scalar)\n",
    "        avg_loss = running_loss/len(data)\n",
    "        print('epoch %d train_loss: %.3f' % (current_epoch, avg_loss))\n",
    "        eval(network, dev_batches, current_epoch, sp_golds, avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_batches = eval_preprocessing(dev_data, dev_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 29/3884 [00:02<06:11, 10.36it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 10.73 GiB total capacity; 9.32 GiB already allocated; 6.69 MiB free; 482.35 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-1cb7d4bf0325>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.00002\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# if you want to run this again, rememebr to add the parameter 'batches'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-39-0548675d724d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(network, data, dev_batches, num_epochs, lr)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mcurrent_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mcurrent_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-867bccf4c8ff>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# pooler_output = (batch_size, 768)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# output = (batch_size, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooler_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'segment_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_extended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m         )\n\u001b[1;32m    764\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m    437\u001b[0m                     \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m                 )\n\u001b[1;32m    441\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add cross attentions if we output attention weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/activations.py\u001b[0m in \u001b[0;36m_gelu_python\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mAlso\u001b[0m \u001b[0msee\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0marxiv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1606.08415\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \"\"\"\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 10.73 GiB total capacity; 9.32 GiB already allocated; 6.69 MiB free; 482.35 MiB cached)"
     ]
    }
   ],
   "source": [
    "train(baseline, dataloader_train, dev_batches, 20, 0.00002) # if you want to run this again, rememebr to add the parameter 'batches'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0826 03:36:24.604294 140100540692288 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json from cache at /root/.cache/torch/transformers/8a3b1cfe5da58286e12a0f5d7d182b8d6eca88c08e26c332ee3817548cf7e60a.f12a4f986e43d8b328f5b067a641064d67b91597567a06c7b122d1ca7dfd9741\n",
      "I0826 03:36:24.606930 140100540692288 configuration_utils.py:300] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "I0826 03:36:24.649986 140100540692288 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-chinese-pytorch_model.bin from cache at /root/.cache/torch/transformers/a75f2e45a9463e784dfe8c1d9672440d5fc1b091d5ab104e3c2d82e90ab1b222.929717ca66a3ba9eb9ec2f85973c6398c54c38a4faa464636a491d7a705f7eb6\n",
      "I0826 03:36:26.365756 140100540692288 modeling_utils.py:765] All model checkpoint weights were used when initializing BertModel.\n",
      "\n",
      "I0826 03:36:26.367031 140100540692288 modeling_utils.py:774] All the weights of BertModel were initialized from the model checkpoint at bert-base-chinese.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "baseline_model(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_baseline = baseline_model()\n",
    "trained_baseline.load_state_dict(torch.load('Models_SEs/baseline/model_epoch11_eval_em:0.172_precision:0.596_recall:0.556_f1:0.529_loss:0.029.m'))\n",
    "trained_baseline.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0821 03:31:45.674727 140430917494592 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json from cache at /root/.cache/torch/transformers/8a3b1cfe5da58286e12a0f5d7d182b8d6eca88c08e26c332ee3817548cf7e60a.f12a4f986e43d8b328f5b067a641064d67b91597567a06c7b122d1ca7dfd9741\n",
      "I0821 03:31:45.676812 140430917494592 configuration_utils.py:300] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "I0821 03:31:45.718839 140430917494592 modeling_utils.py:667] loading weights file https://cdn.huggingface.co/bert-base-chinese-pytorch_model.bin from cache at /root/.cache/torch/transformers/a75f2e45a9463e784dfe8c1d9672440d5fc1b091d5ab104e3c2d82e90ab1b222.929717ca66a3ba9eb9ec2f85973c6398c54c38a4faa464636a491d7a705f7eb6\n",
      "W0821 03:31:48.020285 140430917494592 modeling_utils.py:757] Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForNextSentencePrediction: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "I0821 03:31:48.021350 140430917494592 modeling_utils.py:774] All the weights of BertForNextSentencePrediction were initialized from the model checkpoint at bert-base-chinese.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertForNextSentencePrediction for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultiBERTsModel(\n",
       "  (bertNSP): BertForNextSentencePrediction(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (cls): BertOnlyNSPHead(\n",
       "      (seq_relationship): Linear(in_features=768, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (softmax): Softmax(dim=1)\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (sp_linear): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twoberts = MultiBERTsModel(3, True, trained_baseline, False)\n",
    "twoberts.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load('Models_SEs/attn_aggregate/model_epoch10_eval_em:0.172_precision:0.524_recall:0.504_f1:0.477_loss:0.002.m')\n",
    "# create new OrderedDict that does not contain `module.`\n",
    "from collections import OrderedDict\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    name = k[7:] # remove `module.`\n",
    "    new_state_dict[name] = v\n",
    "# load params\n",
    "twoberts.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 871/871 [00:58<00:00, 14.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sp_em': 0.905, 'sp_prec': 0.988, 'sp_recall': 0.97, 'sp_f1': 0.973}\n",
      "epoch 0 eval_recall: 0.970 eval_f1: 0.973 loss: 0.001\n"
     ]
    }
   ],
   "source": [
    "sp_golds = training_data['QUESTIONS'].apply(lambda x: x[0]['SHINT_']).tolist()\n",
    "batches = eval_preprocessing(training_data, train_dataset)\n",
    "\n",
    "trained_baseline.to(\"cuda\")\n",
    "train_pred, train_obs, train_scores = eval(trained_baseline, batches, 0, sp_golds, 0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 239/239 [00:17<00:00, 11.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sp_em': 0.172, 'sp_prec': 0.596, 'sp_recall': 0.556, 'sp_f1': 0.529}\n",
      "epoch 0 eval_recall: 0.556 eval_f1: 0.529 loss: 0.001\n"
     ]
    }
   ],
   "source": [
    "sp_golds = dev_data['QUESTIONS'].apply(lambda x: x[0]['SHINT_']).tolist()\n",
    "dev_batches = eval_preprocessing(dev_data, dev_dataset)\n",
    "dev_preds, dev_obs, dev_scores = eval(trained_baseline, dev_batches, 0, sp_golds, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190/190 [00:11<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sp_em': 0.163, 'sp_prec': 0.629, 'sp_recall': 0.565, 'sp_f1': 0.545}\n",
      "epoch 0 eval_recall: 0.565 eval_f1: 0.545 loss: 0.001\n"
     ]
    }
   ],
   "source": [
    "sp_golds = test_data['QUESTIONS'].apply(lambda x: x[0]['SHINT_']).tolist()\n",
    "test_batches = eval_preprocessing(test_data, test_dataset)\n",
    "test_preds, test_obs, test_scores = eval(trained_baseline, test_batches, 0, sp_golds, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data_with_performance = datapreprocessing(dev_data, True)\n",
    "training_data_with_performance = datapreprocessing(training_data, True)\n",
    "test_data_with_performance = datapreprocessing(test_data, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_with_performance['train_pred'] = train_pred\n",
    "training_data_with_performance['train_obs'] = train_obs\n",
    "training_data_with_performance['train_scores'] = train_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_sp = []\n",
    "for i in range(training_data_with_performance.shape[0]):\n",
    "    para = training_data_with_performance['Sentence_List'][i]\n",
    "    sen = []\n",
    "    for index in training_data_with_performance['train_pred'][i]:\n",
    "        sen.append(para[index])\n",
    "    correct_sp.append(sen)\n",
    "training_data_with_performance['Pred_List'] = correct_sp\n",
    "correct_sp = []\n",
    "for i in range(training_data_with_performance.shape[0]):\n",
    "    para = training_data_with_performance['Sentence_List'][i]\n",
    "    sen = []\n",
    "    for index in training_data_with_performance['train_obs'][i]:\n",
    "        sen.append(para[index])\n",
    "    correct_sp.append(sen)\n",
    "training_data_with_performance['Obs_List'] = correct_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_with_performance.drop(['SE_Index', 'Label'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Sentence_List</th>\n",
       "      <th>Length</th>\n",
       "      <th>train_pred</th>\n",
       "      <th>train_obs</th>\n",
       "      <th>train_scores</th>\n",
       "      <th>Pred_List</th>\n",
       "      <th>Obs_List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>苏东坡死于哪一年?</td>\n",
       "      <td>[元祐元年（1086年），, 宋哲宗即位，, 高太皇太后垂帘听政，, 回朝任礼部郎中、中书舍...</td>\n",
       "      <td>32</td>\n",
       "      <td>[17]</td>\n",
       "      <td>[12, 17]</td>\n",
       "      <td>[4.585612623486668e-05, 1.6881973351701163e-05...</td>\n",
       "      <td>[七月二十八日于常州孙氏馆病卒，]</td>\n",
       "      <td>[\\n建中靖国元年（1101年），, 七月二十八日于常州孙氏馆病卒，]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>形成于北大西洋的热带气旋，又被称为什么？</td>\n",
       "      <td>[台风（英语：Typhoon，香港天文台缩写T.；日语：台风/たいふう/taifū；韩语：태...</td>\n",
       "      <td>17</td>\n",
       "      <td>[16]</td>\n",
       "      <td>[9, 16]</td>\n",
       "      <td>[2.2695174266118556e-05, 8.305213850690052e-05...</td>\n",
       "      <td>[例如北太平洋西部称为「台风」、北大西洋称为「飓风」、北印度洋称为「气旋风暴」。]</td>\n",
       "      <td>[将中心持续风速每秒17.2米或以上的热带气旋（包括世界气象组织定义中的热带风暴、强烈热带风...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>形成于北太平洋的热带气旋，又被称为什么？</td>\n",
       "      <td>[台风（英语：Typhoon，香港天文台缩写T.；日语：台风/たいふう/taifū；韩语：태...</td>\n",
       "      <td>17</td>\n",
       "      <td>[16]</td>\n",
       "      <td>[11, 16]</td>\n",
       "      <td>[2.2008725863997824e-05, 3.163578730891459e-05...</td>\n",
       "      <td>[例如北太平洋西部称为「台风」、北大西洋称为「飓风」、北印度洋称为「气旋风暴」。]</td>\n",
       "      <td>[「台风」甚至直接泛指热带气旋本身。, 例如北太平洋西部称为「台风」、北大西洋称为「飓风」、...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>形成于北印度洋的热带气旋，又被称为什么？</td>\n",
       "      <td>[台风（英语：Typhoon，香港天文台缩写T.；日语：台风/たいふう/taifū；韩语：태...</td>\n",
       "      <td>17</td>\n",
       "      <td>[16]</td>\n",
       "      <td>[11, 16]</td>\n",
       "      <td>[2.4452738216496073e-05, 1.7731041225488298e-0...</td>\n",
       "      <td>[例如北太平洋西部称为「台风」、北大西洋称为「飓风」、北印度洋称为「气旋风暴」。]</td>\n",
       "      <td>[「台风」甚至直接泛指热带气旋本身。, 例如北太平洋西部称为「台风」、北大西洋称为「飓风」、...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>发生于美国的热带气旋，我们叫它什么？</td>\n",
       "      <td>[台风（英语：Typhoon，香港天文台缩写T.；日语：台风/たいふう/taifū；韩语：태...</td>\n",
       "      <td>17</td>\n",
       "      <td>[11]</td>\n",
       "      <td>[11, 16]</td>\n",
       "      <td>[1.8374197679804638e-05, 1.3571444469562266e-0...</td>\n",
       "      <td>[「台风」甚至直接泛指热带气旋本身。]</td>\n",
       "      <td>[「台风」甚至直接泛指热带气旋本身。, 例如北太平洋西部称为「台风」、北大西洋称为「飓风」、...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>777</td>\n",
       "      <td>文中提及的自动贩卖机卖的是什么？</td>\n",
       "      <td>[动物小学在公园里举行户外教学，, 小动物们看到一个像玻璃柜子一样的机器，, 里面摆著一个个...</td>\n",
       "      <td>35</td>\n",
       "      <td>[13, 27, 28]</td>\n",
       "      <td>[27, 28]</td>\n",
       "      <td>[0.00016559450887143612, 2.908718670369126e-05...</td>\n",
       "      <td>[一位高班的同学走过来说：「这是自动贩卖机，卖的都是饮料。」一面说著，, \\n胖小熊高兴的拍...</td>\n",
       "      <td>[\\n胖小熊高兴的拍手说：「这下可好了，以后出来玩，就不要带水壶，只要带些铜板来买饮料就好了...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>781</td>\n",
       "      <td>晏子来到楚国的时候，楚王是否下令开城门以礼相待迎接？</td>\n",
       "      <td>[春秋时代，齐国和楚国都是有名的大国。, 有一次，齐王派晏子出使到楚国去。, 楚王听说晏子智...</td>\n",
       "      <td>26</td>\n",
       "      <td>[2, 5, 8]</td>\n",
       "      <td>[2, 5]</td>\n",
       "      <td>[1.2578303540067282e-05, 1.7875763660413213e-0...</td>\n",
       "      <td>[楚王听说晏子智慧高、口才好，, 存心想羞辱他，, 楚王下令把城门关上，]</td>\n",
       "      <td>[楚王听说晏子智慧高、口才好，, 存心想羞辱他，]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>821</td>\n",
       "      <td>青河的硕士学位在哪一个国家念的?</td>\n",
       "      <td>[为倾听新住民心声，, 内政部移民署今(18)日下午，, 在台南市举办新住民座谈会，, 有2...</td>\n",
       "      <td>56</td>\n",
       "      <td>[19, 20]</td>\n",
       "      <td>[10, 19, 20]</td>\n",
       "      <td>[1.0251031199004501e-05, 1.1121333045593929e-0...</td>\n",
       "      <td>[青河得以持续进修，, 她不仅取得国立成功大学硕士学位，]</td>\n",
       "      <td>[青河毕业于越南河内国家大学法文系，, 青河得以持续进修，, 她不仅取得国立成功大学硕士学位，]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>826</td>\n",
       "      <td>青河目前的职业为何?</td>\n",
       "      <td>[为倾听新住民心声，, 内政部移民署今(18)日下午，, 在台南市举办新住民座谈会，, 有2...</td>\n",
       "      <td>56</td>\n",
       "      <td>[10, 19]</td>\n",
       "      <td>[19, 23]</td>\n",
       "      <td>[1.0657003258529585e-05, 1.1454480954853352e-0...</td>\n",
       "      <td>[青河毕业于越南河内国家大学法文系，, 青河得以持续进修，]</td>\n",
       "      <td>[青河得以持续进修，, 目前除受聘于成功大学担任越语讲师，]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>858</td>\n",
       "      <td>如果我使用了台湾健保医师开给我的眼药水却发生过敏红肿，是否可以申请药害救济?</td>\n",
       "      <td>[「目睭花花，匏仔看做菜瓜」，, 许多民众如果觉得眼睛雾雾时，, 常常会自行购买眼药水来缓解...</td>\n",
       "      <td>39</td>\n",
       "      <td>[32]</td>\n",
       "      <td>[30, 32]</td>\n",
       "      <td>[1.1404048564145342e-05, 2.911921365011949e-05...</td>\n",
       "      <td>[并不适用我国药害救济制度喔!\\n\\n       食药署为确保药品安全与医疗效能，]</td>\n",
       "      <td>[并不属于我国合法药物，, 并不适用我国药害救济制度喔!\\n\\n       食药署为确保药...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Question  \\\n",
       "13                                苏东坡死于哪一年?   \n",
       "39                     形成于北大西洋的热带气旋，又被称为什么？   \n",
       "40                     形成于北太平洋的热带气旋，又被称为什么？   \n",
       "41                     形成于北印度洋的热带气旋，又被称为什么？   \n",
       "42                       发生于美国的热带气旋，我们叫它什么？   \n",
       "..                                      ...   \n",
       "777                        文中提及的自动贩卖机卖的是什么？   \n",
       "781              晏子来到楚国的时候，楚王是否下令开城门以礼相待迎接？   \n",
       "821                        青河的硕士学位在哪一个国家念的?   \n",
       "826                              青河目前的职业为何?   \n",
       "858  如果我使用了台湾健保医师开给我的眼药水却发生过敏红肿，是否可以申请药害救济?   \n",
       "\n",
       "                                         Sentence_List  Length    train_pred  \\\n",
       "13   [元祐元年（1086年），, 宋哲宗即位，, 高太皇太后垂帘听政，, 回朝任礼部郎中、中书舍...      32          [17]   \n",
       "39   [台风（英语：Typhoon，香港天文台缩写T.；日语：台风/たいふう/taifū；韩语：태...      17          [16]   \n",
       "40   [台风（英语：Typhoon，香港天文台缩写T.；日语：台风/たいふう/taifū；韩语：태...      17          [16]   \n",
       "41   [台风（英语：Typhoon，香港天文台缩写T.；日语：台风/たいふう/taifū；韩语：태...      17          [16]   \n",
       "42   [台风（英语：Typhoon，香港天文台缩写T.；日语：台风/たいふう/taifū；韩语：태...      17          [11]   \n",
       "..                                                 ...     ...           ...   \n",
       "777  [动物小学在公园里举行户外教学，, 小动物们看到一个像玻璃柜子一样的机器，, 里面摆著一个个...      35  [13, 27, 28]   \n",
       "781  [春秋时代，齐国和楚国都是有名的大国。, 有一次，齐王派晏子出使到楚国去。, 楚王听说晏子智...      26     [2, 5, 8]   \n",
       "821  [为倾听新住民心声，, 内政部移民署今(18)日下午，, 在台南市举办新住民座谈会，, 有2...      56      [19, 20]   \n",
       "826  [为倾听新住民心声，, 内政部移民署今(18)日下午，, 在台南市举办新住民座谈会，, 有2...      56      [10, 19]   \n",
       "858  [「目睭花花，匏仔看做菜瓜」，, 许多民众如果觉得眼睛雾雾时，, 常常会自行购买眼药水来缓解...      39          [32]   \n",
       "\n",
       "        train_obs                                       train_scores  \\\n",
       "13       [12, 17]  [4.585612623486668e-05, 1.6881973351701163e-05...   \n",
       "39        [9, 16]  [2.2695174266118556e-05, 8.305213850690052e-05...   \n",
       "40       [11, 16]  [2.2008725863997824e-05, 3.163578730891459e-05...   \n",
       "41       [11, 16]  [2.4452738216496073e-05, 1.7731041225488298e-0...   \n",
       "42       [11, 16]  [1.8374197679804638e-05, 1.3571444469562266e-0...   \n",
       "..            ...                                                ...   \n",
       "777      [27, 28]  [0.00016559450887143612, 2.908718670369126e-05...   \n",
       "781        [2, 5]  [1.2578303540067282e-05, 1.7875763660413213e-0...   \n",
       "821  [10, 19, 20]  [1.0251031199004501e-05, 1.1121333045593929e-0...   \n",
       "826      [19, 23]  [1.0657003258529585e-05, 1.1454480954853352e-0...   \n",
       "858      [30, 32]  [1.1404048564145342e-05, 2.911921365011949e-05...   \n",
       "\n",
       "                                             Pred_List  \\\n",
       "13                                   [七月二十八日于常州孙氏馆病卒，]   \n",
       "39           [例如北太平洋西部称为「台风」、北大西洋称为「飓风」、北印度洋称为「气旋风暴」。]   \n",
       "40           [例如北太平洋西部称为「台风」、北大西洋称为「飓风」、北印度洋称为「气旋风暴」。]   \n",
       "41           [例如北太平洋西部称为「台风」、北大西洋称为「飓风」、北印度洋称为「气旋风暴」。]   \n",
       "42                                 [「台风」甚至直接泛指热带气旋本身。]   \n",
       "..                                                 ...   \n",
       "777  [一位高班的同学走过来说：「这是自动贩卖机，卖的都是饮料。」一面说著，, \\n胖小熊高兴的拍...   \n",
       "781              [楚王听说晏子智慧高、口才好，, 存心想羞辱他，, 楚王下令把城门关上，]   \n",
       "821                      [青河得以持续进修，, 她不仅取得国立成功大学硕士学位，]   \n",
       "826                     [青河毕业于越南河内国家大学法文系，, 青河得以持续进修，]   \n",
       "858        [并不适用我国药害救济制度喔!\\n\\n       食药署为确保药品安全与医疗效能，]   \n",
       "\n",
       "                                              Obs_List  \n",
       "13                 [\\n建中靖国元年（1101年），, 七月二十八日于常州孙氏馆病卒，]  \n",
       "39   [将中心持续风速每秒17.2米或以上的热带气旋（包括世界气象组织定义中的热带风暴、强烈热带风...  \n",
       "40   [「台风」甚至直接泛指热带气旋本身。, 例如北太平洋西部称为「台风」、北大西洋称为「飓风」、...  \n",
       "41   [「台风」甚至直接泛指热带气旋本身。, 例如北太平洋西部称为「台风」、北大西洋称为「飓风」、...  \n",
       "42   [「台风」甚至直接泛指热带气旋本身。, 例如北太平洋西部称为「台风」、北大西洋称为「飓风」、...  \n",
       "..                                                 ...  \n",
       "777  [\\n胖小熊高兴的拍手说：「这下可好了，以后出来玩，就不要带水壶，只要带些铜板来买饮料就好了...  \n",
       "781                          [楚王听说晏子智慧高、口才好，, 存心想羞辱他，]  \n",
       "821   [青河毕业于越南河内国家大学法文系，, 青河得以持续进修，, 她不仅取得国立成功大学硕士学位，]  \n",
       "826                     [青河得以持续进修，, 目前除受聘于成功大学担任越语讲师，]  \n",
       "858  [并不属于我国合法药物，, 并不适用我国药害救济制度喔!\\n\\n       食药署为确保药...  \n",
       "\n",
       "[83 rows x 8 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mismatch = training_data_with_performance[training_data_with_performance['Pred_List'] != training_data_with_performance['Obs_List']]\n",
    "train_mismatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "#20 (Pred:[9], Actual:[])\n",
    "\n",
    "Question:「阿拉伯之春」运动中，走上街头的民众的诉求为何? <br>\n",
    "Predicted SP: 只有突尼西亚成为阿拉伯之春中，<br>\n",
    "Actual: None\n",
    "\n",
    "Comment: While the predicted SP is incorrect, I found out that there is supporting evidence in the paragraph. (...要求推翻本国的专制政体的行动)This might be a case of incorrect input.\n",
    "\n",
    "#70 (Pred:[11], Actual:[])\n",
    "\n",
    "Question: 第二次签订的北美贸易协定从签署至生效过了几日? <br>\n",
    "Predicted SP: 美国、墨西哥和加拿大就更新北美自由贸易协定达成一致，<br>\n",
    "Actual: None\n",
    "\n",
    "Comment: Same as #20. (美国、加拿大及墨西哥在1992年8月12日签署了关于三国间全面贸易的协议。...，北美自由贸易协议于1994年1月1日正式生效。)\n",
    "\n",
    "#156 (Pred:[1], Actual:[])\n",
    "\n",
    "Question: 聊天机器人仰赖哪些方法让回答愈来愈准确? <br>\n",
    "Predicted SP: 麻省理工学院（MIT）人工智慧实验室早在1966年即研发出名为「Eliza」的机器人， <br>\n",
    "Actual: None <br>\n",
    "\n",
    "Comment: Same (聊天机器人的作答准确度要透过程式化的方法改善)\n",
    "\n",
    "#284 (Pred:[3], Actual:[])\n",
    "\n",
    "Question: 不可再生能源的意义是什么？ <br>\n",
    "Predicted SP: 许多这些形式可以很容易转化为另一种的帮助下， <br>\n",
    "Actual: None <br>\n",
    "\n",
    "Comment: Same (是无法经过短时间内再生的能源，而且它们的消耗速度远远超过它们再生的速度)\n",
    "\n",
    "#324 (Pred:[4], Actual:[])\n",
    "\n",
    "Question: 伊甸基金會成立的宗旨為何? <br>\n",
    "Predicted SP: 因著上帝的呼召及一颗爱身心障碍者的同理心，<br>\n",
    "Actual: None <br>\n",
    "\n",
    "Comment: No SP in the paragraph. But I think SP is pretty close to being a supporting evidence. This \n",
    "must be a borderline case.\n",
    "\n",
    "#370 (Pred:[12,25], Actual:[25])\n",
    "\n",
    "Question: 三大健康照护体系保险制度中，政府涉入程度低的是哪一种？<br>\n",
    "Predicted SP: 公医制（政府介入最多）：以英国为代表。 AND 自由市场（政府一般不介入）：以2013年前的美国为代表。<br>\n",
    "Actual: 公医制（政府介入最多）：以英国为代表。<br>\n",
    "\n",
    "Comment: I think this is a very reasonable mismatch. As two supporting evidences are very similar\n",
    "syntax-wise but drastically different in meaning.\n",
    "\n",
    "#371 (Pred:[12,25], Actual:[12])\n",
    "\n",
    "Question: 三大健康照護體系保險制度中，政府涉入程度高的是哪一種？ <br>\n",
    "Predicted SP: 公医制（政府介入最多）：以英国为代表。 AND 自由市场（政府一般不介入）：以2013年前的美国为代表。<br>\n",
    "Actual: 公医制（政府介入最多）：以英国为代表。<br>\n",
    "\n",
    "Comment: Same as #370\n",
    "\n",
    "#395 (Pred:[10], Actual:[])\n",
    "\n",
    "Question: 熬夜是否能减低得到癌症的风险? <br>\n",
    "Predicted SP: 皆强烈建议减少或避免动物性食品摄取， <br>\n",
    "Actual: None <br>\n",
    "\n",
    "Comment: Another potential case of incorrect input. In the paragraph I found this sentence (所以防癌守则：...，注重睡眠品质)\n",
    "\n",
    "#449 (Pred:[2], Actual:[])\n",
    "\n",
    "Question: 高屏地区国庆烟火试放管制时间是从晚上几点开始？ <br>\n",
    "Predicted SP: 屏东县政府表示24号当天屏东河滨公园将管制不开放， <br>\n",
    "Actual: None <br>\n",
    "\n",
    "Comment: Another similar case. This time I strongly believe this is an incorrect input. \n",
    "当晚7时并会进行全面清场 <- This is sufficient to be a supporting evidence\n",
    "\n",
    "#502 (Pred:[7], Actual:[])\n",
    "\n",
    "Question: 为何圣伯多禄大殿只能重建不能整修就好? <br>\n",
    "Predicted SP: 教宗犹利二世决定重建圣伯多禄大殿 <br>\n",
    "Actual: None \n",
    "\n",
    "Comment: Another similar case. (无疑再改动有机会让建筑倒塌)\n",
    "\n",
    "#630 (Pred:[62], Actual:[])\n",
    "\n",
    "Question: 毛笔、铅笔、钢笔，这三种笔中哪个笔尖的硬度高？ <br>\n",
    "Predicted SP: 更进一步看：我们无论使用那一种笔，<br>\n",
    "Actual: None <br>\n",
    "\n",
    "Comment: Again, I think this counts as a supporting evidence (钢笔的笔尖用金属制成，弹性大，硬度高)\n",
    "\n",
    "#731 (Pred:[9], Actual:[])\n",
    "\n",
    "Question: 为什么古埃及人要把死人做成木乃伊? <br>\n",
    "Predicted SP: 是做什么用的呢？ <br>\n",
    "Actual: None <br>\n",
    "\n",
    "Comment: I think this counts (古埃及人相信：人死后只要把遗体保存好，就可以在另一个世界得到永生。)\n",
    "\n",
    "#874 (Pred:[22], Actual:[])\n",
    "\n",
    "Question: 要如何降低肠病毒的传播风险？\n",
    "Predicted SP: 今(2019)年累计37例肠病毒并发重症病例，\n",
    "Actual: None\n",
    "\n",
    "Comment: No doubt, these are supporting evidences (应加强居家环境、教室及游乐设施等的通风、整洁与消毒，并教导学童落实「湿、搓、冲、捧、擦」正确洗手步骤，及生病在家休息等良好卫生观念，)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Data Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data_with_performance['dev_pred'] = dev_preds\n",
    "dev_data_with_performance['dev_obs'] = dev_obs\n",
    "dev_data_with_performance['dev_scores'] = dev_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_sp = []\n",
    "for i in range(dev_data_with_performance.shape[0]):\n",
    "    para = dev_data_with_performance['Sentence_List'][i]\n",
    "    sen = []\n",
    "    for index in dev_data_with_performance['dev_pred'][i]:\n",
    "        sen.append(para[index])\n",
    "    correct_sp.append(sen)\n",
    "dev_data_with_performance['Pred_List'] = correct_sp\n",
    "correct_sp = []\n",
    "for i in range(dev_data_with_performance.shape[0]):\n",
    "    para = dev_data_with_performance['Sentence_List'][i]\n",
    "    sen = []\n",
    "    for index in dev_data_with_performance['dev_obs'][i]:\n",
    "        sen.append(para[index])\n",
    "    correct_sp.append(sen)\n",
    "dev_data_with_performance['Obs_List'] = correct_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data_with_performance.drop(['SE_Index', 'Label'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data_with_performance.drop(['Sentence_List'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_mismatch = dev_data_with_performance[dev_data_with_performance['Obs_List'] != dev_data_with_performance['Pred_List']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_match = dev_data_with_performance[dev_data_with_performance['Obs_List'] == dev_data_with_performance['Pred_List']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['苏轼（1037年1月8日－1101年8月24日），',\n",
       " '眉州眉山（今四川省眉山市）人，',\n",
       " '北宋时著名的文学家、政治家、艺术家、医学家。',\n",
       " '字子瞻，一字和仲，',\n",
       " '号东坡居士、铁冠道人。',\n",
       " '嘉佑二年进士，',\n",
       " '累官至端明殿学士兼翰林学士，',\n",
       " '礼部尚书。南宋理学方炽时，',\n",
       " '加赐谥号文忠，',\n",
       " '复追赠太师。',\n",
       " '有《东坡先生大全集》及《东坡乐府》词集传世，',\n",
       " '宋人王宗稷收其作品，',\n",
       " '编有《苏文忠公全集》。',\n",
       " '\\n其散文、诗、词、赋均有成就，',\n",
       " '且善书法和绘画，',\n",
       " '是文学艺术史上的通才，',\n",
       " '也是公认韵文散文造诣皆比较杰出的大家。',\n",
       " '苏轼的散文为唐宋四家（韩愈、柳宗元、欧苏）之末，',\n",
       " '与唐代的古文运动发起者韩愈并称为「韩潮苏海」，',\n",
       " '也与欧阳修并称「欧苏」；',\n",
       " '更与父亲苏洵、弟苏辙合称「三苏」，',\n",
       " '父子三人，同列唐宋八大家。',\n",
       " '苏轼之诗与黄庭坚并称「苏黄」，',\n",
       " '又与陆游并称「苏陆」；',\n",
       " '其词「以诗入词」，',\n",
       " '首开词坛「豪放」一派，',\n",
       " '振作了晚唐、五代以来绮靡的西昆体余风。',\n",
       " '后世与南宋辛弃疾并称「苏辛」，',\n",
       " '惟苏轼故作豪放，',\n",
       " '其实清朗；其赋亦颇有名气，',\n",
       " '最知名者为贬谪期间借题发挥写的前后《赤壁赋》。',\n",
       " '宋代每逢科考常出现其文命题之考试，',\n",
       " '故当时学者曰：「苏文熟，吃羊肉、苏文生，嚼菜羹」。',\n",
       " '艺术方面，书法名列「苏、黄、米、蔡」北宋四大书法家（宋四家）之首；',\n",
       " '其画则开创了湖州画派；',\n",
       " '并在题画文学史上占有举足轻重的地位。']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_mismatch['Sentence_List'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'berts_dev_mismatch' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store berts_dev_mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'dev_match' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store dev_match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT+LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FGC_LSTM_Network(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        \n",
    "        super(FGC_LSTM_Network, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-chinese')\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.h0 = nn.Parameter(torch.FloatTensor(hidden_size).uniform_(-0.1, 0.1))\n",
    "        self.c0 = nn.Parameter(torch.FloatTensor(hidden_size).uniform_(-0.1, 0.1))\n",
    "        self.linear = nn.Linear(hidden_size*2, 1) \n",
    "        # (H-state and c_state must be converted into 3d in forward function)\n",
    "        \n",
    "    def forward_nn(self, batch):    \n",
    "        # batch['ids'] = (batch_size*number of sentence, sent_len)\n",
    "        # batch['segment_ids'] = (batch_size*number of sentence, sent_len)\n",
    "        # batch['mask_ids'] = (batch_size*number of sentence, sent_len)\n",
    "        # pooler_output = (batch_size, 768)\n",
    "        # hidden_state = (batch_size, sent_len, 768)\n",
    "        # output = (batch_size, 1)\n",
    "        \n",
    "        #h0 = torch.zeros(self.num_layers*2, batch['ids'].shape[0], self.hidden_size).to(device)\n",
    "        #c0 = torch.zeros(self.num_layers*2, batch['ids'].shape[0], self.hidden_size).to(device)\n",
    "        \n",
    "        \n",
    "        batch_size = batch['ids'].shape[0]\n",
    "        max_sent_size = batch['ids'].shape[2]\n",
    "        \n",
    "        #h0 = self.h0.expand(batch_size, self.num_layers*2, -1)\n",
    "        #c0 = self.c0.expand(batch_size, self.num_layers*2, -1)\n",
    "        ids = batch['ids'].view(-1, max_sent_size)\n",
    "        mask_ids = batch['mask_ids'].view(-1, max_sent_size)\n",
    "        segment_ids = batch['segment_ids'].view(-1, max_sent_size)\n",
    "        \n",
    "        hidden_state, pooler_output = self.bert(ids, mask_ids, segment_ids)   \n",
    "        \n",
    "        hidden_state = hidden_state[:,0].view(batch_size, -1, 768)\n",
    "        \n",
    "        lstm_output, (hn, cn) = self.lstm(hidden_state)\n",
    "        \n",
    "        linear_output = self.linear(lstm_output).squeeze(-1)\n",
    "        \n",
    "        return linear_output\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        output = self.forward_nn(batch)\n",
    "        labels = batch['labels']\n",
    "        loss_fn = nn.BCEWithLogitsLoss(weight=batch['sentence_mask'])\n",
    "        loss = loss_fn(output, labels)\n",
    "        return loss\n",
    "     \n",
    "    def _predict(self, batch):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = self.forward_nn(batch)\n",
    "            scores = torch.sigmoid(output)\n",
    "            scores = scores.cpu().numpy().tolist()\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    def predict_fgc(self, batch, threshold=0.5):\n",
    "        scores = self._predict(batch)\n",
    "        max_i = 0\n",
    "        max_score = 0\n",
    "        sp = []\n",
    "\n",
    "        for i, score in enumerate(scores[0]):\n",
    "\n",
    "            if score > max_score:\n",
    "                max_i = i\n",
    "                max_score = score\n",
    "            if score >= threshold:\n",
    "                sp.append(i)\n",
    "\n",
    "        # This is to ensure there's no empty supporting evidences\n",
    "        if not sp:\n",
    "            sp.append(max_i)\n",
    "        return {'sp': sp, 'sp_scores': scores}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT+Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bertAgg(nn.Module):\n",
    "    \n",
    "    def __init__(self, number_of_sentence, max_sentence_length, baseline):\n",
    "        \n",
    "        super(bertAgg, self).__init__()\n",
    "        self.max_sentence_length = max_sentence_length\n",
    "        self.number_of_sentence = number_of_sentence\n",
    "        baseline.load_state_dict(torch.load(\"Models/baseline_models_with_scheduler/model_epoch8_eval_em:0.198_precision:0.603_recall:0.588_f1:0.545_loss:0.031.m\"))\n",
    "        self.baseline = baseline\n",
    "        self.bert = BertModel.from_pretrained('bert-base-chinese')\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.linearAgg = nn.Linear(1536, 1)\n",
    "        self.qsLinear = nn.Linear(1536, 1)\n",
    "        \n",
    "    def forward_nn(self, batch):\n",
    "        \n",
    "        # Sent objects into CUDA\n",
    "        for key in batch:\n",
    "            if key == 'labels':\n",
    "                batch[key] = batch[key].to(device).to(torch.float)\n",
    "            else:\n",
    "                batch[key] = batch[key].to(device).to(torch.long)\n",
    "\n",
    "        batch_size = batch['ids'].shape[0]\n",
    "        padded_zeros = torch.tensor([0] * self.number_of_sentence)\n",
    "        \n",
    "        \n",
    "        # Sent sentences into BERT embeddings\n",
    "        sentence_ids = batch['ids'].view(-1, self.max_sentence_length)\n",
    "        sentence_mask_ids = batch['mask_ids'].view(-1, self.max_sentence_length) #(batch, 5)\n",
    "        sentence_hidden_state, sentence_pooler_output = self.baseline.bert(sentence_ids, sentence_mask_ids)   \n",
    "        \n",
    "        # Sent question into BERT embeddings\n",
    "        question_ids = batch['q_ids']\n",
    "        question_mask_ids = batch['q_mask_ids']\n",
    "        question_hidden_state, question_pooler_output = self.baseline.bert(question_ids, question_mask_ids) # (batch, 768)\n",
    "      \n",
    "        sentence_mask = batch['sentence_mask']\n",
    "        sentence_mask = sentence_mask.type(torch.float)\n",
    "        \n",
    "        # Aggregate\n",
    "        sentence_pooler_output = sentence_pooler_output.view(batch_size, -1, 768) # (batch, 5, 768)\n",
    "        \n",
    "        target_sentence = sentence_pooler_output[:, self.number_of_sentence // 2, :].unsqueeze(1) # (batch, 1, 768)\n",
    "        target_sentence = target_sentence.expand(-1, self.number_of_sentence, -1) # (batch, 5, 768)\n",
    "        \n",
    "        concatenated = torch.cat((target_sentence, sentence_pooler_output), dim=-1) # (batch, 5, 768*2)\n",
    "        att_weight = self.linearAgg(concatenated) + (1.0 - sentence_mask) * -10000 #\n",
    "        #if sentence_pooler_output\n",
    "        att_weight = self.softmax(att_weight) # (batch, 5)\n",
    "        aggregated_sentence = torch.matmul(att_weight.transpose(1,2), sentence_pooler_output) # (batch, 1, 768)\n",
    "        aggregated_sentence = aggregated_sentence.squeeze(1) # (batch, 768)\n",
    "\n",
    "        # Concatenate question to aggregated sentence\n",
    "        qs_concatenated = torch.cat((aggregated_sentence, question_pooler_output), dim=-1) # (batch, 1536)\n",
    "        final_output = self.qsLinear(qs_concatenated) # (batch, 1)\n",
    "        return final_output, att_weight#final_output, att_weight\n",
    "        \n",
    "        \n",
    "        \n",
    "#         for i in range(batch_size):\n",
    "            \n",
    "#             mini_batch = sentence_pooler_output[i]\n",
    "#             # Aggregate sentence weights\n",
    "#             target_sentence = sentence_pooler_output[i, self.number_of_sentence // 2, :]\n",
    "#             target_sentence_clone = target_sentence.expand(self.number_of_sentence, 768)\n",
    "#             concatenated = torch.cat((mini_batch, target_sentence_clone), dim=1)\n",
    "#             target_sentence_aggregated = torch.sum(self.linearAgg(concatenated) * mini_batch, dim=0)\n",
    "            \n",
    "#             # Question sentence feedforward\n",
    "#             question_to_concat = question_pooler_output[i]\n",
    "#             qs_concatenated = torch.cat((target_sentence_aggregated, question_to_concat))\n",
    "#             final_output = self.linearAgg(qs_concatenated).squeeze(-1)\n",
    "#             batch_output.append(final_output)\n",
    "        \n",
    "        \n",
    "#         return torch.tensor(batch_output).reshape(batch_size, 1).to(device)\n",
    "        \n",
    "        \n",
    "    def forward(self, batch):\n",
    "        \n",
    "        output, _ = self.forward_nn(batch)\n",
    "        labels = batch['labels']\n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "        loss = loss_fn(output, labels)\n",
    "        #print(batch['ids'], output, _)\n",
    "        #print(tokenizer.convert_ids_to_tokens(batch['ids'][0][2].tolist()))\n",
    "        #print(tokenizer.convert_ids_to_tokens(batch['ids'][1][2].tolist()))\n",
    "        #print(batch['ids'])\n",
    "        #print(output, labels)\n",
    "        #print(loss)\n",
    "        return loss\n",
    "    \n",
    "    def _predict(self, batch):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            output, att_weight = self.forward_nn(batch)\n",
    "            scores = torch.sigmoid(output)\n",
    "            scores = scores.cpu().numpy().tolist()\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    def predict_fgc(self, batch, threshold=0.5):\n",
    "        scores = self._predict(batch)\n",
    "        max_i = 0\n",
    "        max_score = 0\n",
    "        sp = []\n",
    "\n",
    "        for i, score in enumerate(scores[0]):\n",
    "\n",
    "            if score > max_score:\n",
    "                max_i = i\n",
    "                max_score = score\n",
    "            if score >= threshold:\n",
    "                sp.append(i)\n",
    "\n",
    "        # This is to ensure there's no empty supporting evidences\n",
    "        if not sp:\n",
    "            sp.append(max_i)\n",
    "        return {'sp': sp, 'sp_scores': scores}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline+Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-122-139763ecbec2>, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-122-139763ecbec2>\"\u001b[0;36m, line \u001b[0;32m22\u001b[0m\n\u001b[0;31m    mask_ids =\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class baselineAgg(nn.Module):\n",
    "\n",
    "    def __init__(self, number_of_sentence, max_sentence_length, BMPATH):\n",
    "        \n",
    "        super(bertAgg, self).__init__()\n",
    "        self.max_sentence_length = max_sentence_length\n",
    "        self.number_of_sentence = number_of_sentence\n",
    "        self.baseline = baseline_model().load_state_dict(torch.load(BMPATH))\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward_nn(self, batch):\n",
    "        # batch = (batch_size, sentence length)\n",
    "        # pooler_output = (batch_size, 768)\n",
    "        # Sent objects into CUDA\n",
    "        for key in batch:\n",
    "            if key == 'labels':\n",
    "                batch[key] = batch[key].to(device).to(torch.float)\n",
    "            else:\n",
    "                batch[key] = batch[key].to(device).to(torch.long)\n",
    "\n",
    "        ids = batch['ids'].view(-1, self.max_sentence_length)\n",
    "        mask_ids = \n",
    "        hidden_state, pooler_output = self.baseline.bert(batch['ids'], batch['mask_ids'], batch['segment_ids'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0811 07:59:12.381575 139897081689920 configuration_utils.py:152] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json from cache at /root/.cache/torch/transformers/8a3b1cfe5da58286e12a0f5d7d182b8d6eca88c08e26c332ee3817548cf7e60a.f12a4f986e43d8b328f5b067a641064d67b91597567a06c7b122d1ca7dfd9741\n",
      "I0811 07:59:12.386453 139897081689920 configuration_utils.py:169] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "I0811 07:59:13.261365 139897081689920 modeling_utils.py:387] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-pytorch_model.bin from cache at /root/.cache/torch/transformers/b1b5e295889f2d0979ede9a78ad9cb5dc6a0e25ab7f9417b315f0a2c22f4683d.929717ca66a3ba9eb9ec2f85973c6398c54c38a4faa464636a491d7a705f7eb6\n"
     ]
    }
   ],
   "source": [
    "new_network = bertAgg(3, 250, baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bertAgg(\n",
       "  (baseline): baseline_model(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (linear): Linear(in_features=768, out_features=1, bias=True)\n",
       "  )\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (softmax): Softmax()\n",
       "  (linearAgg): Linear(in_features=1536, out_features=1, bias=True)\n",
       "  (qsLinear): Linear(in_features=1536, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_network.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_val_batches = eval_preprocessing(validation_data, dev_dataset)\n",
    "for data in test_val_batches:\n",
    "    data['ids'] = data['ids'].unsqueeze(0)\n",
    "    data['mask_ids'] = data['mask_ids'].unsqueeze(0)\n",
    "    data['segment_ids'] = data['segment_ids'].unsqueeze(0)\n",
    "    data['labels'] = data['labels'].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_model_eval(new_network, test_val_batches, 0, validation_data['QUESTIONS'].apply(lambda x: x[0]['SHINT_']).tolist(), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Improved Model & Evaluating Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_model_optim(nn, num_epochs, lr, dataloader):\n",
    "    param_optimizer = list(nn.bert.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "    num_epochs = num_epochs\n",
    "    num_train_optimization_steps = len(dataloader) * num_epochs\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=lr)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                     num_warmup_steps=int(\n",
    "                                                         num_train_optimization_steps * 0.1),\n",
    "                                                     num_training_steps=num_train_optimization_steps)\n",
    "    return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _update_sp(metrics, sp_gold, sp_pred):\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "        \n",
    "    for p in sp_pred:\n",
    "        if p in sp_gold:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "    for g in sp_gold:\n",
    "        if g not in sp_pred:\n",
    "            fn += 1\n",
    "            \n",
    "    precision = 1.0 * tp / (tp + fp) if tp + fp > 0 else 0.0\n",
    "    recall = 1.0 * tp / (tp + fn) if tp + fn > 0 else 0.0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0.0\n",
    "    em = 1.0 if fp + fn == 0 else 0.0\n",
    "    \n",
    "    metrics['sp_em'] += em\n",
    "    metrics['sp_f1'] += f1\n",
    "    metrics['sp_prec'] += precision\n",
    "    metrics['sp_recall'] += recall\n",
    "    \n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_sp_fgc(sp_golds, sp_preds):\n",
    "    \n",
    "    metrics = {'sp_em': 0, 'sp_prec': 0, 'sp_recall': 0, 'sp_f1': 0}\n",
    "    \n",
    "    assert len(sp_golds) == len(sp_preds)\n",
    "    \n",
    "    for sp_gold, sp_pred in zip(sp_golds, sp_preds):\n",
    "        _update_sp(metrics, sp_gold, sp_pred)\n",
    "    \n",
    "    N = len(sp_golds)\n",
    "    for k in metrics.keys():\n",
    "        metrics[k] /= N\n",
    "        metrics[k] = round(metrics[k], 3)\n",
    "    print(metrics)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_model_eval(network, train_batches, dev_batches, current_epoch, train_sp_golds, dev_sp_golds, avg_loss):\n",
    "    \n",
    "    network.eval()\n",
    "    with torch.no_grad():\n",
    "        dev_sp_preds = []\n",
    "        train_sp_preds = []\n",
    "        \n",
    "        for batch in tqdm(dev_batches):\n",
    "            out_dct= network.predict_fgc(batch)\n",
    "    \n",
    "            dev_sp_preds.append(out_dct['sp'])\n",
    "            print(out_dct['sp'])\n",
    "        \n",
    "        for batch in tqdm(train_batches):\n",
    "            train_dct = network.predict_fgc(batch)\n",
    "            train_sp_preds.append(train_dct['sp'])\n",
    "            print(train_dct['sp'])\n",
    "            \n",
    "    dev_metrics = eval_sp_fgc(dev_sp_golds, dev_sp_preds)\n",
    "    train_metrics = eval_sp_fgc(train_sp_golds, train_sp_preds)\n",
    "    \n",
    "    print('epoch %d eval_recall: %.3f eval_f1: %.3f loss: %.3f' % (\n",
    "            current_epoch, dev_metrics['sp_recall'], dev_metrics['sp_f1'], avg_loss))\n",
    "    \n",
    "    print('epoch %d eval_recall: %.3f eval_f1: %.3f loss: %.3f' % (\n",
    "            current_epoch, train_metrics['sp_recall'], train_metrics['sp_f1'], avg_loss))\n",
    "    #torch.save(network.state_dict(), \"New_Models/model_epoch{0}_eval_em:{1:.3f}_precision:{2:.3f}_recall:{3:.3f}_f1:{4:.3f}_loss:{5:.3f}.m\".format(current_epoch, metrics['sp_em'], metrics['sp_prec'], metrics['sp_recall'], metrics['sp_f1'], avg_loss))\n",
    "    \n",
    "    return #sp_preds, sp_golds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_model_train(network, dataloader, train_batches, dev_batches, num_epochs, lr):\n",
    "    \n",
    "    optimizer, scheduler = new_model_optim(network, num_epochs, lr, dataloader)\n",
    "    \n",
    "    train_sp_golds = training_data['QUESTIONS'].apply(lambda x: x[0]['SHINT_']).tolist()\n",
    "    dev_sp_golds = validation_data['QUESTIONS'].apply(lambda x: x[0]['SHINT_']).tolist()\n",
    "    \n",
    "    for current_epoch in range(num_epochs):\n",
    "        network.train()\n",
    "        running_loss = 0.0\n",
    "        for batch in tqdm(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            current_loss = network(batch)\n",
    "\n",
    "            current_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(network.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            running_loss += current_loss.item()\n",
    "            \n",
    "        learning_rate_scalar = scheduler.get_lr()[0]\n",
    "        print('lr = %f' % learning_rate_scalar)\n",
    "        avg_loss = running_loss/len(dataloader)\n",
    "        print('epoch %d train_loss: %.3f' % (current_epoch, avg_loss))\n",
    "        new_model_eval(network, train_batches, dev_batches, current_epoch, train_sp_golds, dev_sp_golds, avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "sent_dev_batches = sent_eval_preprocessing(validation_data, sent_dev_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "sent_train_batches = sent_eval_preprocessing(training_data, sent_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e618ea52fd478c9802b9b3cc463bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=247), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30a7561b02f8484faa3ca704eb4f1430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=882), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-7e3b2badd48c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_sp_golds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'QUESTIONS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SHINT_'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdev_sp_golds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'QUESTIONS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SHINT_'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnew_model_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_train_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_dev_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_sp_golds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_sp_golds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-101-2d3751a0ad8f>\u001b[0m in \u001b[0;36mnew_model_eval\u001b[0;34m(network, train_batches, dev_batches, current_epoch, train_sp_golds, dev_sp_golds, avg_loss)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mtrain_dct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_fgc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mtrain_sp_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-121-f8c5729b8a9e>\u001b[0m in \u001b[0;36mpredict_fgc\u001b[0;34m(self, batch, threshold)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_fgc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mmax_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mmax_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-121-f8c5729b8a9e>\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matt_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_sp_golds = training_data['QUESTIONS'].apply(lambda x: x[0]['SHINT_']).tolist()\n",
    "dev_sp_golds = validation_data['QUESTIONS'].apply(lambda x: x[0]['SHINT_']).tolist()\n",
    "new_model_eval(new_network, sent_train_batches, sent_dev_batches, 0, dev_sp_golds, train_sp_golds, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45844c6668d94bf38862eb09e96b00a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7856), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr = 0.000010\n",
      "epoch 0 train_loss: 0.267\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1f26adb820349d88ad8ce5cd578d36b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=247), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00748c1af8a2445b9311b180080a7a64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=882), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sp_em': 0.04, 'sp_prec': 0.259, 'sp_recall': 0.132, 'sp_f1': 0.168}\n",
      "{'sp_em': 0.065, 'sp_prec': 0.279, 'sp_recall': 0.151, 'sp_f1': 0.185}\n",
      "epoch 0 eval_recall: 0.132 eval_f1: 0.168 loss: 0.267\n",
      "epoch 0 eval_recall: 0.151 eval_f1: 0.185 loss: 0.267\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84f6064981cf4f3d91346f1b1ab776f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7856), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr = 0.000020\n",
      "epoch 1 train_loss: 0.270\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4bc7c7332c9417b8739766bc5ec0bf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=247), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70dae450b515485aafbae14c7b531f6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=882), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sp_em': 0.04, 'sp_prec': 0.259, 'sp_recall': 0.132, 'sp_f1': 0.168}\n",
      "{'sp_em': 0.065, 'sp_prec': 0.279, 'sp_recall': 0.151, 'sp_f1': 0.185}\n",
      "epoch 1 eval_recall: 0.132 eval_f1: 0.168 loss: 0.270\n",
      "epoch 1 eval_recall: 0.151 eval_f1: 0.185 loss: 0.270\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e90bef4e0ca6407ca7d24a1b6f420327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7856), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-176ad9f60736>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_model_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_sent_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_train_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_dev_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.00002\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-69-f84f64c20588>\u001b[0m in \u001b[0;36mnew_model_train\u001b[0;34m(network, dataloader, train_batches, dev_batches, num_epochs, lr)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mcurrent_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "new_model_train(new_network, dataloader_sent_train, sent_train_batches, sent_dev_batches, 20, 0.00002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dev_batches = window_sentence_preprocessing(validation_data, dev_dataset, 10)\n",
    "testing_dev_batches = DataLoader(new_dev_batches, batch_size=2, shuffle = False, collate_fn = collate_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MUST DO THIS BEFORE EVALUATING \n",
    "eval_train_batches = eval_preprocessing(training_data, train_dataset)\n",
    "for data in eval_train_batches:\n",
    "    data['ids'] = data['ids'].unsqueeze(0)\n",
    "    data['mask_ids'] = data['mask_ids'].unsqueeze(0)\n",
    "    data['segment_ids'] = data['segment_ids'].unsqueeze(0)\n",
    "    data['labels'] = data['labels'].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cdcac7fd2374199b4951e8018a587f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=882), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.085, 'sp_prec': 0.3, 'sp_recall': 0.172, 'sp_f1': 0.206}\n",
      "epoch 0 eval_recall: 0.172 eval_f1: 0.206 loss: 0.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[18],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [5],\n",
       " [7, 8, 9, 10, 11, 12, 13, 14],\n",
       " [22, 23],\n",
       " [27],\n",
       " [26, 30],\n",
       " [33, 34],\n",
       " [1, 3, 4, 5, 6],\n",
       " [5, 7],\n",
       " [7],\n",
       " [7, 8, 11],\n",
       " [12, 17],\n",
       " [11, 17],\n",
       " [11, 19],\n",
       " [23],\n",
       " [25, 28, 30],\n",
       " [25, 28],\n",
       " [16, 17],\n",
       " [],\n",
       " [9, 10],\n",
       " [9, 11, 13],\n",
       " [0, 2, 6],\n",
       " [0],\n",
       " [0, 14, 16],\n",
       " [0, 14, 16],\n",
       " [0, 14, 16, 17, 20, 21, 24, 25, 27, 29],\n",
       " [0, 14, 17],\n",
       " [0, 14, 20, 21],\n",
       " [0, 14, 24, 25],\n",
       " [0, 14, 27],\n",
       " [0, 14, 29],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [0, 1, 8, 11],\n",
       " [0, 1, 8, 11, 12, 14],\n",
       " [15],\n",
       " [5, 6],\n",
       " [9, 16],\n",
       " [11, 16],\n",
       " [11, 16],\n",
       " [11, 16],\n",
       " [0, 2],\n",
       " [8, 9],\n",
       " [8, 9],\n",
       " [0],\n",
       " [0, 1],\n",
       " [0, 4],\n",
       " [0, 6, 7, 8, 9],\n",
       " [0, 6, 7, 8, 9],\n",
       " [18, 21],\n",
       " [14],\n",
       " [14, 15],\n",
       " [21, 23, 24],\n",
       " [0, 2],\n",
       " [3],\n",
       " [0, 4, 5],\n",
       " [0, 4],\n",
       " [6],\n",
       " [11, 12],\n",
       " [11, 12],\n",
       " [11, 12],\n",
       " [11],\n",
       " [0],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [10, 11],\n",
       " [11, 12, 13, 14],\n",
       " [],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [0, 4],\n",
       " [0, 41],\n",
       " [0, 41],\n",
       " [0, 25, 41],\n",
       " [0, 5, 7],\n",
       " [0, 8],\n",
       " [0, 7],\n",
       " [0, 8],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [3, 4],\n",
       " [3, 4],\n",
       " [5, 6, 7, 8],\n",
       " [5, 6, 8],\n",
       " [9, 10],\n",
       " [9, 10],\n",
       " [9, 10],\n",
       " [9, 10],\n",
       " [11, 12, 13],\n",
       " [11, 12, 14],\n",
       " [2, 3],\n",
       " [2, 3],\n",
       " [4, 5],\n",
       " [6, 8, 9],\n",
       " [6, 8, 9],\n",
       " [5, 6, 8, 9],\n",
       " [12, 14, 15],\n",
       " [12, 14, 15],\n",
       " [0, 1, 2],\n",
       " [3, 4],\n",
       " [3, 4, 5],\n",
       " [7, 11],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [21],\n",
       " [20, 21],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [7, 8],\n",
       " [8, 9],\n",
       " [9, 10],\n",
       " [10, 11],\n",
       " [11, 12],\n",
       " [12, 13],\n",
       " [13, 14],\n",
       " [14, 15],\n",
       " [0, 1, 3, 4],\n",
       " [6, 7],\n",
       " [0, 4],\n",
       " [0, 5],\n",
       " [0],\n",
       " [0, 1],\n",
       " [5],\n",
       " [5],\n",
       " [5],\n",
       " [5],\n",
       " [9],\n",
       " [9, 10, 11, 27],\n",
       " [10, 12],\n",
       " [0, 10, 13],\n",
       " [27],\n",
       " [0, 1, 22],\n",
       " [16],\n",
       " [32],\n",
       " [0, 5],\n",
       " [5, 6],\n",
       " [10],\n",
       " [1, 3],\n",
       " [1, 4],\n",
       " [5, 30, 33, 37],\n",
       " [9],\n",
       " [10, 13],\n",
       " [0, 1, 23, 24, 26],\n",
       " [1, 4],\n",
       " [1, 4],\n",
       " [1, 2, 4],\n",
       " [5, 6],\n",
       " [1, 23, 24],\n",
       " [24],\n",
       " [],\n",
       " [7, 8],\n",
       " [9, 10],\n",
       " [16, 17],\n",
       " [18, 19],\n",
       " [25, 26],\n",
       " [27, 28],\n",
       " [25, 26],\n",
       " [25, 26],\n",
       " [27, 28],\n",
       " [27, 28],\n",
       " [8, 10, 11, 12],\n",
       " [30, 32, 33],\n",
       " [32, 33],\n",
       " [30, 31],\n",
       " [30],\n",
       " [32, 33],\n",
       " [30, 31],\n",
       " [0],\n",
       " [7, 8],\n",
       " [0],\n",
       " [6, 7, 10],\n",
       " [7],\n",
       " [0, 1, 5],\n",
       " [0, 1, 5, 7],\n",
       " [0, 18, 19],\n",
       " [0, 1, 5, 18, 19],\n",
       " [0],\n",
       " [0, 5],\n",
       " [0, 39],\n",
       " [33, 35],\n",
       " [0, 43, 44, 45, 48],\n",
       " [0, 9],\n",
       " [0, 39],\n",
       " [22, 23, 24],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [46, 49],\n",
       " [0],\n",
       " [0],\n",
       " [0, 11],\n",
       " [0, 11, 12],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [1, 3],\n",
       " [1, 6],\n",
       " [1, 8, 9, 11],\n",
       " [0, 1],\n",
       " [0, 1, 5],\n",
       " [0, 1],\n",
       " [8, 9],\n",
       " [8, 9],\n",
       " [0, 9, 12],\n",
       " [0, 6],\n",
       " [0],\n",
       " [0],\n",
       " [0, 10],\n",
       " [0, 12, 13],\n",
       " [0, 32, 33],\n",
       " [0, 32, 33],\n",
       " [0, 32, 33],\n",
       " [0, 14],\n",
       " [39],\n",
       " [0, 40],\n",
       " [0],\n",
       " [39, 43],\n",
       " [39, 40],\n",
       " [0, 35],\n",
       " [39, 42],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0, 1],\n",
       " [8, 9],\n",
       " [19],\n",
       " [21, 26, 34],\n",
       " [40, 41, 42, 43],\n",
       " [0],\n",
       " [9, 11, 12],\n",
       " [9, 12],\n",
       " [0, 1],\n",
       " [1, 9, 13],\n",
       " [19, 20, 31],\n",
       " [19],\n",
       " [19],\n",
       " [0, 2, 3, 4],\n",
       " [0, 34, 35],\n",
       " [0, 1, 21],\n",
       " [0, 3, 21, 22],\n",
       " [0, 4],\n",
       " [0, 21, 22, 24],\n",
       " [0, 1, 12, 15],\n",
       " [0, 1, 11, 12],\n",
       " [20],\n",
       " [27, 28],\n",
       " [27, 28],\n",
       " [27, 28],\n",
       " [0],\n",
       " [0, 1],\n",
       " [2, 3],\n",
       " [9, 10],\n",
       " [11, 12],\n",
       " [18, 19],\n",
       " [27, 28],\n",
       " [29, 30],\n",
       " [18, 19, 20, 21],\n",
       " [0],\n",
       " [1, 2],\n",
       " [0, 9, 10],\n",
       " [6],\n",
       " [0, 12],\n",
       " [1, 14, 15],\n",
       " [14, 16],\n",
       " [0, 1],\n",
       " [1],\n",
       " [11],\n",
       " [11],\n",
       " [2, 3],\n",
       " [4],\n",
       " [11],\n",
       " [11],\n",
       " [15],\n",
       " [11],\n",
       " [0, 1, 2],\n",
       " [6],\n",
       " [],\n",
       " [12],\n",
       " [16, 20],\n",
       " [12],\n",
       " [16, 17, 20],\n",
       " [0, 6],\n",
       " [0, 10],\n",
       " [0, 10, 34, 38, 40],\n",
       " [17, 21],\n",
       " [12, 13, 17],\n",
       " [14, 15],\n",
       " [35, 37],\n",
       " [4, 15],\n",
       " [31],\n",
       " [56],\n",
       " [49, 55],\n",
       " [11, 15],\n",
       " [1],\n",
       " [2, 4],\n",
       " [2, 7],\n",
       " [2, 8],\n",
       " [10, 12],\n",
       " [14],\n",
       " [15, 16],\n",
       " [16],\n",
       " [28, 29, 30],\n",
       " [29],\n",
       " [30],\n",
       " [35, 37, 49],\n",
       " [2, 3, 5, 6, 13, 14],\n",
       " [9, 10],\n",
       " [9, 10],\n",
       " [9, 10],\n",
       " [9, 10],\n",
       " [9, 10],\n",
       " [9, 10],\n",
       " [22, 28],\n",
       " [35],\n",
       " [35],\n",
       " [50],\n",
       " [],\n",
       " [3, 7],\n",
       " [7],\n",
       " [0, 1, 15, 16, 17, 18, 19],\n",
       " [7],\n",
       " [24],\n",
       " [14, 15],\n",
       " [29, 30, 35, 36, 39],\n",
       " [0, 3],\n",
       " [19, 20],\n",
       " [0, 4, 39],\n",
       " [4],\n",
       " [2],\n",
       " [0],\n",
       " [22],\n",
       " [0, 15, 16],\n",
       " [0, 16],\n",
       " [0, 17],\n",
       " [0],\n",
       " [5],\n",
       " [0, 15],\n",
       " [0, 15],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [1, 13],\n",
       " [12],\n",
       " [17],\n",
       " [0, 4],\n",
       " [0, 20, 21],\n",
       " [21, 27],\n",
       " [43, 44, 45, 48],\n",
       " [0, 43, 44],\n",
       " [0],\n",
       " [0, 1],\n",
       " [8, 9],\n",
       " [6, 8, 10, 14, 16],\n",
       " [32, 33],\n",
       " [34, 35],\n",
       " [14, 15],\n",
       " [23, 24],\n",
       " [1, 2, 12, 25],\n",
       " [2, 12, 25],\n",
       " [2],\n",
       " [2, 3, 4],\n",
       " [12, 15],\n",
       " [25, 26],\n",
       " [25],\n",
       " [12],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0, 2, 4, 5],\n",
       " [11],\n",
       " [12, 14],\n",
       " [18, 19],\n",
       " [16, 17],\n",
       " [12],\n",
       " [12],\n",
       " [14],\n",
       " [0, 1, 2],\n",
       " [3],\n",
       " [4],\n",
       " [10, 11],\n",
       " [10, 11],\n",
       " [11],\n",
       " [7, 8],\n",
       " [11],\n",
       " [11],\n",
       " [11],\n",
       " [11],\n",
       " [],\n",
       " [0, 1, 4],\n",
       " [7, 12],\n",
       " [13],\n",
       " [4, 6],\n",
       " [4, 6],\n",
       " [4, 6],\n",
       " [4, 8],\n",
       " [19],\n",
       " [0, 7],\n",
       " [17, 18, 19],\n",
       " [3],\n",
       " [7, 9],\n",
       " [7, 8],\n",
       " [7, 14],\n",
       " [20, 21],\n",
       " [8, 9],\n",
       " [0, 3, 4],\n",
       " [3, 9],\n",
       " [1, 3],\n",
       " [1, 2, 3],\n",
       " [15, 17],\n",
       " [16],\n",
       " [4, 6, 9],\n",
       " [0, 5],\n",
       " [0, 9],\n",
       " [10, 11],\n",
       " [0, 1],\n",
       " [9, 12],\n",
       " [9, 12],\n",
       " [17],\n",
       " [0, 28, 29],\n",
       " [0, 1, 2, 5, 9],\n",
       " [0, 1, 5, 9],\n",
       " [4, 5, 6, 7],\n",
       " [14, 15, 18],\n",
       " [22],\n",
       " [9],\n",
       " [27, 28],\n",
       " [27, 28, 29],\n",
       " [27, 28],\n",
       " [0, 2],\n",
       " [0, 5],\n",
       " [8],\n",
       " [12, 13],\n",
       " [12, 13],\n",
       " [12, 13, 14],\n",
       " [13, 14],\n",
       " [0],\n",
       " [0, 2],\n",
       " [0, 8],\n",
       " [5],\n",
       " [5, 6],\n",
       " [0],\n",
       " [],\n",
       " [0, 1, 7, 12],\n",
       " [3, 4],\n",
       " [9],\n",
       " [4, 9],\n",
       " [2, 3],\n",
       " [19, 20],\n",
       " [27, 28],\n",
       " [0, 1],\n",
       " [21, 22],\n",
       " [9, 10],\n",
       " [2],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [0, 22],\n",
       " [19],\n",
       " [10, 19],\n",
       " [0],\n",
       " [0, 2],\n",
       " [2],\n",
       " [0, 1],\n",
       " [0, 7],\n",
       " [0, 4, 6, 7],\n",
       " [0, 4],\n",
       " [2],\n",
       " [0],\n",
       " [2],\n",
       " [2],\n",
       " [2],\n",
       " [3, 8, 14, 20],\n",
       " [0, 3],\n",
       " [2, 3],\n",
       " [3, 4],\n",
       " [3, 20, 22],\n",
       " [27],\n",
       " [20, 22, 31],\n",
       " [3, 31, 33],\n",
       " [1],\n",
       " [10, 12, 13, 17],\n",
       " [3],\n",
       " [7],\n",
       " [3, 4],\n",
       " [8, 9],\n",
       " [0, 6, 9],\n",
       " [0, 3, 9],\n",
       " [0, 6, 7, 9],\n",
       " [0, 9, 11],\n",
       " [0, 9, 20],\n",
       " [0, 9, 27],\n",
       " [7, 9],\n",
       " [7, 10],\n",
       " [11, 16, 17, 18],\n",
       " [7, 12, 13, 14, 15, 17],\n",
       " [],\n",
       " [0, 2],\n",
       " [0, 2],\n",
       " [0, 1, 3],\n",
       " [0],\n",
       " [0, 4],\n",
       " [0, 4],\n",
       " [0, 5],\n",
       " [0, 4, 5],\n",
       " [0, 7, 10, 11],\n",
       " [11, 13],\n",
       " [11, 13],\n",
       " [11, 13],\n",
       " [11, 13],\n",
       " [5],\n",
       " [6],\n",
       " [0],\n",
       " [4, 5],\n",
       " [4, 5],\n",
       " [0],\n",
       " [0],\n",
       " [10],\n",
       " [1, 10, 11],\n",
       " [4, 7],\n",
       " [8],\n",
       " [15],\n",
       " [14],\n",
       " [10, 18],\n",
       " [0],\n",
       " [0, 1],\n",
       " [13],\n",
       " [2],\n",
       " [3],\n",
       " [1],\n",
       " [4, 5],\n",
       " [8],\n",
       " [9],\n",
       " [11, 12],\n",
       " [11, 12],\n",
       " [0],\n",
       " [0, 2],\n",
       " [0, 2],\n",
       " [3],\n",
       " [4, 5],\n",
       " [6],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [2],\n",
       " [2, 3],\n",
       " [5],\n",
       " [0, 13],\n",
       " [14, 15],\n",
       " [3],\n",
       " [3],\n",
       " [1, 2, 3, 4],\n",
       " [23],\n",
       " [5, 11, 12],\n",
       " [23, 24, 25, 26],\n",
       " [46, 47],\n",
       " [48, 49],\n",
       " [0],\n",
       " [0, 1],\n",
       " [2, 3, 5],\n",
       " [2, 4],\n",
       " [9],\n",
       " [12],\n",
       " [0, 1, 9],\n",
       " [12],\n",
       " [16],\n",
       " [0],\n",
       " [0, 1],\n",
       " [0, 2, 4],\n",
       " [0, 12],\n",
       " [14, 23],\n",
       " [39, 40, 41, 50],\n",
       " [0, 1],\n",
       " [7],\n",
       " [7, 9],\n",
       " [15],\n",
       " [16],\n",
       " [30, 31],\n",
       " [30, 39],\n",
       " [30, 36, 37],\n",
       " [0, 1, 2, 6, 7],\n",
       " [0, 1, 2, 6, 7],\n",
       " [8],\n",
       " [13, 16, 17],\n",
       " [17, 18, 19],\n",
       " [17, 19, 20],\n",
       " [17, 20],\n",
       " [38, 39, 40, 41],\n",
       " [44, 45],\n",
       " [46, 47],\n",
       " [1, 4, 13],\n",
       " [14],\n",
       " [14],\n",
       " [15, 16],\n",
       " [15, 16],\n",
       " [18],\n",
       " [18],\n",
       " [18],\n",
       " [18],\n",
       " [0, 2, 3, 4],\n",
       " [0],\n",
       " [12, 13, 14],\n",
       " [16, 17],\n",
       " [15, 23, 24],\n",
       " [27, 28],\n",
       " [15, 27, 34],\n",
       " [15, 27, 37],\n",
       " [46, 52],\n",
       " [27, 38, 42, 43],\n",
       " [57, 58, 59],\n",
       " [46, 58],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [2, 3],\n",
       " [3, 4],\n",
       " [4, 5],\n",
       " [17],\n",
       " [22, 23, 24, 25],\n",
       " [26],\n",
       " [],\n",
       " [0, 2],\n",
       " [2],\n",
       " [2],\n",
       " [3, 8],\n",
       " [19, 23],\n",
       " [18, 23, 24],\n",
       " [24],\n",
       " [32, 33],\n",
       " [0],\n",
       " [2, 3],\n",
       " [7],\n",
       " [13],\n",
       " [7, 8],\n",
       " [14],\n",
       " [16, 18, 19],\n",
       " [22, 23],\n",
       " [24, 25],\n",
       " [36, 37],\n",
       " [5],\n",
       " [5],\n",
       " [5, 6, 7],\n",
       " [12, 13],\n",
       " [9, 10, 11],\n",
       " [13],\n",
       " [14],\n",
       " [15],\n",
       " [16],\n",
       " [17],\n",
       " [19, 20, 21],\n",
       " [29, 31],\n",
       " [29, 30, 31],\n",
       " [32],\n",
       " [0],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2, 4],\n",
       " [8, 11, 12, 13],\n",
       " [13, 14, 15, 17, 18],\n",
       " [20],\n",
       " [20, 21, 22, 24],\n",
       " [20, 24, 25],\n",
       " [20, 24, 25],\n",
       " [30, 31, 33],\n",
       " [30, 35, 37],\n",
       " [30, 36],\n",
       " [56, 59, 60],\n",
       " [11],\n",
       " [12],\n",
       " [8, 9],\n",
       " [13, 14],\n",
       " [13, 15],\n",
       " [17],\n",
       " [33, 34, 35, 36],\n",
       " [36],\n",
       " [0, 1],\n",
       " [2],\n",
       " [9, 10],\n",
       " [2, 3],\n",
       " [2, 5, 6],\n",
       " [14],\n",
       " [19],\n",
       " [22, 23, 26, 29, 33, 37],\n",
       " [22, 23, 26, 29, 33, 37],\n",
       " [2],\n",
       " [2],\n",
       " [37, 38],\n",
       " [29, 31],\n",
       " [23],\n",
       " [0],\n",
       " [0],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 3, 4, 5],\n",
       " [14, 15, 16],\n",
       " [0, 2, 26, 29, 30],\n",
       " [31, 32, 33, 34],\n",
       " [0, 2],\n",
       " [0, 2],\n",
       " [13],\n",
       " [13],\n",
       " [16],\n",
       " [22],\n",
       " [30],\n",
       " [38, 39],\n",
       " [0],\n",
       " [0],\n",
       " [5, 7, 9, 13],\n",
       " [5, 7, 9, 13],\n",
       " [23, 24],\n",
       " [26, 27],\n",
       " [8, 10],\n",
       " [13, 14, 15, 16],\n",
       " [24, 25, 26],\n",
       " [13, 14, 15, 16],\n",
       " [20, 21, 22],\n",
       " [27, 28],\n",
       " [33, 34],\n",
       " [33, 35],\n",
       " [33, 37],\n",
       " [33, 37, 38],\n",
       " [39, 40, 41],\n",
       " [],\n",
       " [0, 1, 10],\n",
       " [7],\n",
       " [0, 1, 10],\n",
       " [10],\n",
       " [10],\n",
       " [10],\n",
       " [10],\n",
       " [10],\n",
       " [10],\n",
       " [10],\n",
       " [10],\n",
       " [0],\n",
       " [2],\n",
       " [20],\n",
       " [20, 21, 22],\n",
       " [0, 2],\n",
       " [36],\n",
       " [2, 17],\n",
       " [46, 47, 48, 49, 62, 63, 64],\n",
       " [0],\n",
       " [0, 1],\n",
       " [0, 5, 6, 7],\n",
       " [8, 9],\n",
       " [21, 22],\n",
       " [22, 24, 25, 26],\n",
       " [29, 30, 31, 32, 33],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [14, 15, 16, 17],\n",
       " [20],\n",
       " [20],\n",
       " [22, 23, 25, 26],\n",
       " [29, 30, 31, 32],\n",
       " [47, 48],\n",
       " [0],\n",
       " [51, 52, 53],\n",
       " [1, 2, 3, 5, 6],\n",
       " [7, 8, 9],\n",
       " [9, 11, 12],\n",
       " [22, 23, 26, 27, 28],\n",
       " [31, 32, 33],\n",
       " [39, 42],\n",
       " [39, 44],\n",
       " [0, 5, 6],\n",
       " [11, 19, 20],\n",
       " [21, 22, 23],\n",
       " [11, 30],\n",
       " [11, 40, 41, 42],\n",
       " [11, 52, 53, 54],\n",
       " [1, 11, 13, 28],\n",
       " [13, 14],\n",
       " [0, 13, 14, 22, 25, 26],\n",
       " [8, 9, 11, 13],\n",
       " [0, 27, 31],\n",
       " [31, 32],\n",
       " [27, 28],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [1],\n",
       " [2, 5],\n",
       " [7, 8, 9],\n",
       " [18, 20, 21],\n",
       " [24],\n",
       " [0, 5, 6, 7],\n",
       " [5, 9],\n",
       " [5, 9],\n",
       " [9, 10, 11],\n",
       " [12, 13, 14],\n",
       " [24, 25],\n",
       " [24, 25],\n",
       " [24, 25],\n",
       " [33],\n",
       " [0],\n",
       " [0, 1, 2],\n",
       " [0],\n",
       " [0, 10, 12, 15, 17],\n",
       " [10, 15, 17, 18, 19, 20],\n",
       " [24],\n",
       " [24],\n",
       " [24],\n",
       " [24],\n",
       " [17, 24, 25, 26],\n",
       " [4],\n",
       " [4, 5],\n",
       " [5],\n",
       " [6],\n",
       " [5],\n",
       " [6],\n",
       " [6],\n",
       " [1],\n",
       " [1, 5, 7],\n",
       " [2, 3],\n",
       " [1, 2, 3, 4],\n",
       " [0, 1],\n",
       " [0, 5],\n",
       " [0, 7],\n",
       " [6, 9, 10, 19, 25, 31, 35],\n",
       " [10, 19, 20],\n",
       " [10],\n",
       " [10, 19, 20],\n",
       " [19, 20],\n",
       " [19, 20, 21],\n",
       " [10, 12],\n",
       " [10, 12, 14],\n",
       " [19, 23],\n",
       " [13, 14],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [1, 2, 7, 8, 10],\n",
       " [1, 2, 7, 8, 9],\n",
       " [1, 2, 7, 8, 10],\n",
       " [9, 10],\n",
       " [25, 26, 27],\n",
       " [0, 1, 3],\n",
       " [9, 12, 13],\n",
       " [9, 15],\n",
       " [21, 24],\n",
       " [27, 28, 29],\n",
       " [27, 28],\n",
       " [27, 28],\n",
       " [9, 14, 15, 16],\n",
       " [21, 24],\n",
       " [19, 30, 31],\n",
       " [5, 6, 7, 9, 10, 11, 15],\n",
       " [15, 16],\n",
       " [18, 19],\n",
       " [35, 37],\n",
       " [35, 37],\n",
       " [35, 37],\n",
       " [0, 1],\n",
       " [3],\n",
       " [6, 7],\n",
       " [16, 17, 18],\n",
       " [20, 21],\n",
       " [29, 32],\n",
       " [30, 32],\n",
       " [39, 40],\n",
       " [22, 23, 24, 25],\n",
       " [18],\n",
       " [32],\n",
       " [23],\n",
       " [],\n",
       " [34],\n",
       " [0, 4, 9, 31, 32],\n",
       " [0, 5],\n",
       " [2, 5],\n",
       " [5, 6],\n",
       " [5, 6],\n",
       " [30, 31]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model_eval(new_network, eval_train_batches, 0, training_data['QUESTIONS'].apply(lambda x: x[0]['SHINT_']).tolist(), 0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a53720000ed403c8b8eb8573ff7b626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1807), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000005\n",
      "epoch 0 train_loss: 0.122\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57a2168935514ff29a673e445e8104b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-155-41a2b2197348>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_train_3d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.00002\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-108-292a0695e69a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(network, data, dev_batches, num_epochs, lr)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunning_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch %d train_loss: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcurrent_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mnew_model_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp_golds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-107-b9b4ee56998e>\u001b[0m in \u001b[0;36mnew_model_eval\u001b[0;34m(network, dev_batches, current_epoch, sp_golds, avg_loss)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mout_dct\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_fgc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0msp_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_dct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-aa65ccc0f9ec>\u001b[0m in \u001b[0;36mpredict_fgc\u001b[0;34m(self, batch, threshold)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_fgc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0mmax_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mmax_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-aa65ccc0f9ec>\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-aa65ccc0f9ec>\u001b[0m in \u001b[0;36mforward_nn\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mmax_sent_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "train(new_network, dataloader_train_3d, a, 20, 0.00002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 768])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Parameter(torch.FloatTensor(768).uniform_(-0.1, 0.1)).expand(2, 10, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 7, 68])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = iter(dataloader_train_3d).next()['ids']\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 4397,  342, 1367, 2548, 1355, 4385, 4342, 4342, 4500,  784,  720,\n",
       "         3341, 7157, 4635, 6009, 8024, 2130, 2768, 1400, 1315, 5543, 3175,  912,\n",
       "         4638, 3123, 6822, 5632, 2346, 1673, 2349,  775, 1358, 4635, 6009, 1920,\n",
       "         7623, 8043,  102, 7479, 5865, 6814,  782, 4638, 2608, 2552,  680, 3675,\n",
       "         1213, 8024,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 101, 4397,  342, 1367, 2548, 1355, 4385, 4342, 4342, 4500,  784,  720,\n",
       "         3341, 7157, 4635, 6009, 8024, 2130, 2768, 1400, 1315, 5543, 3175,  912,\n",
       "         4638, 3123, 6822, 5632, 2346, 1673, 2349,  775, 1358, 4635, 6009, 1920,\n",
       "         7623, 8043,  102, 4397,  679,  852, 2868, 2245,  749,  782, 5102, 4638,\n",
       "         4761, 6399, 7566, 1818, 8024,  102,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 101, 4397,  342, 1367, 2548, 1355, 4385, 4342, 4342, 4500,  784,  720,\n",
       "         3341, 7157, 4635, 6009, 8024, 2130, 2768, 1400, 1315, 5543, 3175,  912,\n",
       "         4638, 3123, 6822, 5632, 2346, 1673, 2349,  775, 1358, 4635, 6009, 1920,\n",
       "         7623, 8043,  102,  738, 3136, 2193, 2769,  812, 8024,  102,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 101, 4397,  342, 1367, 2548, 1355, 4385, 4342, 4342, 4500,  784,  720,\n",
       "         3341, 7157, 4635, 6009, 8024, 2130, 2768, 1400, 1315, 5543, 3175,  912,\n",
       "         4638, 3123, 6822, 5632, 2346, 1673, 2349,  775, 1358, 4635, 6009, 1920,\n",
       "         7623, 8043,  102, 6206,  809, 3291,  711,  782, 6887, 4638, 5125, 4868,\n",
       "         3341, 2190, 2521, 1220, 4289,  511,  102,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]], device='cuda:0')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_network.loss(iter(dataloader_train_3d).next())[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_network.loss(iter(dataloader_train_3d).next())[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': tensor([[[ 101, 1380, 2577,  ...,    0,    0,    0],\n",
       "          [ 101, 1380, 2577,  ...,    0,    0,    0],\n",
       "          [ 101, 1380, 2577,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 101, 1380, 2577,  ...,    0,    0,    0],\n",
       "          [ 101, 1380, 2577,  ...,    0,    0,    0],\n",
       "          [ 101, 1380, 2577,  ...,    0,    0,    0]],\n",
       " \n",
       "         [[ 101, 5018,  671,  ...,    0,    0,    0],\n",
       "          [ 101, 5018,  671,  ...,    0,    0,    0],\n",
       "          [ 101, 5018,  671,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 101, 5018,  671,  ...,    0,    0,    0],\n",
       "          [ 101, 5018,  671,  ...,    0,    0,    0],\n",
       "          [ 101, 5018,  671,  ...,    0,    0,    0]]], device='cuda:0'),\n",
       " 'mask_ids': tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]]], device='cuda:0'),\n",
       " 'segment_ids': tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]]], device='cuda:0'),\n",
       " 'labels': tensor([[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]], device='cuda:0')}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter(dataloader_train_3d).next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Improved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data_with_performance_0 = datapreprocessing(validation_data, True)\n",
    "training_data_with_performance_0 = datapreprocessing(training_data, True)\n",
    "test_data_with_performance_0 = datapreprocessing(test_data, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a07dee24f94334b3b836ebff3d932e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=882), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.18, 'sp_prec': 0.573, 'sp_recall': 0.381, 'sp_f1': 0.43}\n",
      "epoch 0 eval_recall: 0.381 eval_f1: 0.430 loss: 0.001\n"
     ]
    }
   ],
   "source": [
    "train_pred_0, train_obs_0 = new_model_eval(new_network, b, 0, training_data['QUESTIONS'].apply(lambda x: x[0]['SHINT_']).tolist()\n",
    ", 0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_with_performance_0['train_pred'] = train_pred_0\n",
    "training_data_with_performance_0['train_obs'] = train_obs_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_sp = []\n",
    "for i in range(training_data_with_performance_0.shape[0]):\n",
    "    para = training_data_with_performance_0['Sentence_List'][i]\n",
    "    sen = []\n",
    "    for index in training_data_with_performance_0['train_pred'][i]:\n",
    "        sen.append(para[index])\n",
    "    correct_sp.append(sen)\n",
    "training_data_with_performance_0['Pred_List'] = correct_sp\n",
    "correct_sp = []\n",
    "for i in range(training_data_with_performance_0.shape[0]):\n",
    "    para = training_data_with_performance_0['Sentence_List'][i]\n",
    "    sen = []\n",
    "    for index in training_data_with_performance_0['train_obs'][i]:\n",
    "        sen.append(para[index])\n",
    "    correct_sp.append(sen)\n",
    "training_data_with_performance_0['Obs_List'] = correct_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_with_performance_0.drop(['SE_Index', 'Label', 'train_pred', 'train_obs'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Sentence_List</th>\n",
       "      <th>Length</th>\n",
       "      <th>Pred_List</th>\n",
       "      <th>Obs_List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>苏东坡的老家在哪?</td>\n",
       "      <td>[嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...</td>\n",
       "      <td>35</td>\n",
       "      <td>[苏轼才20岁，]</td>\n",
       "      <td>[苏轼回蜀守丧，]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>苏东坡出生于哪一年?</td>\n",
       "      <td>[嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...</td>\n",
       "      <td>35</td>\n",
       "      <td>[苏轼才20岁，]</td>\n",
       "      <td>[嘉佑二年（1057年），, 苏轼才20岁，]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>苏东坡和谁一起进京参加会考?</td>\n",
       "      <td>[嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...</td>\n",
       "      <td>35</td>\n",
       "      <td>[苏轼才20岁，]</td>\n",
       "      <td>[苏轼才20岁，, 与弟弟苏辙一同进京参加会考，]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>苏东坡与曾巩是否同为欧阳修的学生?</td>\n",
       "      <td>[嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...</td>\n",
       "      <td>35</td>\n",
       "      <td>[苏轼以一篇《刑赏忠厚之至论》的论文得到考官梅尧臣的青睐，]</td>\n",
       "      <td>[欧阳修亦十分赞赏，, 原本欲拔擢为第一，, 但又怕该文为自己的门生曾巩所作，, 为了避嫌，...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>苏东坡与王安石在职场上是否理念相同?</td>\n",
       "      <td>[嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...</td>\n",
       "      <td>35</td>\n",
       "      <td>[苏轼以一篇《刑赏忠厚之至论》的论文得到考官梅尧臣的青睐，]</td>\n",
       "      <td>[反对王安石变法中的一些作为，, 王安石于是屡次在神宗面前诋毁苏轼，]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>小明感染肠病毒后痊瘉一周后是否就不会再传染给别人了?</td>\n",
       "      <td>[国内肠病毒轻症疫情持续上升，, 另新增1例肠病毒71型并发重症病例。, 疾病管制署再次呼吁...</td>\n",
       "      <td>42</td>\n",
       "      <td>[请尽速送大医院接受治疗。]</td>\n",
       "      <td>[痊愈后肠病毒会随著粪便排出达8到12周之久。]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>877</td>\n",
       "      <td>这起诈骗案件发生于台北市哪一个行政区？</td>\n",
       "      <td>[松山分局三民派出所警员白小帆，, 警员张秀秀。, 于一百零八年十月三十一日十五时至十七时，...</td>\n",
       "      <td>32</td>\n",
       "      <td>[松山分局三民派出所警员白小帆，, 于一百零八年十月三十一日十五时至十七时，, 疑似遭到诈骗...</td>\n",
       "      <td>[松山分局三民派出所警员白小帆，, 疑似遭到诈骗两元，]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>878</td>\n",
       "      <td>这起诈骗案件发生的日期是哪一天？</td>\n",
       "      <td>[松山分局三民派出所警员白小帆，, 警员张秀秀。, 于一百零八年十月三十一日十五时至十七时，...</td>\n",
       "      <td>32</td>\n",
       "      <td>[疑似遭到诈骗两元，, 到场后，发现系一名年约八十二岁陈姓妇人\\n欲提领新台币三十三万元。]</td>\n",
       "      <td>[于一百零八年十月三十一日十五时至十七时，, 疑似遭到诈骗两元，]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>这起诈骗案件的受害人姓氏为何？</td>\n",
       "      <td>[松山分局三民派出所警员白小帆，, 警员张秀秀。, 于一百零八年十月三十一日十五时至十七时，...</td>\n",
       "      <td>32</td>\n",
       "      <td>[疑似遭到诈骗两元，]</td>\n",
       "      <td>[疑似遭到诈骗两元，, 到场后，发现系一名年约八十二岁陈姓妇人\\n欲提领新台币三十三万元。]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>881</td>\n",
       "      <td>反诈骗专线电话是几号？</td>\n",
       "      <td>[松山分局三民派出所警员白小帆，, 警员张秀秀。, 于一百零八年十月三十一日十五时至十七时，...</td>\n",
       "      <td>32</td>\n",
       "      <td>[避免遭诈骗。]</td>\n",
       "      <td>[也可拨打一六五求证，, 避免遭诈骗。]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>723 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Question  \\\n",
       "0                     苏东坡的老家在哪?   \n",
       "1                    苏东坡出生于哪一年?   \n",
       "2                苏东坡和谁一起进京参加会考?   \n",
       "4             苏东坡与曾巩是否同为欧阳修的学生?   \n",
       "5            苏东坡与王安石在职场上是否理念相同?   \n",
       "..                          ...   \n",
       "875  小明感染肠病毒后痊瘉一周后是否就不会再传染给别人了?   \n",
       "877         这起诈骗案件发生于台北市哪一个行政区？   \n",
       "878            这起诈骗案件发生的日期是哪一天？   \n",
       "880             这起诈骗案件的受害人姓氏为何？   \n",
       "881                 反诈骗专线电话是几号？   \n",
       "\n",
       "                                         Sentence_List  Length  \\\n",
       "0    [嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...      35   \n",
       "1    [嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...      35   \n",
       "2    [嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...      35   \n",
       "4    [嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...      35   \n",
       "5    [嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...      35   \n",
       "..                                                 ...     ...   \n",
       "875  [国内肠病毒轻症疫情持续上升，, 另新增1例肠病毒71型并发重症病例。, 疾病管制署再次呼吁...      42   \n",
       "877  [松山分局三民派出所警员白小帆，, 警员张秀秀。, 于一百零八年十月三十一日十五时至十七时，...      32   \n",
       "878  [松山分局三民派出所警员白小帆，, 警员张秀秀。, 于一百零八年十月三十一日十五时至十七时，...      32   \n",
       "880  [松山分局三民派出所警员白小帆，, 警员张秀秀。, 于一百零八年十月三十一日十五时至十七时，...      32   \n",
       "881  [松山分局三民派出所警员白小帆，, 警员张秀秀。, 于一百零八年十月三十一日十五时至十七时，...      32   \n",
       "\n",
       "                                             Pred_List  \\\n",
       "0                                            [苏轼才20岁，]   \n",
       "1                                            [苏轼才20岁，]   \n",
       "2                                            [苏轼才20岁，]   \n",
       "4                       [苏轼以一篇《刑赏忠厚之至论》的论文得到考官梅尧臣的青睐，]   \n",
       "5                       [苏轼以一篇《刑赏忠厚之至论》的论文得到考官梅尧臣的青睐，]   \n",
       "..                                                 ...   \n",
       "875                                     [请尽速送大医院接受治疗。]   \n",
       "877  [松山分局三民派出所警员白小帆，, 于一百零八年十月三十一日十五时至十七时，, 疑似遭到诈骗...   \n",
       "878     [疑似遭到诈骗两元，, 到场后，发现系一名年约八十二岁陈姓妇人\\n欲提领新台币三十三万元。]   \n",
       "880                                        [疑似遭到诈骗两元，]   \n",
       "881                                           [避免遭诈骗。]   \n",
       "\n",
       "                                              Obs_List  \n",
       "0                                            [苏轼回蜀守丧，]  \n",
       "1                              [嘉佑二年（1057年），, 苏轼才20岁，]  \n",
       "2                            [苏轼才20岁，, 与弟弟苏辙一同进京参加会考，]  \n",
       "4    [欧阳修亦十分赞赏，, 原本欲拔擢为第一，, 但又怕该文为自己的门生曾巩所作，, 为了避嫌，...  \n",
       "5                  [反对王安石变法中的一些作为，, 王安石于是屡次在神宗面前诋毁苏轼，]  \n",
       "..                                                 ...  \n",
       "875                           [痊愈后肠病毒会随著粪便排出达8到12周之久。]  \n",
       "877                       [松山分局三民派出所警员白小帆，, 疑似遭到诈骗两元，]  \n",
       "878                  [于一百零八年十月三十一日十五时至十七时，, 疑似遭到诈骗两元，]  \n",
       "880     [疑似遭到诈骗两元，, 到场后，发现系一名年约八十二岁陈姓妇人\\n欲提领新台币三十三万元。]  \n",
       "881                               [也可拨打一六五求证，, 避免遭诈骗。]  \n",
       "\n",
       "[723 rows x 5 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mismatch = training_data_with_performance_0[training_data_with_performance_0['Pred_List'] != training_data_with_performance_0['Obs_List']]\n",
    "train_mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 17\n",
    "print(train_mismatch.loc[i]['Question'])\n",
    "print(train_mismatch.loc[i]['Pred_List'])\n",
    "print(train_mismatch.loc[i]['Obs_List'])\n",
    "train_mismatch.loc[i]['Sentence_List']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0724 09:52:32.290062 140341672732480 tokenization_utils.py:375] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /root/.cache/torch/transformers/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for a in dataloader_train_3d:\n",
    "    for b in a['']:\n",
    "        for c in b:\n",
    "            print(c)\n",
    "            #print(tokenizer.convert_ids_to_tokens(c.tolist()))\n",
    "    counter += 1\n",
    "    if counter == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
