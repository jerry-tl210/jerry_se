{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0812 07:04:58.167424 140680368949056 file_utils.py:39] PyTorch version 1.2.0+cu92 available.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM, BertForQuestionAnswering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence \n",
    "import torchvision\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.optimization import AdamW\n",
    "from transformers.optimization import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = pd.read_json(\"FGC_release_1.7.13/FGC_release_all_dev.json\")\n",
    "training_data = pd.read_json(\"FGC_release_1.7.13/FGC_release_all_train.json\")\n",
    "test_data = pd.read_json(\"FGC_release_1.7.13/FGC_release_all_test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all the questions where there's no supporting evidence to it\n",
    "training_data = training_data[training_data['QUESTIONS'].apply(lambda x: len(x[0]['SHINT_']) > 0)]\n",
    "validation_data = validation_data[validation_data['QUESTIONS'].apply(lambda x: len(x[0]['SHINT_']) > 0)]\n",
    "test_data = test_data[test_data['QUESTIONS'].apply(lambda x: len(x[0]['SHINT_']) > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2]).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0812 07:09:56.867145 140680368949056 tokenization_utils_base.py:1254] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /root/.cache/torch/transformers/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(data):\n",
    "    all_instances = []\n",
    "    questions = data['QUESTIONS'].apply(lambda x: [x[0]['QTEXT_CN'], len(x[0]['SHINT'][1])]).tolist()\n",
    "    sentences = [sentence['text'] for sentence_dict in data['SENTS'] for sentence in sentence_dict]\n",
    "    lengths = np.array(questions)[:, 1].astype(int).tolist()\n",
    "    indices = data['QUESTIONS'].apply(lambda x: x[0]['SHINT_']).tolist()\n",
    "    labels = [[0] * length for length in lengths]\n",
    "    all_labels = []\n",
    "    # Inpute index into labels\n",
    "    for i in range(len(labels)):\n",
    "        np_label = np.array(labels[i])\n",
    "        np_index = np.array(indices[i])\n",
    "        np_label[np_index] = 1\n",
    "        label = np_label.tolist()\n",
    "        labels[i] = label\n",
    "        all_labels = all_labels + label\n",
    "    counter = 0\n",
    "    for question in questions:\n",
    "        question_text = question[0]\n",
    "        for j in range(counter, counter + question[1]):\n",
    "            all_instances.append([question_text, sentences[j]])\n",
    "    \n",
    "    all_tokenized = []\n",
    "    for i in range(len(all_instances)):\n",
    "        tokenized = tokenizer([all_instances[i]], padding='max_length', truncation=True, max_length=512, return_tensors = 'pt')\n",
    "        tokenized['input_ids'] = tokenized['input_ids'].to(device)\n",
    "        tokenized['input_ids'] = tokenized['input_ids'].squeeze(0)\n",
    "        tokenized['token_type_ids'] = tokenized['token_type_ids'].to(device)\n",
    "        tokenized['token_type_ids'] = tokenized['token_type_ids'].squeeze(0)\n",
    "        tokenized['attention_mask'] = tokenized['attention_mask'].to(device)\n",
    "        tokenized['attention_mask'] = tokenized['attention_mask'].squeeze(0)\n",
    "        tokenized['label'] = torch.tensor(all_labels[i])\n",
    "        all_tokenized.append(tokenized)\n",
    "    return all_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dev_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-3dfcc814f556>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_all_instances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_preprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdev_all_instances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_preprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_all_instances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_preprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dev_data' is not defined"
     ]
    }
   ],
   "source": [
    "train_all_instances = data_preprocessing(training_data)\n",
    "dev_all_instances = data_preprocessing(dev_data)\n",
    "test_all_instances = data_preprocessing(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0812 02:15:41.785210 139797494843200 tokenization_utils_base.py:1254] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /root/.cache/torch/transformers/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datapreprocessing(data, return_df=False):\n",
    "    \n",
    "    # Save all the questions, potential supporting evidence and indices in three lists\n",
    "    textQ_to_be_tokenized = []\n",
    "    textA_to_be_tokenized = []\n",
    "    sp_index = []\n",
    "    max_counter = 0\n",
    "    for dictionary in data['QUESTIONS']:\n",
    "        for element in dictionary:\n",
    "            textQ_to_be_tokenized.append(element['QTEXT_CN'])\n",
    "            sp_index.append(element['SHINT_'])\n",
    "    for dictionary in data['SENTS']:\n",
    "        current_text_sentence = []\n",
    "        for element in dictionary:\n",
    "            current_text_sentence.append(element['text'])\n",
    "        textA_to_be_tokenized.append(current_text_sentence)\n",
    "    \n",
    "    QandA_label = pd.DataFrame({'Question': textQ_to_be_tokenized,\n",
    "                                'Sentence_List': textA_to_be_tokenized,\n",
    "                                'SE_Index': sp_index,\n",
    "                                'Label': sp_index})\n",
    "\n",
    "    QandA_label['Length'] = QandA_label['Sentence_List'].apply(lambda x: len(x))\n",
    "    QandA_label['SE_Index'] = QandA_label['SE_Index'].apply(lambda x: [0])\n",
    "    QandA_label['SE_Index'] = QandA_label['SE_Index'] * QandA_label['Length']\n",
    "    QandA_label['SE_Index'] = list(zip(QandA_label['SE_Index'], QandA_label['Label']))\n",
    "\n",
    "    # Extract label index\n",
    "    for row in QandA_label['SE_Index']:\n",
    "        for index in row[1]:\n",
    "            row[0][index] = 1\n",
    "        \n",
    "    indexed = [i[0] for i in list(QandA_label['SE_Index'])]\n",
    "    QandA_label['Label'] = indexed\n",
    "\n",
    "    if return_df:\n",
    "        return QandA_label\n",
    "    \n",
    "    Q_and_Sentence_all_Comb = pd.DataFrame({'Question':np.repeat(QandA_label['Question'].values, QandA_label['Sentence_List'].str.len()),\n",
    "                        'Sentence':np.concatenate(QandA_label['Sentence_List'].values)})\n",
    "    Q_and_Sentence_all_Comb['Label'] = QandA_label['Label'].sum()\n",
    "    \n",
    "            \n",
    "    # Put all question and sentence combination into a list \n",
    "    All_instances = []\n",
    "    \n",
    "        \n",
    "    for i in range(len(QandA_label)):\n",
    "        \n",
    "        for sentence in QandA_label['Sentence_List'][i]:\n",
    "            question_token = tokenizer.tokenize(QandA_label['Question'][i])\n",
    "            sentence_token = tokenizer.tokenize(sentence)\n",
    "            instance = ['[CLS]'] + question_token + ['[SEP]'] + sentence_token + ['[SEP]'] \n",
    "\n",
    "            \n",
    "            if len(instance) > 512:\n",
    "                instance = instance[:511] + ['[SEP]']\n",
    "                #max_counter += 1\n",
    "\n",
    "            #instance = instance[:100]\n",
    "            All_instances.append(instance)\n",
    "            \n",
    "    # Convert ids to segment_ids\n",
    "    segment_ids = []\n",
    "    for token in All_instances:\n",
    "        length_of_zeros = token.index('[SEP]') - token.index('[CLS]') + 1\n",
    "        length_of_ones = len(token) - length_of_zeros\n",
    "        zeros_and_ones = [0] * length_of_zeros + [1] * length_of_ones\n",
    "        segment_ids.append(zeros_and_ones)\n",
    "        \n",
    "    ids = []\n",
    "    for token in All_instances:\n",
    "        ids.append(tokenizer.convert_tokens_to_ids(token))\n",
    "        \n",
    "    mask_ids = []\n",
    "    for token in All_instances:\n",
    "        mask_ids.append([1] * len(token))\n",
    "        \n",
    "    labels = list(Q_and_Sentence_all_Comb['Label'])\n",
    "    labels = [[i] for i in labels]\n",
    "    return All_instances, ids, segment_ids, mask_ids, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_sentence(data, number_of_sentence):\n",
    "    \n",
    "    QandA_label = datapreprocessing(training_data, True)\n",
    "    \n",
    "    Q_and_Sentence_all_Comb = pd.DataFrame({'Question':np.repeat(QandA_label['Question'].values, QandA_label['Sentence_List'].str.len()),\n",
    "                        'Sentence':np.concatenate(QandA_label['Sentence_List'].values)})\n",
    "    Q_and_Sentence_all_Comb['Label'] = QandA_label['Label'].sum()\n",
    "    \n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "\n",
    "    len_array = np.cumsum(np.array(data['SENTS'].apply(lambda x: len(x))))\n",
    "\n",
    "    # Put all question and sentence combination into a list \n",
    "    All_instances = []\n",
    "    padded_zeros = [0] * 250\n",
    "    \n",
    "    for i in range(len(QandA_label)):\n",
    "        \n",
    "        for j in range(len(QandA_label['Sentence_List'][i])):\n",
    "            \n",
    "            question_token = tokenizer.tokenize(QandA_label['Question'][i])\n",
    "            q_instance = ['[CLS]'] + question_token + ['[SEP]']\n",
    "            if len(q_instance) > 250:\n",
    "                q_instance = q_instance[:249] + ['[SEP]']\n",
    "\n",
    "            sentences = []\n",
    "            \n",
    "            for k in range(j - number_of_sentence//2, j + number_of_sentence//2 + 1):\n",
    "                if k < 0 or k >= len(QandA_label['Sentence_List'][i]):\n",
    "                    sentences.append(padded_zeros)\n",
    "                else:\n",
    "                    sentence_token = tokenizer.tokenize(QandA_label['Sentence_List'][i][k])\n",
    "                    s_instance = ['[CLS]'] + sentence_token + ['[SEP]']\n",
    "                    if len(s_instance) > 250:\n",
    "                        s_instance = s_instance[:249] + ['[SEP]']\n",
    "                    sentences.append(s_instance)\n",
    "            \n",
    "                \n",
    "            # Append the target sentence\n",
    "            #question_token = tokenizer.tokenize(QandA_label['Question'][i])\n",
    "            #sentence_token = tokenizer.tokenize(QandA_label['Sentence_List'][i][j])\n",
    "            #q_instance = ['[CLS]'] + question_token + ['[SEP]']\n",
    "            #s_instance = ['[CLS]'] + sentence_token + ['[SEP]'] \n",
    "            \n",
    "            #if len(s_instance) > 250:\n",
    "                #s_instance = s_instance[:249] + ['[SEP]']\n",
    "            #if len(q_instance) > 250:\n",
    "                #question = question[:249] + ['[SEP]']\n",
    "\n",
    "            All_instances.append((q_instance, sentences))\n",
    "\n",
    "    ids = []\n",
    "    mask_ids = []\n",
    "    sentence_masks = []\n",
    "    \n",
    "    for token in All_instances:\n",
    "        \n",
    "        q_tokenized = tokenizer.convert_tokens_to_ids(token[0])\n",
    "        q_mask = [1] * 250\n",
    "        \n",
    "        if len(q_tokenized) < 250:\n",
    "            q_tokenized = q_tokenized + (250 - len(q_tokenized)) * [0]\n",
    "            q_mask = q_tokenized.index(0) * [1] + (250 - q_tokenized.index(0)) * [0]\n",
    "            \n",
    "        s_tokens = []\n",
    "        s_masks = []\n",
    "        sen_mask = []\n",
    "        for sentence in token[1]:\n",
    "            \n",
    "            if sentence == padded_zeros:\n",
    "                s_tokens.append(padded_zeros)\n",
    "                s_masks.append(padded_zeros)\n",
    "                sen_mask.append([0])\n",
    "                \n",
    "            else:\n",
    "                s_tokenized = tokenizer.convert_tokens_to_ids(sentence)\n",
    "                s_mask = [1] * 250\n",
    "        \n",
    "                if len(s_tokenized) < 250:\n",
    "                    s_tokenized = s_tokenized + (250 - len(s_tokenized)) * [0]\n",
    "                    s_mask = s_tokenized.index(0) * [1] + (250 - s_tokenized.index(0)) * [0]\n",
    "            \n",
    "                s_tokens.append(s_tokenized)\n",
    "                s_masks.append(s_mask)\n",
    "                sen_mask.append([1])\n",
    "                \n",
    "        ids.append((q_tokenized, s_tokens))\n",
    "        mask_ids.append((q_mask, s_masks))\n",
    "        sentence_masks.append(sen_mask)\n",
    "\n",
    "    labels = list(Q_and_Sentence_all_Comb['Label'])\n",
    "    labels = [[i] for i in labels]\n",
    "    return All_instances, ids, mask_ids, sentence_masks, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_sentence_preprocessing(data, dataset, number_of_sentences):\n",
    "    \n",
    "    len_array = np.cumsum(np.array(data['SENTS'].apply(lambda x: len(x))))\n",
    "    dictionary_lists = []\n",
    "    batches = []\n",
    "    \n",
    "    unit_counter = 0\n",
    "    \n",
    "    for count, instance in enumerate(dataset, 1):\n",
    "        \n",
    "        dictionary_lists.append(instance)\n",
    "        unit_counter += 1\n",
    "        \n",
    "        if (unit_counter % number_of_sentences == 0) or (count in len_array):\n",
    "            \n",
    "            padded_ids = pad_sequence([torch.tensor(instance['ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_ids = padded_ids.to(device)\n",
    "\n",
    "            padded_segment_ids = pad_sequence([torch.tensor(instance['segment_ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_segment_ids = padded_segment_ids.to(device)\n",
    "\n",
    "            padded_mask_ids = pad_sequence([torch.tensor(instance['mask_ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_mask_ids = padded_mask_ids.to(device)\n",
    "\n",
    "            labels = torch.stack([torch.tensor(instance['labels']) for instance in dictionary_lists])\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            current_dev_batch = {'ids': padded_ids, 'mask_ids': padded_mask_ids, 'segment_ids': padded_segment_ids, 'labels': labels}\n",
    "\n",
    "            batches.append(current_dev_batch)\n",
    "            dictionary_lists = []\n",
    "            unit_counter = 0\n",
    "    \n",
    "    return batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_window_sentence_preprocessing(data, dataset, number_of_sentences):\n",
    "    \n",
    "    len_array = np.cumsum(np.array(data['SENTS'].apply(lambda x: len(x))))\n",
    "    dictionary_lists = []\n",
    "    batches = []\n",
    "    \n",
    "    unit_counter = 0\n",
    "    \n",
    "    for i in range(1, len(dataset) + 1):\n",
    "        \n",
    "        # Need to pad zeros\n",
    "        dictionary_lists.append(dataset[i-1])\n",
    "        dictionary_lists\n",
    "        unit_counter += 1\n",
    "        \n",
    "        if (unit_counter % number_of_sentences == 0) or (i in len_array):\n",
    "            \n",
    "            padded_ids = pad_sequence([torch.tensor(instance['ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_ids = padded_ids.to(device)\n",
    "\n",
    "            padded_segment_ids = pad_sequence([torch.tensor(instance['segment_ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_segment_ids = padded_segment_ids.to(device)\n",
    "\n",
    "            padded_mask_ids = pad_sequence([torch.tensor(instance['mask_ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_mask_ids = padded_mask_ids.to(device)\n",
    "\n",
    "            labels = torch.stack([torch.tensor(instance['labels']) for instance in dictionary_lists])\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            current_dev_batch = {'ids': padded_ids, 'mask_ids': padded_mask_ids, 'segment_ids': padded_segment_ids, 'labels': labels}\n",
    "\n",
    "            batches.append(current_dev_batch)\n",
    "            dictionary_lists = []\n",
    "            unit_counter = 0\n",
    "    \n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_preprocessing(data, dataset):\n",
    "    \n",
    "    len_array = np.cumsum(np.array(data['SENTS'].apply(lambda x: len(x))))\n",
    "\n",
    "    dictionary_lists = []\n",
    "    batches = []\n",
    "    for i in range(len(dataset.instances)):\n",
    "        \n",
    "        instance = dataset.instances[i]\n",
    "        dictionary_lists.append(instance)\n",
    "        \n",
    "        if i in len_array - 1:\n",
    "\n",
    "            padded_ids = pad_sequence([torch.tensor(instance['ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_ids = padded_ids.to(device)\n",
    "\n",
    "            padded_segment_ids = pad_sequence([torch.tensor(instance['segment_ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_segment_ids = padded_segment_ids.to(device)\n",
    "\n",
    "            padded_mask_ids = pad_sequence([torch.tensor(instance['mask_ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_mask_ids = padded_mask_ids.to(device)\n",
    "\n",
    "            labels = torch.stack([torch.tensor(instance['labels']) for instance in dictionary_lists])\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            \n",
    "            current_dev_batch = {'ids': padded_ids, 'mask_ids': padded_mask_ids, 'segment_ids': padded_segment_ids, 'labels': labels}\n",
    "\n",
    "            batches.append(current_dev_batch)\n",
    "            dictionary_lists = []\n",
    "\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_eval_preprocessing(data, dataset): \n",
    "    \n",
    "    len_array = np.cumsum(np.array(data['SENTS'].apply(lambda x: len(x))))\n",
    "\n",
    "    dictionary_lists = []\n",
    "    batches = []\n",
    "    for i in range(len(dataset.instances)):\n",
    "        \n",
    "        instance = dataset.instances[i]\n",
    "        dictionary_lists.append(instance)\n",
    "        \n",
    "        if i in len_array - 1:\n",
    "\n",
    "            \n",
    "            padded_ids = pad_sequence([torch.tensor(instance['ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_ids = padded_ids.to(device)\n",
    "\n",
    "            #padded_segment_ids = pad_sequence([torch.tensor(instance['segment_ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            #padded_segment_ids = padded_segment_ids.to(device)\n",
    "\n",
    "            padded_mask_ids = pad_sequence([torch.tensor(instance['mask_ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_mask_ids = padded_mask_ids.to(device)\n",
    "            \n",
    "            padded_sentence_masks = pad_sequence([torch.tensor(instance['sentence_mask']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_sentence_masks = padded_sentence_masks.to(device)\n",
    "            \n",
    "            padded_q_ids = pad_sequence([torch.tensor(instance['q_ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_q_ids = padded_q_ids.to(device)\n",
    "            \n",
    "            padded_q_mask_ids = pad_sequence([torch.tensor(instance['q_mask_ids']) for instance in dictionary_lists], batch_first=True)\n",
    "            padded_q_mask_ids = padded_q_mask_ids.to(device)\n",
    "\n",
    "            labels = torch.stack([torch.tensor(instance['labels']) for instance in dictionary_lists])\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            \n",
    "            current_dev_batch = {'ids': padded_ids, 'mask_ids': padded_mask_ids, 'sentence_mask': padded_sentence_masks,\n",
    "                                 'labels': labels, 'q_ids': padded_q_ids, \"q_mask_ids\": padded_q_mask_ids}\n",
    "\n",
    "            batches.append(current_dev_batch)\n",
    "            dictionary_lists = []\n",
    "\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_instances, dev_ids, dev_seg_ids, dev_mask_ids, dev_labels = datapreprocessing(validation_data)\n",
    "train_instances, train_ids, train_seg_ids, train_mask_ids, train_labels = datapreprocessing(training_data)\n",
    "test_instances, test_ids, test_seg_ids, test_mask_ids, test_labels = datapreprocessing(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0811 02:29:23.051539 139897081689920 tokenization_utils.py:375] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /root/.cache/torch/transformers/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00\n"
     ]
    }
   ],
   "source": [
    "qs_instances, qs_ids, qs_mask_ids, qs_sen_mask, qs_labels = data_to_sentence(training_data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0811 02:29:56.492766 139897081689920 tokenization_utils.py:375] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /root/.cache/torch/transformers/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00\n"
     ]
    }
   ],
   "source": [
    "dev_qs_instances, dev_qs_ids, dev_qs_mask_ids, dev_qs_sen_mask, dev_qs_labels = data_to_sentence(validation_data, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, ids, segment_ids, mask_ids, labels):\n",
    "        self.instances = []\n",
    "        for ids_i, segment_ids_i, mask_ids, label in zip(ids, segment_ids, mask_ids, labels):\n",
    "            self.instances.append({\"ids\": ids_i, \"segment_ids\": segment_ids_i, \n",
    "                                   \"mask_ids\": mask_ids, \"labels\": label})  \n",
    "                                   \n",
    "    def __len__(self):\n",
    "        return len(self.instances)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.instances[idx]\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionSentenceDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, ids, mask_ids, sen_masks, labels):\n",
    "        self.instances = []\n",
    "        for ids_i, mask_ids, sen_mask, label in zip(ids, mask_ids, sen_masks, labels):\n",
    "            self.instances.append({\"ids\": torch.tensor(ids_i[1]), \"mask_ids\": torch.tensor(mask_ids[1]), \n",
    "                                   \"sentence_mask\": torch.tensor(sen_mask), \"labels\": torch.tensor(label), \n",
    "                                   \"q_ids\": torch.tensor(ids_i[0]), \"q_mask_ids\": torch.tensor(mask_ids[0])})\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.instances)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.instances[idx]\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SentenceDataset(train_ids, train_seg_ids, train_mask_ids, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset = SentenceDataset(dev_ids, dev_seg_ids, dev_mask_ids, dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SentenceDataset(test_ids, test_seg_ids, test_mask_ids, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_train_dataset = QuestionSentenceDataset(qs_ids, qs_mask_ids, qs_sen_mask, qs_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_dev_dataset = QuestionSentenceDataset(dev_qs_ids, dev_qs_mask_ids, dev_qs_sen_mask, dev_qs_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31422"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    padded_ids = pad_sequence([torch.tensor(instance['ids']) for instance in batch], batch_first=True)\n",
    "    padded_ids = padded_ids.to(device)\n",
    "    \n",
    "    padded_segment_ids = pad_sequence([torch.tensor(instance['segment_ids']) for instance in batch], batch_first=True)\n",
    "    padded_segment_ids = padded_segment_ids.to(device)\n",
    "    \n",
    "    padded_mask_ids = pad_sequence([torch.tensor(instance['mask_ids']) for instance in batch], batch_first=True)\n",
    "    padded_mask_ids = padded_mask_ids.to(device)\n",
    "    \n",
    "    labels = torch.stack([torch.tensor(instance['labels']) for instance in batch])\n",
    "    labels = labels.to(device)\n",
    "    return {'ids': padded_ids, 'mask_ids': padded_mask_ids, 'segment_ids': padded_segment_ids, 'labels': labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_3d(batch):\n",
    "    \n",
    "    batch_size = len(batch)\n",
    "    \n",
    "    max_num_sentences, max_sentence_length = find_max_dimension(batch)\n",
    "    \n",
    "    # sentence weight\n",
    "    sentence_mask = torch.zeros(batch_size, max_num_sentences)\n",
    "    \n",
    "    \n",
    "    target_ids = torch.zeros(batch_size, max_num_sentences, max_sentence_length)\n",
    "    target_segment_ids = torch.zeros(batch_size, max_num_sentences, max_sentence_length)\n",
    "    target_mask_ids = torch.zeros(batch_size, max_num_sentences, max_sentence_length)\n",
    "    target_labels = torch.zeros(batch_size, max_num_sentences, 1)\n",
    "    for i in range(len(batch)):\n",
    "        \n",
    "        source_id_dimension = batch[i]['ids'].shape\n",
    "        \n",
    "        sentence_mask[i, :source_id_dimension[0]] = 1\n",
    "        \n",
    "        target_ids[i, :source_id_dimension[0], :source_id_dimension[1]] = batch[i]['ids']\n",
    "        \n",
    "        source_segment_id_dimension = batch[i]['segment_ids'].shape\n",
    "        target_segment_ids[i, :source_segment_id_dimension[0], :source_segment_id_dimension[1]] = batch[i]['segment_ids']\n",
    "        \n",
    "        source_mask_id_dimension = batch[i]['mask_ids'].shape\n",
    "        target_mask_ids[i, :source_mask_id_dimension[0], :source_mask_id_dimension[1]] = batch[i]['mask_ids']\n",
    "        \n",
    "        source_label_dimension = batch[i]['labels'].shape\n",
    "        target_labels[i, :source_label_dimension[0], :source_label_dimension[1]] = batch[i]['labels']\n",
    "    \n",
    "    target_labels = target_labels.squeeze(-1)\n",
    "    \n",
    "    target_ids = target_ids.to(device).to(torch.long)\n",
    "    target_segment_ids = target_segment_ids.to(device).to(torch.long)\n",
    "    target_mask_ids = target_segment_ids.to(device).to(torch.long)\n",
    "    target_labels = target_labels.to(dtype=torch.float, device=device)\n",
    "    sentence_mask = sentence_mask.to(device).to(torch.float)\n",
    "    return {'ids': target_ids, 'mask_ids': target_mask_ids, 'segment_ids': target_segment_ids, 'labels': target_labels, 'sentence_mask': sentence_mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_2d(batch):\n",
    "    \n",
    "    batch_size = len(batch)\n",
    "    \n",
    "    max_num_sentences, max_sentence_length = find_max_dimension(batch)\n",
    "    \n",
    "    # sentence weight\n",
    "    #sentence_mask = torch.zeros(batch_size, max_num_sentences)\n",
    "    \n",
    "    \n",
    "    target_ids = torch.zeros(max_num_sentences, max_sentence_length)\n",
    "    target_segment_ids = torch.zeros(max_num_sentences, max_sentence_length)\n",
    "    target_mask_ids = torch.zeros(max_num_sentences, max_sentence_length)\n",
    "    target_labels = torch.zeros(max_num_sentences, 1)\n",
    "    for i in range(len(batch)):\n",
    "        \n",
    "        source_id_dimension = batch[i]['ids'].shape\n",
    "        \n",
    "        #sentence_mask[:source_id_dimension[0]] = 1\n",
    "        \n",
    "        target_ids[:source_id_dimension[0], :source_id_dimension[1]] = batch[i]['ids']\n",
    "        \n",
    "        source_segment_id_dimension = batch[i]['segment_ids'].shape\n",
    "        target_segment_ids[:source_segment_id_dimension[0], :source_segment_id_dimension[1]] = batch[i]['segment_ids']\n",
    "        \n",
    "        source_mask_id_dimension = batch[i]['mask_ids'].shape\n",
    "        target_mask_ids[:source_mask_id_dimension[0], :source_mask_id_dimension[1]] = batch[i]['mask_ids']\n",
    "        \n",
    "        source_label_dimension = batch[i]['labels'].shape\n",
    "        target_labels[:source_label_dimension[0], :source_label_dimension[1]] = batch[i]['labels']\n",
    "\n",
    "    #target_labels = target_labels.squeeze(-1)\n",
    "    \n",
    "    target_ids = target_ids.to(device).to(torch.long)\n",
    "    target_segment_ids = target_segment_ids.to(device).to(torch.long)\n",
    "    target_mask_ids = target_segment_ids.to(device).to(torch.long)\n",
    "    target_labels = target_labels.to(dtype=torch.float, device=device)\n",
    "    #sentence_mask = sentence_mask.to(device).to(torch.float)\n",
    "    return {'ids': target_ids, 'mask_ids': target_mask_ids, 'segment_ids': target_segment_ids, 'labels': target_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_dimension(batch):\n",
    "    num_sentences = []\n",
    "    sentence_lengths = []\n",
    "    for question in batch:\n",
    "        num_sentences.append(question['ids'].shape[0])\n",
    "        sentence_lengths.append(question['ids'].shape[1])\n",
    "    return max(num_sentences), max(sentence_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_train_batches = window_sentence_preprocessing(training_data, train_dataset, 10)\n",
    "#new_train_2d_batches = window_sentence_preprocessing(training_data, train_dataset, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_train_batches[4]['ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(train_dataset, batch_size=4, shuffle = True, collate_fn = collate)\n",
    "#dataloader_train_3d = DataLoader(new_train_batches, batch_size=2, shuffle = True, collate_fn = collate_3d)\n",
    "#dataloader_train_2d = DataLoader(new_train_2d_batches, batch_size=8, shuffle = True, collate_fn = collate_2d)\n",
    "#dataloader_sent_train = DataLoader(sent_train_dataset, batch_size = 4, shuffle = True)\n",
    "#dataloader_sent_train_eval = DataLoader(sent_train_dataset, batch_size = 1)\n",
    "#dataloader_sent_dev = DataLoader(sent_dev_dataset, batch_size = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentence_lengths = []\n",
    "dev_sentence_lengths = []\n",
    "test_sentence_lengths = []\n",
    "\n",
    "for instance_dict in train_dataset.instances:\n",
    "    train_sentence_lengths.append(len(instance_dict['ids']))\n",
    "    \n",
    "for instance_dict in dev_dataset.instances:\n",
    "    dev_sentence_lengths.append(len(instance_dict['ids']))\n",
    "    \n",
    "for instance_dict in test_dataset.instances:\n",
    "    test_sentence_lengths.append(len(instance_dict['ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data >512 percentage: 0.0\n",
      "dev data >512 percentage: 0.0\n",
      "test data >512 percentage: 0.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(train_sentence_lengths, bins=100)\n",
    "plt.hist(dev_sentence_lengths, bins=100)\n",
    "plt.hist(test_sentence_lengths, bins=100)\n",
    "print('train data >512 percentage:', (np.array(train_sentence_lengths) > 512).sum() / len(train_sentence_lengths))\n",
    "print('dev data >512 percentage:', (np.array(dev_sentence_lengths) > 512).sum() / len(dev_sentence_lengths))\n",
    "print('test data >512 percentage:', (np.array(test_sentence_lengths) > 512).sum() / len(test_sentence_lengths))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class baseline_model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(baseline_model, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-chinese')\n",
    "        self.linear = nn.Linear(768, 1)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        # batch['ids'] = (batch_size, sent_len)\n",
    "        # batch['segment_ids'] = (batch_size, sent_len)\n",
    "        # batch['mask_ids'] = (batch_size, sent_len)\n",
    "        # pooler_output = (batch_size, 768)\n",
    "        # output = (batch_size, 1)\n",
    "        hidden_state, pooler_output = self.bert(batch['ids'], batch['mask_ids'], batch['segment_ids'])\n",
    "        \n",
    "        linear_output = self.linear(pooler_output)\n",
    "\n",
    "        return linear_output\n",
    "\n",
    "    def loss(self, batch):\n",
    "        \n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "        output = self.forward(batch)\n",
    "        target = batch['labels'].float().to(device)\n",
    "        \n",
    "        return loss_fn(output, target)\n",
    "    \n",
    "    def _predict(self, batch):\n",
    "        \n",
    "        output = self.forward(batch)\n",
    "        scores = torch.sigmoid(output)\n",
    "        scores = scores.cpu().numpy()[:,0].tolist()\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    def predict_fgc(self, batch, threshold=0.5):\n",
    "        \n",
    "        scores = self._predict(batch)\n",
    "        max_i = 0\n",
    "        max_score = 0\n",
    "        sp = []\n",
    "        \n",
    "        for i, score in enumerate(scores):\n",
    "\n",
    "            if score > max_score:\n",
    "                max_i = i\n",
    "                max_score = score\n",
    "            if score >= threshold:\n",
    "                sp.append(i)\n",
    "\n",
    "        if not sp:\n",
    "            sp.append(max_i)\n",
    "\n",
    "        return {'sp': sp, 'sp_scores': scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0812 02:16:03.949645 139797494843200 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json from cache at /root/.cache/torch/transformers/8a3b1cfe5da58286e12a0f5d7d182b8d6eca88c08e26c332ee3817548cf7e60a.f12a4f986e43d8b328f5b067a641064d67b91597567a06c7b122d1ca7dfd9741\n",
      "I0812 02:16:03.951986 139797494843200 configuration_utils.py:300] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "I0812 02:16:04.254365 139797494843200 modeling_utils.py:666] loading weights file https://cdn.huggingface.co/bert-base-chinese-pytorch_model.bin from cache at /root/.cache/torch/transformers/a75f2e45a9463e784dfe8c1d9672440d5fc1b091d5ab104e3c2d82e90ab1b222.929717ca66a3ba9eb9ec2f85973c6398c54c38a4faa464636a491d7a705f7eb6\n",
      "I0812 02:16:07.470762 139797494843200 modeling_utils.py:764] All model checkpoint weights were used when initializing BertModel.\n",
      "\n",
      "I0812 02:16:07.472046 139797494843200 modeling_utils.py:773] All the weights of BertModel were initialized from the model checkpoint at bert-base-chinese.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "baseline_model(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline = baseline_model()\n",
    "baseline.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Baseline Model & Evaluating Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optim(nn, num_epochs, lr):\n",
    "    param_optimizer = list(nn.bert.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "    num_epochs = num_epochs\n",
    "    num_train_optimization_steps = len(dataloader_train) * num_epochs\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=lr)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                     num_warmup_steps=int(\n",
    "                                                         num_train_optimization_steps * 0.1),\n",
    "                                                     num_training_steps=num_train_optimization_steps)\n",
    "    return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _update_sp(metrics, sp_gold, sp_pred):\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "        \n",
    "    for p in sp_pred:\n",
    "        if p in sp_gold:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "    for g in sp_gold:\n",
    "        if g not in sp_pred:\n",
    "            fn += 1\n",
    "            \n",
    "    precision = 1.0 * tp / (tp + fp) if tp + fp > 0 else 0.0\n",
    "    recall = 1.0 * tp / (tp + fn) if tp + fn > 0 else 0.0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0.0\n",
    "    em = 1.0 if fp + fn == 0 else 0.0\n",
    "    \n",
    "    metrics['sp_em'] += em\n",
    "    metrics['sp_f1'] += f1\n",
    "    metrics['sp_prec'] += precision\n",
    "    metrics['sp_recall'] += recall\n",
    "    \n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_sp_fgc(sp_golds, sp_preds):\n",
    "    \n",
    "    metrics = {'sp_em': 0, 'sp_prec': 0, 'sp_recall': 0, 'sp_f1': 0}\n",
    "    \n",
    "    assert len(sp_golds) == len(sp_preds)\n",
    "    \n",
    "    for sp_gold, sp_pred in zip(sp_golds, sp_preds):\n",
    "        _update_sp(metrics, sp_gold, sp_pred)\n",
    "    \n",
    "    N = len(sp_golds)\n",
    "    for k in metrics.keys():\n",
    "        metrics[k] /= N\n",
    "        metrics[k] = round(metrics[k], 3)\n",
    "    print(metrics)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fgc_atype(atype_golds, atype_preds):\n",
    "    \n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    \n",
    "    for gold, atype in zip(atype_golds, atype_preds):\n",
    "        if atype == gold:\n",
    "            pos += 1\n",
    "        else:\n",
    "            neg += 1\n",
    "    return pos/len(atypes_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(network, dev_batches, current_epoch, sp_golds, avg_loss):\n",
    "    \n",
    "    network.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        sp_preds = []\n",
    "        for batch in tqdm(dev_batches):\n",
    "            \n",
    "            out_dct = network.predict_fgc(batch)\n",
    "            sp_preds.append(out_dct['sp'])\n",
    "                \n",
    "    metrics = eval_sp_fgc(sp_golds, sp_preds)\n",
    "    print('epoch %d eval_recall: %.3f eval_f1: %.3f loss: %.3f' % (\n",
    "            current_epoch, metrics['sp_recall'], metrics['sp_f1'], avg_loss))\n",
    "        \n",
    "    torch.save(network.state_dict(), \"Models_SEs/model_epoch{0}_eval_em:{1:.3f}_precision:{2:.3f}_recall:{3:.3f}_f1:{4:.3f}_loss:{5:.3f}.m\".format(current_epoch, metrics['sp_em'], metrics['sp_prec'], metrics['sp_recall'], metrics['sp_f1'], avg_loss))\n",
    "    \n",
    "    return sp_preds, sp_golds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(network, data, dev_batches, num_epochs, lr):\n",
    "    \n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer, scheduler = optim(network, num_epochs, lr)\n",
    "    \n",
    "    sp_golds = validation_data['QUESTIONS'].apply(lambda x: x[0]['SHINT_']).tolist()\n",
    "    \n",
    "    for current_epoch in range(num_epochs):\n",
    "        network.train()\n",
    "        running_loss = 0.0\n",
    "        for batch in tqdm(data):\n",
    "            optimizer.zero_grad()\n",
    "            current_output = network(batch)\n",
    "            current_target = batch['labels'].to(dtype=torch.float, device=device)\n",
    "            current_loss = loss_fn(current_output, current_target)\n",
    "            current_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(network.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            running_loss += current_loss.item()\n",
    "            \n",
    "        learning_rate_scalar = scheduler.get_lr()[0]\n",
    "        print('lr = %f' % learning_rate_scalar)\n",
    "        avg_loss = running_loss/len(data)\n",
    "        print('epoch %d train_loss: %.3f' % (current_epoch, avg_loss))\n",
    "        eval(network, dev_batches, current_epoch, sp_golds, avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_batches = eval_preprocessing(validation_data, dev_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "807b0fd485bf4bd9b373b96b9dca74c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000010\n",
      "epoch 0 train_loss: 0.246\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d36bc20684aa40e3b696ff12b9d42b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.18, 'sp_prec': 0.732, 'sp_recall': 0.454, 'sp_f1': 0.528}\n",
      "epoch 0 eval_recall: 0.454 eval_f1: 0.528 loss: 0.246\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32bb8eef079d4854802ef872256a43a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000020\n",
      "epoch 1 train_loss: 0.202\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80eebe9da58e406390b71596bdd0e935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.146, 'sp_prec': 0.593, 'sp_recall': 0.551, 'sp_f1': 0.523}\n",
      "epoch 1 eval_recall: 0.551 eval_f1: 0.523 loss: 0.202\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e1cfac3ff6465f84d9a2531ef423d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000019\n",
      "epoch 2 train_loss: 0.174\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b661cf89858408995e2e06056b87a17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.163, 'sp_prec': 0.648, 'sp_recall': 0.562, 'sp_f1': 0.546}\n",
      "epoch 2 eval_recall: 0.562 eval_f1: 0.546 loss: 0.174\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab4932062704c64b301edf417e2d837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000018\n",
      "epoch 3 train_loss: 0.145\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "193d73cf384744f4bf754a2130682e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.113, 'sp_prec': 0.533, 'sp_recall': 0.689, 'sp_f1': 0.538}\n",
      "epoch 3 eval_recall: 0.689 eval_f1: 0.538 loss: 0.145\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "746fd88323d54a74b932803ffb4b363f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000017\n",
      "epoch 4 train_loss: 0.115\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bec13191beb4a5e9b50cdca7cb7bcd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.134, 'sp_prec': 0.605, 'sp_recall': 0.551, 'sp_f1': 0.518}\n",
      "epoch 4 eval_recall: 0.551 eval_f1: 0.518 loss: 0.115\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58409232b48f4920970db6dbc5379628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000016\n",
      "epoch 5 train_loss: 0.101\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6d7b973c4894735a596f6e50fb17a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.126, 'sp_prec': 0.567, 'sp_recall': 0.637, 'sp_f1': 0.537}\n",
      "epoch 5 eval_recall: 0.637 eval_f1: 0.537 loss: 0.101\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f71d5cd9753041deb9b76ccf3a56f92e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000014\n",
      "epoch 6 train_loss: 0.078\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a521d98097ef46f8ba2d5aef61ed4078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.146, 'sp_prec': 0.593, 'sp_recall': 0.605, 'sp_f1': 0.541}\n",
      "epoch 6 eval_recall: 0.605 eval_f1: 0.541 loss: 0.078\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dec14f8281d49d6bb9e2577a88fc7ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000013\n",
      "epoch 7 train_loss: 0.065\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "282fc290454942d9bce148b475d8a307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.159, 'sp_prec': 0.619, 'sp_recall': 0.564, 'sp_f1': 0.54}\n",
      "epoch 7 eval_recall: 0.564 eval_f1: 0.540 loss: 0.065\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a25e79db67b4b12bd5df54477c2d1e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000012\n",
      "epoch 8 train_loss: 0.051\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "540bd1ea56b34fb2aeaee2afb05c38a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.155, 'sp_prec': 0.612, 'sp_recall': 0.562, 'sp_f1': 0.535}\n",
      "epoch 8 eval_recall: 0.562 eval_f1: 0.535 loss: 0.051\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd1a48faa654f05ad0e8049be53d543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000011\n",
      "epoch 9 train_loss: 0.046\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "864c606f38c944deb1ff7d7dba5b2881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.155, 'sp_prec': 0.604, 'sp_recall': 0.534, 'sp_f1': 0.511}\n",
      "epoch 9 eval_recall: 0.534 eval_f1: 0.511 loss: 0.046\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e67e9b28888d42d1be7a5e40d17ae2a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000010\n",
      "epoch 10 train_loss: 0.035\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50ece5481c7f401b8d242de38b2dd750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.138, 'sp_prec': 0.577, 'sp_recall': 0.646, 'sp_f1': 0.548}\n",
      "epoch 10 eval_recall: 0.646 eval_f1: 0.548 loss: 0.035\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c35517768b343d6b84ba29760bb78bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000009\n",
      "epoch 11 train_loss: 0.029\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "800df5b00254430089917bb12a269046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.172, 'sp_prec': 0.596, 'sp_recall': 0.556, 'sp_f1': 0.529}\n",
      "epoch 11 eval_recall: 0.556 eval_f1: 0.529 loss: 0.029\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee8582c5455c49f1815b38139f8d0d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000008\n",
      "epoch 12 train_loss: 0.026\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f04b670fece9444ba9bfae429a7ec798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.121, 'sp_prec': 0.552, 'sp_recall': 0.589, 'sp_f1': 0.515}\n",
      "epoch 12 eval_recall: 0.589 eval_f1: 0.515 loss: 0.026\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "191b677709a544f09cca707f37102520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000007\n",
      "epoch 13 train_loss: 0.022\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3831f991cea4c7f835722a7a3164b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.138, 'sp_prec': 0.576, 'sp_recall': 0.537, 'sp_f1': 0.505}\n",
      "epoch 13 eval_recall: 0.537 eval_f1: 0.505 loss: 0.022\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a22f4b95db0747febd036c0976e33e0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000006\n",
      "epoch 14 train_loss: 0.021\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae677d0cea4340a7b23bcfe78604c330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.167, 'sp_prec': 0.588, 'sp_recall': 0.557, 'sp_f1': 0.519}\n",
      "epoch 14 eval_recall: 0.557 eval_f1: 0.519 loss: 0.021\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cd33c43ed1543cb92f6136272d369bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000004\n",
      "epoch 15 train_loss: 0.015\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0332ad030f6486095231842780a670e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.167, 'sp_prec': 0.606, 'sp_recall': 0.578, 'sp_f1': 0.538}\n",
      "epoch 15 eval_recall: 0.578 eval_f1: 0.538 loss: 0.015\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cedff151aff4b828094bd5bdba88962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000003\n",
      "epoch 16 train_loss: 0.010\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f744c6eccaf46c38aaa75f32875215b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.167, 'sp_prec': 0.592, 'sp_recall': 0.604, 'sp_f1': 0.54}\n",
      "epoch 16 eval_recall: 0.604 eval_f1: 0.540 loss: 0.010\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a189524548243d6b76efba0a7693c7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000002\n",
      "epoch 17 train_loss: 0.006\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90666bd6e8b94bb6a251cc78e8a9923f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.163, 'sp_prec': 0.602, 'sp_recall': 0.587, 'sp_f1': 0.54}\n",
      "epoch 17 eval_recall: 0.587 eval_f1: 0.540 loss: 0.006\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2be18849b3d840be8167ef983a95ca21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000001\n",
      "epoch 18 train_loss: 0.003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54fea467db704163971b61d0b180de44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.138, 'sp_prec': 0.589, 'sp_recall': 0.61, 'sp_f1': 0.542}\n",
      "epoch 18 eval_recall: 0.610 eval_f1: 0.542 loss: 0.003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "837983e0646f4314bf319ee8061b0d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7767), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000000\n",
      "epoch 19 train_loss: 0.004\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb87fac7452b4fc5b3044ff86c9e34e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.142, 'sp_prec': 0.597, 'sp_recall': 0.608, 'sp_f1': 0.543}\n",
      "epoch 19 eval_recall: 0.608 eval_f1: 0.543 loss: 0.004\n"
     ]
    }
   ],
   "source": [
    "train(baseline, dataloader_train, dev_batches, 20, 0.00002) # if you want to run this again, rememebr to add the parameter 'batches'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0724 08:26:42.599873 140341672732480 configuration_utils.py:152] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json from cache at /root/.cache/torch/transformers/8a3b1cfe5da58286e12a0f5d7d182b8d6eca88c08e26c332ee3817548cf7e60a.f12a4f986e43d8b328f5b067a641064d67b91597567a06c7b122d1ca7dfd9741\n",
      "I0724 08:26:42.603232 140341672732480 configuration_utils.py:169] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "I0724 08:26:43.473549 140341672732480 modeling_utils.py:387] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-pytorch_model.bin from cache at /root/.cache/torch/transformers/b1b5e295889f2d0979ede9a78ad9cb5dc6a0e25ab7f9417b315f0a2c22f4683d.929717ca66a3ba9eb9ec2f85973c6398c54c38a4faa464636a491d7a705f7eb6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_baseline = baseline_model()\n",
    "trained_baseline.load_state_dict(torch.load(\"Models/baseline_models_with_scheduler/model_epoch8_eval_em:0.198_precision:0.603_recall:0.588_f1:0.545_loss:0.031.m\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dd358afcf454dbca8cc9ebb869256ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=882), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.895, 'sp_prec': 0.97, 'sp_recall': 0.955, 'sp_f1': 0.958}\n",
      "epoch 0 eval_recall: 0.955 eval_f1: 0.958 loss: 0.001\n"
     ]
    }
   ],
   "source": [
    "sp_golds = training_data['QUESTIONS'].apply(lambda x: x[0]['SHINT_']).tolist()\n",
    "batches = eval_preprocessing(training_data, train_dataset)\n",
    "\n",
    "trained_network.to(\"cuda\")\n",
    "train_pred, train_obs = eval(trained_network, batches, 0, sp_golds, 0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14706ff3ce654779a0bf43f754162b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=247), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.194, 'sp_prec': 0.599, 'sp_recall': 0.584, 'sp_f1': 0.541}\n",
      "epoch 0 eval_recall: 0.584 eval_f1: 0.541 loss: 0.001\n"
     ]
    }
   ],
   "source": [
    "sp_golds = validation_data['QUESTIONS'].apply(lambda x: x[0]['SHINT_']).tolist()\n",
    "dev_batches = eval_preprocessing(validation_data, dev_dataset)\n",
    "dev_preds, dev_obs = eval(trained_network, dev_batches, 0, sp_golds, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d31d52a9c5467fbd6374a5c131ccc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=193), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.212, 'sp_prec': 0.643, 'sp_recall': 0.553, 'sp_f1': 0.55}\n",
      "epoch 0 eval_recall: 0.553 eval_f1: 0.550 loss: 0.001\n"
     ]
    }
   ],
   "source": [
    "sp_golds = test_data['QUESTIONS'].apply(lambda x: x[0]['SHINT_']).tolist()\n",
    "test_batches = eval_preprocessing(test_data, test_dataset)\n",
    "test_preds, test_obds = eval(trained_network, test_batches, 0, sp_golds, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data_with_performance = datapreprocessing(validation_data, True)\n",
    "training_data_with_performance = datapreprocessing(training_data, True)\n",
    "test_data_with_performance = datapreprocessing(test_data, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_with_performance['train_pred'] = train_pred\n",
    "training_data_with_performance['train_obs'] = train_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_sp = []\n",
    "for i in range(training_data_with_performance.shape[0]):\n",
    "    para = training_data_with_performance['Sentence_List'][i]\n",
    "    sen = []\n",
    "    for index in training_data_with_performance['train_pred'][i]:\n",
    "        sen.append(para[index])\n",
    "    correct_sp.append(sen)\n",
    "training_data_with_performance['Pred_List'] = correct_sp\n",
    "correct_sp = []\n",
    "for i in range(training_data_with_performance.shape[0]):\n",
    "    para = training_data_with_performance['Sentence_List'][i]\n",
    "    sen = []\n",
    "    for index in training_data_with_performance['train_obs'][i]:\n",
    "        sen.append(para[index])\n",
    "    correct_sp.append(sen)\n",
    "training_data_with_performance['Obs_List'] = correct_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_with_performance.drop(['SE_Index', 'Label', 'train_pred', 'train_obs'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Sentence_List</th>\n",
       "      <th>Length</th>\n",
       "      <th>Pred_List</th>\n",
       "      <th>Obs_List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>苏东坡出生于哪一年?</td>\n",
       "      <td>[嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...</td>\n",
       "      <td>35</td>\n",
       "      <td>[苏轼才20岁，]</td>\n",
       "      <td>[嘉佑二年（1057年），, 苏轼才20岁，]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>苏东坡和谁一起进京参加会考?</td>\n",
       "      <td>[嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...</td>\n",
       "      <td>35</td>\n",
       "      <td>[与弟弟苏辙一同进京参加会考，]</td>\n",
       "      <td>[苏轼才20岁，, 与弟弟苏辙一同进京参加会考，]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>在苏东坡被王安石诬陷时，谁为他说话？</td>\n",
       "      <td>[嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...</td>\n",
       "      <td>35</td>\n",
       "      <td>[范镇极辩苏轼贩盐之诬，]</td>\n",
       "      <td>[范镇极辩苏轼贩盐之诬，, 并愿意退休负责。]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>苏东坡哪一年离开海南岛?</td>\n",
       "      <td>[元祐元年（1086年），, 宋哲宗即位，, 高太皇太后垂帘听政，, 回朝任礼部郎中、中书舍...</td>\n",
       "      <td>32</td>\n",
       "      <td>[\\n绍圣元年（1094年）被哲宗贬谪至惠州、儋州（海南岛）。, 下诏让苏轼北还。]</td>\n",
       "      <td>[\\n绍圣元年（1094年）被哲宗贬谪至惠州、儋州（海南岛）。, \\n元符三年（1100年）...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>苏东坡死于哪一年?</td>\n",
       "      <td>[元祐元年（1086年），, 宋哲宗即位，, 高太皇太后垂帘听政，, 回朝任礼部郎中、中书舍...</td>\n",
       "      <td>32</td>\n",
       "      <td>[七月二十八日于常州孙氏馆病卒，]</td>\n",
       "      <td>[\\n建中靖国元年（1101年），, 七月二十八日于常州孙氏馆病卒，]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>829</td>\n",
       "      <td>青河大学时代在哪一所学校念书?</td>\n",
       "      <td>[为倾听新住民心声，, 内政部移民署今(18)日下午，, 在台南市举办新住民座谈会，, 有2...</td>\n",
       "      <td>56</td>\n",
       "      <td>[青河毕业于越南河内国家大学法文系，, 青河得以持续进修，]</td>\n",
       "      <td>[青河毕业于越南河内国家大学法文系，, 青河得以持续进修，, 她不仅取得国立成功大学硕士学位，]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>831</td>\n",
       "      <td>青河的硕士学位在哪一个国家念的?</td>\n",
       "      <td>[为倾听新住民心声，, 内政部移民署今(18)日下午，, 在台南市举办新住民座谈会，, 有2...</td>\n",
       "      <td>56</td>\n",
       "      <td>[青河毕业于越南河内国家大学法文系，, 青河得以持续进修，]</td>\n",
       "      <td>[青河毕业于越南河内国家大学法文系，, 青河得以持续进修，, 她不仅取得国立成功大学硕士学位，]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>867</td>\n",
       "      <td>如果我使用了日本买的眼药水却发生过敏红肿，是否可以申请药害救济?</td>\n",
       "      <td>[「目睭花花，匏仔看做菜瓜」，, 许多民众如果觉得眼睛雾雾时，, 常常会自行购买眼药水来缓解...</td>\n",
       "      <td>39</td>\n",
       "      <td>[透过网购或国外带回的眼药水，, 并不属于我国合法药物，, 并不适用我国药害救济制度喔!\\n...</td>\n",
       "      <td>[透过网购或国外带回的眼药水，, 并不适用我国药害救济制度喔!\\n\\n       食药署为...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>目前在台湾出现的肠病毒有哪几型?</td>\n",
       "      <td>[国内肠病毒轻症疫情持续上升，, 另新增1例肠病毒71型并发重症病例。, 疾病管制署再次呼吁...</td>\n",
       "      <td>42</td>\n",
       "      <td>[以感染肠病毒71型为多(28例)，, 其他分别感染肠病毒D68型、克沙奇A6型、A10型(...</td>\n",
       "      <td>[今(2019)年累计37例肠病毒并发重症病例，, 以感染肠病毒71型为多(28例)，, 其...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>874</td>\n",
       "      <td>要如何降低肠病毒的传播风险？</td>\n",
       "      <td>[国内肠病毒轻症疫情持续上升，, 另新增1例肠病毒71型并发重症病例。, 疾病管制署再次呼吁...</td>\n",
       "      <td>42</td>\n",
       "      <td>[疾病管制署再次呼吁，]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Question  \\\n",
       "1                          苏东坡出生于哪一年?   \n",
       "2                      苏东坡和谁一起进京参加会考?   \n",
       "8                  在苏东坡被王安石诬陷时，谁为他说话？   \n",
       "12                       苏东坡哪一年离开海南岛?   \n",
       "13                          苏东坡死于哪一年?   \n",
       "..                                ...   \n",
       "829                  青河大学时代在哪一所学校念书?    \n",
       "831                  青河的硕士学位在哪一个国家念的?   \n",
       "867  如果我使用了日本买的眼药水却发生过敏红肿，是否可以申请药害救济?   \n",
       "870                  目前在台湾出现的肠病毒有哪几型?   \n",
       "874                    要如何降低肠病毒的传播风险？   \n",
       "\n",
       "                                         Sentence_List  Length  \\\n",
       "1    [嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...      35   \n",
       "2    [嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...      35   \n",
       "8    [嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...      35   \n",
       "12   [元祐元年（1086年），, 宋哲宗即位，, 高太皇太后垂帘听政，, 回朝任礼部郎中、中书舍...      32   \n",
       "13   [元祐元年（1086年），, 宋哲宗即位，, 高太皇太后垂帘听政，, 回朝任礼部郎中、中书舍...      32   \n",
       "..                                                 ...     ...   \n",
       "829  [为倾听新住民心声，, 内政部移民署今(18)日下午，, 在台南市举办新住民座谈会，, 有2...      56   \n",
       "831  [为倾听新住民心声，, 内政部移民署今(18)日下午，, 在台南市举办新住民座谈会，, 有2...      56   \n",
       "867  [「目睭花花，匏仔看做菜瓜」，, 许多民众如果觉得眼睛雾雾时，, 常常会自行购买眼药水来缓解...      39   \n",
       "870  [国内肠病毒轻症疫情持续上升，, 另新增1例肠病毒71型并发重症病例。, 疾病管制署再次呼吁...      42   \n",
       "874  [国内肠病毒轻症疫情持续上升，, 另新增1例肠病毒71型并发重症病例。, 疾病管制署再次呼吁...      42   \n",
       "\n",
       "                                             Pred_List  \\\n",
       "1                                            [苏轼才20岁，]   \n",
       "2                                     [与弟弟苏辙一同进京参加会考，]   \n",
       "8                                        [范镇极辩苏轼贩盐之诬，]   \n",
       "12          [\\n绍圣元年（1094年）被哲宗贬谪至惠州、儋州（海南岛）。, 下诏让苏轼北还。]   \n",
       "13                                   [七月二十八日于常州孙氏馆病卒，]   \n",
       "..                                                 ...   \n",
       "829                     [青河毕业于越南河内国家大学法文系，, 青河得以持续进修，]   \n",
       "831                     [青河毕业于越南河内国家大学法文系，, 青河得以持续进修，]   \n",
       "867  [透过网购或国外带回的眼药水，, 并不属于我国合法药物，, 并不适用我国药害救济制度喔!\\n...   \n",
       "870  [以感染肠病毒71型为多(28例)，, 其他分别感染肠病毒D68型、克沙奇A6型、A10型(...   \n",
       "874                                       [疾病管制署再次呼吁，]   \n",
       "\n",
       "                                              Obs_List  \n",
       "1                              [嘉佑二年（1057年），, 苏轼才20岁，]  \n",
       "2                            [苏轼才20岁，, 与弟弟苏辙一同进京参加会考，]  \n",
       "8                              [范镇极辩苏轼贩盐之诬，, 并愿意退休负责。]  \n",
       "12   [\\n绍圣元年（1094年）被哲宗贬谪至惠州、儋州（海南岛）。, \\n元符三年（1100年）...  \n",
       "13                 [\\n建中靖国元年（1101年），, 七月二十八日于常州孙氏馆病卒，]  \n",
       "..                                                 ...  \n",
       "829   [青河毕业于越南河内国家大学法文系，, 青河得以持续进修，, 她不仅取得国立成功大学硕士学位，]  \n",
       "831   [青河毕业于越南河内国家大学法文系，, 青河得以持续进修，, 她不仅取得国立成功大学硕士学位，]  \n",
       "867  [透过网购或国外带回的眼药水，, 并不适用我国药害救济制度喔!\\n\\n       食药署为...  \n",
       "870  [今(2019)年累计37例肠病毒并发重症病例，, 以感染肠病毒71型为多(28例)，, 其...  \n",
       "874                                                 []  \n",
       "\n",
       "[93 rows x 5 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mismatch = training_data_with_performance[training_data_with_performance['Pred_List'] != training_data_with_performance['Obs_List']]\n",
    "train_mismatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "#20 (Pred:[9], Actual:[])\n",
    "\n",
    "Question:「阿拉伯之春」运动中，走上街头的民众的诉求为何? <br>\n",
    "Predicted SP: 只有突尼西亚成为阿拉伯之春中，<br>\n",
    "Actual: None\n",
    "\n",
    "Comment: While the predicted SP is incorrect, I found out that there is supporting evidence in the paragraph. (...要求推翻本国的专制政体的行动)This might be a case of incorrect input.\n",
    "\n",
    "#70 (Pred:[11], Actual:[])\n",
    "\n",
    "Question: 第二次签订的北美贸易协定从签署至生效过了几日? <br>\n",
    "Predicted SP: 美国、墨西哥和加拿大就更新北美自由贸易协定达成一致，<br>\n",
    "Actual: None\n",
    "\n",
    "Comment: Same as #20. (美国、加拿大及墨西哥在1992年8月12日签署了关于三国间全面贸易的协议。...，北美自由贸易协议于1994年1月1日正式生效。)\n",
    "\n",
    "#156 (Pred:[1], Actual:[])\n",
    "\n",
    "Question: 聊天机器人仰赖哪些方法让回答愈来愈准确? <br>\n",
    "Predicted SP: 麻省理工学院（MIT）人工智慧实验室早在1966年即研发出名为「Eliza」的机器人， <br>\n",
    "Actual: None <br>\n",
    "\n",
    "Comment: Same (聊天机器人的作答准确度要透过程式化的方法改善)\n",
    "\n",
    "#284 (Pred:[3], Actual:[])\n",
    "\n",
    "Question: 不可再生能源的意义是什么？ <br>\n",
    "Predicted SP: 许多这些形式可以很容易转化为另一种的帮助下， <br>\n",
    "Actual: None <br>\n",
    "\n",
    "Comment: Same (是无法经过短时间内再生的能源，而且它们的消耗速度远远超过它们再生的速度)\n",
    "\n",
    "#324 (Pred:[4], Actual:[])\n",
    "\n",
    "Question: 伊甸基金會成立的宗旨為何? <br>\n",
    "Predicted SP: 因著上帝的呼召及一颗爱身心障碍者的同理心，<br>\n",
    "Actual: None <br>\n",
    "\n",
    "Comment: No SP in the paragraph. But I think SP is pretty close to being a supporting evidence. This \n",
    "must be a borderline case.\n",
    "\n",
    "#370 (Pred:[12,25], Actual:[25])\n",
    "\n",
    "Question: 三大健康照护体系保险制度中，政府涉入程度低的是哪一种？<br>\n",
    "Predicted SP: 公医制（政府介入最多）：以英国为代表。 AND 自由市场（政府一般不介入）：以2013年前的美国为代表。<br>\n",
    "Actual: 公医制（政府介入最多）：以英国为代表。<br>\n",
    "\n",
    "Comment: I think this is a very reasonable mismatch. As two supporting evidences are very similar\n",
    "syntax-wise but drastically different in meaning.\n",
    "\n",
    "#371 (Pred:[12,25], Actual:[12])\n",
    "\n",
    "Question: 三大健康照護體系保險制度中，政府涉入程度高的是哪一種？ <br>\n",
    "Predicted SP: 公医制（政府介入最多）：以英国为代表。 AND 自由市场（政府一般不介入）：以2013年前的美国为代表。<br>\n",
    "Actual: 公医制（政府介入最多）：以英国为代表。<br>\n",
    "\n",
    "Comment: Same as #370\n",
    "\n",
    "#395 (Pred:[10], Actual:[])\n",
    "\n",
    "Question: 熬夜是否能减低得到癌症的风险? <br>\n",
    "Predicted SP: 皆强烈建议减少或避免动物性食品摄取， <br>\n",
    "Actual: None <br>\n",
    "\n",
    "Comment: Another potential case of incorrect input. In the paragraph I found this sentence (所以防癌守则：...，注重睡眠品质)\n",
    "\n",
    "#449 (Pred:[2], Actual:[])\n",
    "\n",
    "Question: 高屏地区国庆烟火试放管制时间是从晚上几点开始？ <br>\n",
    "Predicted SP: 屏东县政府表示24号当天屏东河滨公园将管制不开放， <br>\n",
    "Actual: None <br>\n",
    "\n",
    "Comment: Another similar case. This time I strongly believe this is an incorrect input. \n",
    "当晚7时并会进行全面清场 <- This is sufficient to be a supporting evidence\n",
    "\n",
    "#502 (Pred:[7], Actual:[])\n",
    "\n",
    "Question: 为何圣伯多禄大殿只能重建不能整修就好? <br>\n",
    "Predicted SP: 教宗犹利二世决定重建圣伯多禄大殿 <br>\n",
    "Actual: None \n",
    "\n",
    "Comment: Another similar case. (无疑再改动有机会让建筑倒塌)\n",
    "\n",
    "#630 (Pred:[62], Actual:[])\n",
    "\n",
    "Question: 毛笔、铅笔、钢笔，这三种笔中哪个笔尖的硬度高？ <br>\n",
    "Predicted SP: 更进一步看：我们无论使用那一种笔，<br>\n",
    "Actual: None <br>\n",
    "\n",
    "Comment: Again, I think this counts as a supporting evidence (钢笔的笔尖用金属制成，弹性大，硬度高)\n",
    "\n",
    "#731 (Pred:[9], Actual:[])\n",
    "\n",
    "Question: 为什么古埃及人要把死人做成木乃伊? <br>\n",
    "Predicted SP: 是做什么用的呢？ <br>\n",
    "Actual: None <br>\n",
    "\n",
    "Comment: I think this counts (古埃及人相信：人死后只要把遗体保存好，就可以在另一个世界得到永生。)\n",
    "\n",
    "#874 (Pred:[22], Actual:[])\n",
    "\n",
    "Question: 要如何降低肠病毒的传播风险？\n",
    "Predicted SP: 今(2019)年累计37例肠病毒并发重症病例，\n",
    "Actual: None\n",
    "\n",
    "Comment: No doubt, these are supporting evidences (应加强居家环境、教室及游乐设施等的通风、整洁与消毒，并教导学童落实「湿、搓、冲、捧、擦」正确洗手步骤，及生病在家休息等良好卫生观念，)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Data Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data_with_performance['dev_pred'] = dev_preds\n",
    "validation_data_with_performance['dev_obs'] = dev_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_sp = []\n",
    "for i in range(validation_data_with_performance.shape[0]):\n",
    "    para = validation_data_with_performance['Sentence_List'][i]\n",
    "    sen = []\n",
    "    for index in validation_data_with_performance['dev_pred'][i]:\n",
    "        sen.append(para[index])\n",
    "    correct_sp.append(sen)\n",
    "validation_data_with_performance['Pred_List'] = correct_sp\n",
    "correct_sp = []\n",
    "for i in range(validation_data_with_performance.shape[0]):\n",
    "    para = validation_data_with_performance['Sentence_List'][i]\n",
    "    sen = []\n",
    "    for index in validation_data_with_performance['dev_obs'][i]:\n",
    "        sen.append(para[index])\n",
    "    correct_sp.append(sen)\n",
    "validation_data_with_performance['Obs_List'] = correct_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data_with_performance.drop(['SE_Index', 'Label'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data_with_performance.drop(['Sentence_List', 'dev_pred', 'dev_obs'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_mismatch = validation_data_with_performance[validation_data_with_performance['Obs_List'] != validation_data_with_performance['Pred_List']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Length</th>\n",
       "      <th>Pred_List</th>\n",
       "      <th>Obs_List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>苏东坡在中国历史上，是哪一个朝代的人？</td>\n",
       "      <td>36</td>\n",
       "      <td>[苏轼（1037年1月8日－1101年8月24日），]</td>\n",
       "      <td>[苏轼（1037年1月8日－1101年8月24日），, 北宋时著名的文学家、政治家、艺术家、...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>苏东坡是中国哪个省份的人？</td>\n",
       "      <td>36</td>\n",
       "      <td>[苏轼（1037年1月8日－1101年8月24日），, 眉州眉山（今四川省眉山市）人，]</td>\n",
       "      <td>[苏轼（1037年1月8日－1101年8月24日），, 眉州眉山（今四川省眉山市）人，, 号...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>苏东坡的爸爸叫什么名字?</td>\n",
       "      <td>36</td>\n",
       "      <td>[苏轼（1037年1月8日－1101年8月24日），]</td>\n",
       "      <td>[苏轼（1037年1月8日－1101年8月24日），, 号东坡居士、铁冠道人。, 苏轼的散文...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>苏文忠公指的是谁?</td>\n",
       "      <td>36</td>\n",
       "      <td>[苏轼（1037年1月8日－1101年8月24日），]</td>\n",
       "      <td>[苏轼（1037年1月8日－1101年8月24日），, 加赐谥号文忠，]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>《苏文忠公全集》是由何人编纂？</td>\n",
       "      <td>36</td>\n",
       "      <td>[苏轼（1037年1月8日－1101年8月24日），, 编有《苏文忠公全集》。]</td>\n",
       "      <td>[宋人王宗稷收其作品，, 编有《苏文忠公全集》。]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>237</td>\n",
       "      <td>内政部消防署提出防范纵火方法「三从四得」，请问是哪「三从」?</td>\n",
       "      <td>33</td>\n",
       "      <td>[可以依照「三从四得」的方法防范纵火，, 民众可以依照「三从四得」的方法，, 防范居家或社区...</td>\n",
       "      <td>[\\n内政部表示，, 民众可以依照「三从四得」的方法，, 三从就是「从消除死角做起」、「从守...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>238</td>\n",
       "      <td>内政部消防署提出防范纵火方法「三从四得」，请问是哪「四得」?</td>\n",
       "      <td>33</td>\n",
       "      <td>[可以依照「三从四得」的方法防范纵火，, 民众可以依照「三从四得」的方法，, 防范居家或社区...</td>\n",
       "      <td>[\\n内政部表示，, 民众可以依照「三从四得」的方法，, 四得就是「可疑状况要认得」、「大门...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>244</td>\n",
       "      <td>这起诈骗案件的受害人是男性还是女性？</td>\n",
       "      <td>39</td>\n",
       "      <td>[经查系单身女子曾女数月前上网至「异性」交友网站，, 被骗曾姓女子信以为真，, 遂依指示至南...</td>\n",
       "      <td>[南港分局南港派出所于108年11月5日接获民众报案称其友人疑似遭受诈骗案件，, 经查系单身...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245</td>\n",
       "      <td>这起诈骗案件的诈骗金额是多少？</td>\n",
       "      <td>39</td>\n",
       "      <td>[警方查证后确认系一椿网路交友爱情诈骗案件，]</td>\n",
       "      <td>[南港分局南港派出所于108年11月5日接获民众报案称其友人疑似遭受诈骗案件，, 当日接获该...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246</td>\n",
       "      <td>这起诈骗案件中受害人与诈骗者是否见过面？</td>\n",
       "      <td>39</td>\n",
       "      <td>[南港分局南港派出所于108年11月5日接获民众报案称其友人疑似遭受诈骗案件，, 经查系单身...</td>\n",
       "      <td>[南港分局南港派出所于108年11月5日接获民众报案称其友人疑似遭受诈骗案件，, 结识不详外...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Question  Length  \\\n",
       "0               苏东坡在中国历史上，是哪一个朝代的人？      36   \n",
       "1                     苏东坡是中国哪个省份的人？      36   \n",
       "2                      苏东坡的爸爸叫什么名字?      36   \n",
       "3                         苏文忠公指的是谁?      36   \n",
       "4                   《苏文忠公全集》是由何人编纂？      36   \n",
       "..                              ...     ...   \n",
       "237  内政部消防署提出防范纵火方法「三从四得」，请问是哪「三从」?      33   \n",
       "238  内政部消防署提出防范纵火方法「三从四得」，请问是哪「四得」?      33   \n",
       "244              这起诈骗案件的受害人是男性还是女性？      39   \n",
       "245                 这起诈骗案件的诈骗金额是多少？      39   \n",
       "246            这起诈骗案件中受害人与诈骗者是否见过面？      39   \n",
       "\n",
       "                                             Pred_List  \\\n",
       "0                          [苏轼（1037年1月8日－1101年8月24日），]   \n",
       "1         [苏轼（1037年1月8日－1101年8月24日），, 眉州眉山（今四川省眉山市）人，]   \n",
       "2                          [苏轼（1037年1月8日－1101年8月24日），]   \n",
       "3                          [苏轼（1037年1月8日－1101年8月24日），]   \n",
       "4             [苏轼（1037年1月8日－1101年8月24日），, 编有《苏文忠公全集》。]   \n",
       "..                                                 ...   \n",
       "237  [可以依照「三从四得」的方法防范纵火，, 民众可以依照「三从四得」的方法，, 防范居家或社区...   \n",
       "238  [可以依照「三从四得」的方法防范纵火，, 民众可以依照「三从四得」的方法，, 防范居家或社区...   \n",
       "244  [经查系单身女子曾女数月前上网至「异性」交友网站，, 被骗曾姓女子信以为真，, 遂依指示至南...   \n",
       "245                            [警方查证后确认系一椿网路交友爱情诈骗案件，]   \n",
       "246  [南港分局南港派出所于108年11月5日接获民众报案称其友人疑似遭受诈骗案件，, 经查系单身...   \n",
       "\n",
       "                                              Obs_List  \n",
       "0    [苏轼（1037年1月8日－1101年8月24日），, 北宋时著名的文学家、政治家、艺术家、...  \n",
       "1    [苏轼（1037年1月8日－1101年8月24日），, 眉州眉山（今四川省眉山市）人，, 号...  \n",
       "2    [苏轼（1037年1月8日－1101年8月24日），, 号东坡居士、铁冠道人。, 苏轼的散文...  \n",
       "3                 [苏轼（1037年1月8日－1101年8月24日），, 加赐谥号文忠，]  \n",
       "4                            [宋人王宗稷收其作品，, 编有《苏文忠公全集》。]  \n",
       "..                                                 ...  \n",
       "237  [\\n内政部表示，, 民众可以依照「三从四得」的方法，, 三从就是「从消除死角做起」、「从守...  \n",
       "238  [\\n内政部表示，, 民众可以依照「三从四得」的方法，, 四得就是「可疑状况要认得」、「大门...  \n",
       "244  [南港分局南港派出所于108年11月5日接获民众报案称其友人疑似遭受诈骗案件，, 经查系单身...  \n",
       "245  [南港分局南港派出所于108年11月5日接获民众报案称其友人疑似遭受诈骗案件，, 当日接获该...  \n",
       "246  [南港分局南港派出所于108年11月5日接获民众报案称其友人疑似遭受诈骗案件，, 结识不详外...  \n",
       "\n",
       "[199 rows x 4 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'dev_mismatch' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store dev_mismatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT+LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FGC_LSTM_Network(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        \n",
    "        super(FGC_LSTM_Network, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-chinese')\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.h0 = nn.Parameter(torch.FloatTensor(hidden_size).uniform_(-0.1, 0.1))\n",
    "        self.c0 = nn.Parameter(torch.FloatTensor(hidden_size).uniform_(-0.1, 0.1))\n",
    "        self.linear = nn.Linear(hidden_size*2, 1) \n",
    "        # (H-state and c_state must be converted into 3d in forward function)\n",
    "        \n",
    "    def forward_nn(self, batch):    \n",
    "        # batch['ids'] = (batch_size*number of sentence, sent_len)\n",
    "        # batch['segment_ids'] = (batch_size*number of sentence, sent_len)\n",
    "        # batch['mask_ids'] = (batch_size*number of sentence, sent_len)\n",
    "        # pooler_output = (batch_size, 768)\n",
    "        # hidden_state = (batch_size, sent_len, 768)\n",
    "        # output = (batch_size, 1)\n",
    "        \n",
    "        #h0 = torch.zeros(self.num_layers*2, batch['ids'].shape[0], self.hidden_size).to(device)\n",
    "        #c0 = torch.zeros(self.num_layers*2, batch['ids'].shape[0], self.hidden_size).to(device)\n",
    "        \n",
    "        \n",
    "        batch_size = batch['ids'].shape[0]\n",
    "        max_sent_size = batch['ids'].shape[2]\n",
    "        \n",
    "        #h0 = self.h0.expand(batch_size, self.num_layers*2, -1)\n",
    "        #c0 = self.c0.expand(batch_size, self.num_layers*2, -1)\n",
    "        ids = batch['ids'].view(-1, max_sent_size)\n",
    "        mask_ids = batch['mask_ids'].view(-1, max_sent_size)\n",
    "        segment_ids = batch['segment_ids'].view(-1, max_sent_size)\n",
    "        \n",
    "        hidden_state, pooler_output = self.bert(ids, mask_ids, segment_ids)   \n",
    "        \n",
    "        hidden_state = hidden_state[:,0].view(batch_size, -1, 768)\n",
    "        \n",
    "        lstm_output, (hn, cn) = self.lstm(hidden_state)\n",
    "        \n",
    "        linear_output = self.linear(lstm_output).squeeze(-1)\n",
    "        \n",
    "        return linear_output\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        output = self.forward_nn(batch)\n",
    "        labels = batch['labels']\n",
    "        loss_fn = nn.BCEWithLogitsLoss(weight=batch['sentence_mask'])\n",
    "        loss = loss_fn(output, labels)\n",
    "        return loss\n",
    "     \n",
    "    \"\"\"\n",
    "    def loss_fn(self, batch):\n",
    "        \n",
    "        batch_size = batch['ids'].shape[0]\n",
    "        \n",
    "        if torch.zeros(max(size_list) - min(size_list), batch.shape[2]) in batch:\n",
    "            loss_fn = nn.BCEWithLogitsLoss(w)\n",
    "            \n",
    "        else:\n",
    "            loss_fn = nn.BCEWithLogitsLoss()\n",
    "        output = self.forward(batch)\n",
    "        target = batch['labels'].float().to(device)\n",
    "        \n",
    "        return loss_fn(output, target)\n",
    "    \"\"\"\n",
    "    \n",
    "    def _predict(self, batch):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = self.forward_nn(batch)\n",
    "            scores = torch.sigmoid(output)\n",
    "            scores = scores.cpu().numpy().tolist()\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    def predict_fgc(self, batch, threshold=0.5):\n",
    "        scores = self._predict(batch)\n",
    "        max_i = 0\n",
    "        max_score = 0\n",
    "        sp = []\n",
    "\n",
    "        for i, score in enumerate(scores[0]):\n",
    "\n",
    "            if score > max_score:\n",
    "                max_i = i\n",
    "                max_score = score\n",
    "            if score >= threshold:\n",
    "                sp.append(i)\n",
    "\n",
    "        # This is to ensure there's no empty supporting evidences\n",
    "        if not sp:\n",
    "            sp.append(max_i)\n",
    "        return {'sp': sp, 'sp_scores': scores}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT+Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bertAgg(nn.Module):\n",
    "    \n",
    "    def __init__(self, number_of_sentence, max_sentence_length, baseline):\n",
    "        \n",
    "        super(bertAgg, self).__init__()\n",
    "        self.max_sentence_length = max_sentence_length\n",
    "        self.number_of_sentence = number_of_sentence\n",
    "        baseline.load_state_dict(torch.load(\"Models/baseline_models_with_scheduler/model_epoch8_eval_em:0.198_precision:0.603_recall:0.588_f1:0.545_loss:0.031.m\"))\n",
    "        self.baseline = baseline\n",
    "        self.bert = BertModel.from_pretrained('bert-base-chinese')\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.linearAgg = nn.Linear(1536, 1)\n",
    "        self.qsLinear = nn.Linear(1536, 1)\n",
    "        \n",
    "    def forward_nn(self, batch):\n",
    "        \n",
    "        # Sent objects into CUDA\n",
    "        for key in batch:\n",
    "            if key == 'labels':\n",
    "                batch[key] = batch[key].to(device).to(torch.float)\n",
    "            else:\n",
    "                batch[key] = batch[key].to(device).to(torch.long)\n",
    "\n",
    "        batch_size = batch['ids'].shape[0]\n",
    "        padded_zeros = torch.tensor([0] * self.number_of_sentence)\n",
    "        \n",
    "        \n",
    "        # Sent sentences into BERT embeddings\n",
    "        sentence_ids = batch['ids'].view(-1, self.max_sentence_length)\n",
    "        sentence_mask_ids = batch['mask_ids'].view(-1, self.max_sentence_length) #(batch, 5)\n",
    "        sentence_hidden_state, sentence_pooler_output = self.baseline.bert(sentence_ids, sentence_mask_ids)   \n",
    "        \n",
    "        # Sent question into BERT embeddings\n",
    "        question_ids = batch['q_ids']\n",
    "        question_mask_ids = batch['q_mask_ids']\n",
    "        question_hidden_state, question_pooler_output = self.baseline.bert(question_ids, question_mask_ids) # (batch, 768)\n",
    "      \n",
    "        sentence_mask = batch['sentence_mask']\n",
    "        sentence_mask = sentence_mask.type(torch.float)\n",
    "        \n",
    "        # Aggregate\n",
    "        sentence_pooler_output = sentence_pooler_output.view(batch_size, -1, 768) # (batch, 5, 768)\n",
    "        \n",
    "        target_sentence = sentence_pooler_output[:, self.number_of_sentence // 2, :].unsqueeze(1) # (batch, 1, 768)\n",
    "        target_sentence = target_sentence.expand(-1, self.number_of_sentence, -1) # (batch, 5, 768)\n",
    "        \n",
    "        concatenated = torch.cat((target_sentence, sentence_pooler_output), dim=-1) # (batch, 5, 768*2)\n",
    "        att_weight = self.linearAgg(concatenated) + (1.0 - sentence_mask) * -10000 #\n",
    "        #if sentence_pooler_output\n",
    "        att_weight = self.softmax(att_weight) # (batch, 5)\n",
    "        aggregated_sentence = torch.matmul(att_weight.transpose(1,2), sentence_pooler_output) # (batch, 1, 768)\n",
    "        aggregated_sentence = aggregated_sentence.squeeze(1) # (batch, 768)\n",
    "\n",
    "        # Concatenate question to aggregated sentence\n",
    "        qs_concatenated = torch.cat((aggregated_sentence, question_pooler_output), dim=-1) # (batch, 1536)\n",
    "        final_output = self.qsLinear(qs_concatenated) # (batch, 1)\n",
    "        return final_output, att_weight#final_output, att_weight\n",
    "        \n",
    "        \n",
    "        \n",
    "#         for i in range(batch_size):\n",
    "            \n",
    "#             mini_batch = sentence_pooler_output[i]\n",
    "#             # Aggregate sentence weights\n",
    "#             target_sentence = sentence_pooler_output[i, self.number_of_sentence // 2, :]\n",
    "#             target_sentence_clone = target_sentence.expand(self.number_of_sentence, 768)\n",
    "#             concatenated = torch.cat((mini_batch, target_sentence_clone), dim=1)\n",
    "#             target_sentence_aggregated = torch.sum(self.linearAgg(concatenated) * mini_batch, dim=0)\n",
    "            \n",
    "#             # Question sentence feedforward\n",
    "#             question_to_concat = question_pooler_output[i]\n",
    "#             qs_concatenated = torch.cat((target_sentence_aggregated, question_to_concat))\n",
    "#             final_output = self.linearAgg(qs_concatenated).squeeze(-1)\n",
    "#             batch_output.append(final_output)\n",
    "        \n",
    "        \n",
    "#         return torch.tensor(batch_output).reshape(batch_size, 1).to(device)\n",
    "        \n",
    "        \n",
    "    def forward(self, batch):\n",
    "        \n",
    "        output, _ = self.forward_nn(batch)\n",
    "        labels = batch['labels']\n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "        loss = loss_fn(output, labels)\n",
    "        #print(batch['ids'], output, _)\n",
    "        #print(tokenizer.convert_ids_to_tokens(batch['ids'][0][2].tolist()))\n",
    "        #print(tokenizer.convert_ids_to_tokens(batch['ids'][1][2].tolist()))\n",
    "        #print(batch['ids'])\n",
    "        #print(output, labels)\n",
    "        #print(loss)\n",
    "        return loss\n",
    "    \n",
    "    def _predict(self, batch):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            output, att_weight = self.forward_nn(batch)\n",
    "            scores = torch.sigmoid(output)\n",
    "            scores = scores.cpu().numpy().tolist()\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    def predict_fgc(self, batch, threshold=0.5):\n",
    "        scores = self._predict(batch)\n",
    "        max_i = 0\n",
    "        max_score = 0\n",
    "        sp = []\n",
    "\n",
    "        for i, score in enumerate(scores[0]):\n",
    "\n",
    "            if score > max_score:\n",
    "                max_i = i\n",
    "                max_score = score\n",
    "            if score >= threshold:\n",
    "                sp.append(i)\n",
    "\n",
    "        # This is to ensure there's no empty supporting evidences\n",
    "        if not sp:\n",
    "            sp.append(max_i)\n",
    "        return {'sp': sp, 'sp_scores': scores}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline+Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-122-139763ecbec2>, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-122-139763ecbec2>\"\u001b[0;36m, line \u001b[0;32m22\u001b[0m\n\u001b[0;31m    mask_ids =\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class baselineAgg(nn.Module):\n",
    "\n",
    "    def __init__(self, number_of_sentence, max_sentence_length, BMPATH):\n",
    "        \n",
    "        super(bertAgg, self).__init__()\n",
    "        self.max_sentence_length = max_sentence_length\n",
    "        self.number_of_sentence = number_of_sentence\n",
    "        self.baseline = baseline_model().load_state_dict(torch.load(BMPATH))\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward_nn(self, batch):\n",
    "        # batch = (batch_size, sentence length)\n",
    "        # pooler_output = (batch_size, 768)\n",
    "        # Sent objects into CUDA\n",
    "        for key in batch:\n",
    "            if key == 'labels':\n",
    "                batch[key] = batch[key].to(device).to(torch.float)\n",
    "            else:\n",
    "                batch[key] = batch[key].to(device).to(torch.long)\n",
    "\n",
    "        ids = batch['ids'].view(-1, self.max_sentence_length)\n",
    "        mask_ids = \n",
    "        hidden_state, pooler_output = self.baseline.bert(batch['ids'], batch['mask_ids'], batch['segment_ids'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0811 07:59:12.381575 139897081689920 configuration_utils.py:152] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json from cache at /root/.cache/torch/transformers/8a3b1cfe5da58286e12a0f5d7d182b8d6eca88c08e26c332ee3817548cf7e60a.f12a4f986e43d8b328f5b067a641064d67b91597567a06c7b122d1ca7dfd9741\n",
      "I0811 07:59:12.386453 139897081689920 configuration_utils.py:169] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "I0811 07:59:13.261365 139897081689920 modeling_utils.py:387] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-pytorch_model.bin from cache at /root/.cache/torch/transformers/b1b5e295889f2d0979ede9a78ad9cb5dc6a0e25ab7f9417b315f0a2c22f4683d.929717ca66a3ba9eb9ec2f85973c6398c54c38a4faa464636a491d7a705f7eb6\n"
     ]
    }
   ],
   "source": [
    "new_network = bertAgg(3, 250, baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bertAgg(\n",
       "  (baseline): baseline_model(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (linear): Linear(in_features=768, out_features=1, bias=True)\n",
       "  )\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (softmax): Softmax()\n",
       "  (linearAgg): Linear(in_features=1536, out_features=1, bias=True)\n",
       "  (qsLinear): Linear(in_features=1536, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_network.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_val_batches = eval_preprocessing(validation_data, dev_dataset)\n",
    "for data in test_val_batches:\n",
    "    data['ids'] = data['ids'].unsqueeze(0)\n",
    "    data['mask_ids'] = data['mask_ids'].unsqueeze(0)\n",
    "    data['segment_ids'] = data['segment_ids'].unsqueeze(0)\n",
    "    data['labels'] = data['labels'].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_model_eval(new_network, test_val_batches, 0, validation_data['QUESTIONS'].apply(lambda x: x[0]['SHINT_']).tolist(), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Improved Model & Evaluating Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_model_optim(nn, num_epochs, lr, dataloader):\n",
    "    param_optimizer = list(nn.bert.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "    num_epochs = num_epochs\n",
    "    num_train_optimization_steps = len(dataloader) * num_epochs\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=lr)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                     num_warmup_steps=int(\n",
    "                                                         num_train_optimization_steps * 0.1),\n",
    "                                                     num_training_steps=num_train_optimization_steps)\n",
    "    return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _update_sp(metrics, sp_gold, sp_pred):\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "        \n",
    "    for p in sp_pred:\n",
    "        if p in sp_gold:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "    for g in sp_gold:\n",
    "        if g not in sp_pred:\n",
    "            fn += 1\n",
    "            \n",
    "    precision = 1.0 * tp / (tp + fp) if tp + fp > 0 else 0.0\n",
    "    recall = 1.0 * tp / (tp + fn) if tp + fn > 0 else 0.0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0.0\n",
    "    em = 1.0 if fp + fn == 0 else 0.0\n",
    "    \n",
    "    metrics['sp_em'] += em\n",
    "    metrics['sp_f1'] += f1\n",
    "    metrics['sp_prec'] += precision\n",
    "    metrics['sp_recall'] += recall\n",
    "    \n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_sp_fgc(sp_golds, sp_preds):\n",
    "    \n",
    "    metrics = {'sp_em': 0, 'sp_prec': 0, 'sp_recall': 0, 'sp_f1': 0}\n",
    "    \n",
    "    assert len(sp_golds) == len(sp_preds)\n",
    "    \n",
    "    for sp_gold, sp_pred in zip(sp_golds, sp_preds):\n",
    "        _update_sp(metrics, sp_gold, sp_pred)\n",
    "    \n",
    "    N = len(sp_golds)\n",
    "    for k in metrics.keys():\n",
    "        metrics[k] /= N\n",
    "        metrics[k] = round(metrics[k], 3)\n",
    "    print(metrics)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_model_eval(network, train_batches, dev_batches, current_epoch, train_sp_golds, dev_sp_golds, avg_loss):\n",
    "    \n",
    "    network.eval()\n",
    "    with torch.no_grad():\n",
    "        dev_sp_preds = []\n",
    "        train_sp_preds = []\n",
    "        \n",
    "        for batch in tqdm(dev_batches):\n",
    "            out_dct= network.predict_fgc(batch)\n",
    "    \n",
    "            dev_sp_preds.append(out_dct['sp'])\n",
    "            print(out_dct['sp'])\n",
    "        \n",
    "        for batch in tqdm(train_batches):\n",
    "            train_dct = network.predict_fgc(batch)\n",
    "            train_sp_preds.append(train_dct['sp'])\n",
    "            print(train_dct['sp'])\n",
    "            \n",
    "    dev_metrics = eval_sp_fgc(dev_sp_golds, dev_sp_preds)\n",
    "    train_metrics = eval_sp_fgc(train_sp_golds, train_sp_preds)\n",
    "    \n",
    "    print('epoch %d eval_recall: %.3f eval_f1: %.3f loss: %.3f' % (\n",
    "            current_epoch, dev_metrics['sp_recall'], dev_metrics['sp_f1'], avg_loss))\n",
    "    \n",
    "    print('epoch %d eval_recall: %.3f eval_f1: %.3f loss: %.3f' % (\n",
    "            current_epoch, train_metrics['sp_recall'], train_metrics['sp_f1'], avg_loss))\n",
    "    #torch.save(network.state_dict(), \"New_Models/model_epoch{0}_eval_em:{1:.3f}_precision:{2:.3f}_recall:{3:.3f}_f1:{4:.3f}_loss:{5:.3f}.m\".format(current_epoch, metrics['sp_em'], metrics['sp_prec'], metrics['sp_recall'], metrics['sp_f1'], avg_loss))\n",
    "    \n",
    "    return #sp_preds, sp_golds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_model_train(network, dataloader, train_batches, dev_batches, num_epochs, lr):\n",
    "    \n",
    "    optimizer, scheduler = new_model_optim(network, num_epochs, lr, dataloader)\n",
    "    \n",
    "    train_sp_golds = training_data['QUESTIONS'].apply(lambda x: x[0]['SHINT_']).tolist()\n",
    "    dev_sp_golds = validation_data['QUESTIONS'].apply(lambda x: x[0]['SHINT_']).tolist()\n",
    "    \n",
    "    for current_epoch in range(num_epochs):\n",
    "        network.train()\n",
    "        running_loss = 0.0\n",
    "        for batch in tqdm(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            current_loss = network(batch)\n",
    "\n",
    "            current_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(network.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            running_loss += current_loss.item()\n",
    "            \n",
    "        learning_rate_scalar = scheduler.get_lr()[0]\n",
    "        print('lr = %f' % learning_rate_scalar)\n",
    "        avg_loss = running_loss/len(dataloader)\n",
    "        print('epoch %d train_loss: %.3f' % (current_epoch, avg_loss))\n",
    "        new_model_eval(network, train_batches, dev_batches, current_epoch, train_sp_golds, dev_sp_golds, avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "sent_dev_batches = sent_eval_preprocessing(validation_data, sent_dev_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "sent_train_batches = sent_eval_preprocessing(training_data, sent_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e618ea52fd478c9802b9b3cc463bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=247), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30a7561b02f8484faa3ca704eb4f1430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=882), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-7e3b2badd48c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_sp_golds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'QUESTIONS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SHINT_'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdev_sp_golds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'QUESTIONS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SHINT_'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnew_model_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_train_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_dev_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_sp_golds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_sp_golds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-101-2d3751a0ad8f>\u001b[0m in \u001b[0;36mnew_model_eval\u001b[0;34m(network, train_batches, dev_batches, current_epoch, train_sp_golds, dev_sp_golds, avg_loss)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mtrain_dct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_fgc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mtrain_sp_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-121-f8c5729b8a9e>\u001b[0m in \u001b[0;36mpredict_fgc\u001b[0;34m(self, batch, threshold)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_fgc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mmax_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mmax_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-121-f8c5729b8a9e>\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matt_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_sp_golds = training_data['QUESTIONS'].apply(lambda x: x[0]['SHINT_']).tolist()\n",
    "dev_sp_golds = validation_data['QUESTIONS'].apply(lambda x: x[0]['SHINT_']).tolist()\n",
    "new_model_eval(new_network, sent_train_batches, sent_dev_batches, 0, dev_sp_golds, train_sp_golds, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45844c6668d94bf38862eb09e96b00a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7856), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr = 0.000010\n",
      "epoch 0 train_loss: 0.267\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1f26adb820349d88ad8ce5cd578d36b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=247), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00748c1af8a2445b9311b180080a7a64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=882), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sp_em': 0.04, 'sp_prec': 0.259, 'sp_recall': 0.132, 'sp_f1': 0.168}\n",
      "{'sp_em': 0.065, 'sp_prec': 0.279, 'sp_recall': 0.151, 'sp_f1': 0.185}\n",
      "epoch 0 eval_recall: 0.132 eval_f1: 0.168 loss: 0.267\n",
      "epoch 0 eval_recall: 0.151 eval_f1: 0.185 loss: 0.267\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84f6064981cf4f3d91346f1b1ab776f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7856), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr = 0.000020\n",
      "epoch 1 train_loss: 0.270\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4bc7c7332c9417b8739766bc5ec0bf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=247), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70dae450b515485aafbae14c7b531f6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=882), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sp_em': 0.04, 'sp_prec': 0.259, 'sp_recall': 0.132, 'sp_f1': 0.168}\n",
      "{'sp_em': 0.065, 'sp_prec': 0.279, 'sp_recall': 0.151, 'sp_f1': 0.185}\n",
      "epoch 1 eval_recall: 0.132 eval_f1: 0.168 loss: 0.270\n",
      "epoch 1 eval_recall: 0.151 eval_f1: 0.185 loss: 0.270\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e90bef4e0ca6407ca7d24a1b6f420327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7856), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-176ad9f60736>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_model_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_sent_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_train_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_dev_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.00002\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-69-f84f64c20588>\u001b[0m in \u001b[0;36mnew_model_train\u001b[0;34m(network, dataloader, train_batches, dev_batches, num_epochs, lr)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mcurrent_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "new_model_train(new_network, dataloader_sent_train, sent_train_batches, sent_dev_batches, 20, 0.00002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dev_batches = window_sentence_preprocessing(validation_data, dev_dataset, 10)\n",
    "testing_dev_batches = DataLoader(new_dev_batches, batch_size=2, shuffle = False, collate_fn = collate_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MUST DO THIS BEFORE EVALUATING \n",
    "eval_train_batches = eval_preprocessing(training_data, train_dataset)\n",
    "for data in eval_train_batches:\n",
    "    data['ids'] = data['ids'].unsqueeze(0)\n",
    "    data['mask_ids'] = data['mask_ids'].unsqueeze(0)\n",
    "    data['segment_ids'] = data['segment_ids'].unsqueeze(0)\n",
    "    data['labels'] = data['labels'].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cdcac7fd2374199b4951e8018a587f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=882), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.085, 'sp_prec': 0.3, 'sp_recall': 0.172, 'sp_f1': 0.206}\n",
      "epoch 0 eval_recall: 0.172 eval_f1: 0.206 loss: 0.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[18],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [5],\n",
       " [7, 8, 9, 10, 11, 12, 13, 14],\n",
       " [22, 23],\n",
       " [27],\n",
       " [26, 30],\n",
       " [33, 34],\n",
       " [1, 3, 4, 5, 6],\n",
       " [5, 7],\n",
       " [7],\n",
       " [7, 8, 11],\n",
       " [12, 17],\n",
       " [11, 17],\n",
       " [11, 19],\n",
       " [23],\n",
       " [25, 28, 30],\n",
       " [25, 28],\n",
       " [16, 17],\n",
       " [],\n",
       " [9, 10],\n",
       " [9, 11, 13],\n",
       " [0, 2, 6],\n",
       " [0],\n",
       " [0, 14, 16],\n",
       " [0, 14, 16],\n",
       " [0, 14, 16, 17, 20, 21, 24, 25, 27, 29],\n",
       " [0, 14, 17],\n",
       " [0, 14, 20, 21],\n",
       " [0, 14, 24, 25],\n",
       " [0, 14, 27],\n",
       " [0, 14, 29],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [0, 1, 8, 11],\n",
       " [0, 1, 8, 11, 12, 14],\n",
       " [15],\n",
       " [5, 6],\n",
       " [9, 16],\n",
       " [11, 16],\n",
       " [11, 16],\n",
       " [11, 16],\n",
       " [0, 2],\n",
       " [8, 9],\n",
       " [8, 9],\n",
       " [0],\n",
       " [0, 1],\n",
       " [0, 4],\n",
       " [0, 6, 7, 8, 9],\n",
       " [0, 6, 7, 8, 9],\n",
       " [18, 21],\n",
       " [14],\n",
       " [14, 15],\n",
       " [21, 23, 24],\n",
       " [0, 2],\n",
       " [3],\n",
       " [0, 4, 5],\n",
       " [0, 4],\n",
       " [6],\n",
       " [11, 12],\n",
       " [11, 12],\n",
       " [11, 12],\n",
       " [11],\n",
       " [0],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [10, 11],\n",
       " [11, 12, 13, 14],\n",
       " [],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [0, 4],\n",
       " [0, 41],\n",
       " [0, 41],\n",
       " [0, 25, 41],\n",
       " [0, 5, 7],\n",
       " [0, 8],\n",
       " [0, 7],\n",
       " [0, 8],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [3, 4],\n",
       " [3, 4],\n",
       " [5, 6, 7, 8],\n",
       " [5, 6, 8],\n",
       " [9, 10],\n",
       " [9, 10],\n",
       " [9, 10],\n",
       " [9, 10],\n",
       " [11, 12, 13],\n",
       " [11, 12, 14],\n",
       " [2, 3],\n",
       " [2, 3],\n",
       " [4, 5],\n",
       " [6, 8, 9],\n",
       " [6, 8, 9],\n",
       " [5, 6, 8, 9],\n",
       " [12, 14, 15],\n",
       " [12, 14, 15],\n",
       " [0, 1, 2],\n",
       " [3, 4],\n",
       " [3, 4, 5],\n",
       " [7, 11],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [21],\n",
       " [20, 21],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [7, 8],\n",
       " [8, 9],\n",
       " [9, 10],\n",
       " [10, 11],\n",
       " [11, 12],\n",
       " [12, 13],\n",
       " [13, 14],\n",
       " [14, 15],\n",
       " [0, 1, 3, 4],\n",
       " [6, 7],\n",
       " [0, 4],\n",
       " [0, 5],\n",
       " [0],\n",
       " [0, 1],\n",
       " [5],\n",
       " [5],\n",
       " [5],\n",
       " [5],\n",
       " [9],\n",
       " [9, 10, 11, 27],\n",
       " [10, 12],\n",
       " [0, 10, 13],\n",
       " [27],\n",
       " [0, 1, 22],\n",
       " [16],\n",
       " [32],\n",
       " [0, 5],\n",
       " [5, 6],\n",
       " [10],\n",
       " [1, 3],\n",
       " [1, 4],\n",
       " [5, 30, 33, 37],\n",
       " [9],\n",
       " [10, 13],\n",
       " [0, 1, 23, 24, 26],\n",
       " [1, 4],\n",
       " [1, 4],\n",
       " [1, 2, 4],\n",
       " [5, 6],\n",
       " [1, 23, 24],\n",
       " [24],\n",
       " [],\n",
       " [7, 8],\n",
       " [9, 10],\n",
       " [16, 17],\n",
       " [18, 19],\n",
       " [25, 26],\n",
       " [27, 28],\n",
       " [25, 26],\n",
       " [25, 26],\n",
       " [27, 28],\n",
       " [27, 28],\n",
       " [8, 10, 11, 12],\n",
       " [30, 32, 33],\n",
       " [32, 33],\n",
       " [30, 31],\n",
       " [30],\n",
       " [32, 33],\n",
       " [30, 31],\n",
       " [0],\n",
       " [7, 8],\n",
       " [0],\n",
       " [6, 7, 10],\n",
       " [7],\n",
       " [0, 1, 5],\n",
       " [0, 1, 5, 7],\n",
       " [0, 18, 19],\n",
       " [0, 1, 5, 18, 19],\n",
       " [0],\n",
       " [0, 5],\n",
       " [0, 39],\n",
       " [33, 35],\n",
       " [0, 43, 44, 45, 48],\n",
       " [0, 9],\n",
       " [0, 39],\n",
       " [22, 23, 24],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [46, 49],\n",
       " [0],\n",
       " [0],\n",
       " [0, 11],\n",
       " [0, 11, 12],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [1, 3],\n",
       " [1, 6],\n",
       " [1, 8, 9, 11],\n",
       " [0, 1],\n",
       " [0, 1, 5],\n",
       " [0, 1],\n",
       " [8, 9],\n",
       " [8, 9],\n",
       " [0, 9, 12],\n",
       " [0, 6],\n",
       " [0],\n",
       " [0],\n",
       " [0, 10],\n",
       " [0, 12, 13],\n",
       " [0, 32, 33],\n",
       " [0, 32, 33],\n",
       " [0, 32, 33],\n",
       " [0, 14],\n",
       " [39],\n",
       " [0, 40],\n",
       " [0],\n",
       " [39, 43],\n",
       " [39, 40],\n",
       " [0, 35],\n",
       " [39, 42],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0, 1],\n",
       " [8, 9],\n",
       " [19],\n",
       " [21, 26, 34],\n",
       " [40, 41, 42, 43],\n",
       " [0],\n",
       " [9, 11, 12],\n",
       " [9, 12],\n",
       " [0, 1],\n",
       " [1, 9, 13],\n",
       " [19, 20, 31],\n",
       " [19],\n",
       " [19],\n",
       " [0, 2, 3, 4],\n",
       " [0, 34, 35],\n",
       " [0, 1, 21],\n",
       " [0, 3, 21, 22],\n",
       " [0, 4],\n",
       " [0, 21, 22, 24],\n",
       " [0, 1, 12, 15],\n",
       " [0, 1, 11, 12],\n",
       " [20],\n",
       " [27, 28],\n",
       " [27, 28],\n",
       " [27, 28],\n",
       " [0],\n",
       " [0, 1],\n",
       " [2, 3],\n",
       " [9, 10],\n",
       " [11, 12],\n",
       " [18, 19],\n",
       " [27, 28],\n",
       " [29, 30],\n",
       " [18, 19, 20, 21],\n",
       " [0],\n",
       " [1, 2],\n",
       " [0, 9, 10],\n",
       " [6],\n",
       " [0, 12],\n",
       " [1, 14, 15],\n",
       " [14, 16],\n",
       " [0, 1],\n",
       " [1],\n",
       " [11],\n",
       " [11],\n",
       " [2, 3],\n",
       " [4],\n",
       " [11],\n",
       " [11],\n",
       " [15],\n",
       " [11],\n",
       " [0, 1, 2],\n",
       " [6],\n",
       " [],\n",
       " [12],\n",
       " [16, 20],\n",
       " [12],\n",
       " [16, 17, 20],\n",
       " [0, 6],\n",
       " [0, 10],\n",
       " [0, 10, 34, 38, 40],\n",
       " [17, 21],\n",
       " [12, 13, 17],\n",
       " [14, 15],\n",
       " [35, 37],\n",
       " [4, 15],\n",
       " [31],\n",
       " [56],\n",
       " [49, 55],\n",
       " [11, 15],\n",
       " [1],\n",
       " [2, 4],\n",
       " [2, 7],\n",
       " [2, 8],\n",
       " [10, 12],\n",
       " [14],\n",
       " [15, 16],\n",
       " [16],\n",
       " [28, 29, 30],\n",
       " [29],\n",
       " [30],\n",
       " [35, 37, 49],\n",
       " [2, 3, 5, 6, 13, 14],\n",
       " [9, 10],\n",
       " [9, 10],\n",
       " [9, 10],\n",
       " [9, 10],\n",
       " [9, 10],\n",
       " [9, 10],\n",
       " [22, 28],\n",
       " [35],\n",
       " [35],\n",
       " [50],\n",
       " [],\n",
       " [3, 7],\n",
       " [7],\n",
       " [0, 1, 15, 16, 17, 18, 19],\n",
       " [7],\n",
       " [24],\n",
       " [14, 15],\n",
       " [29, 30, 35, 36, 39],\n",
       " [0, 3],\n",
       " [19, 20],\n",
       " [0, 4, 39],\n",
       " [4],\n",
       " [2],\n",
       " [0],\n",
       " [22],\n",
       " [0, 15, 16],\n",
       " [0, 16],\n",
       " [0, 17],\n",
       " [0],\n",
       " [5],\n",
       " [0, 15],\n",
       " [0, 15],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [1, 13],\n",
       " [12],\n",
       " [17],\n",
       " [0, 4],\n",
       " [0, 20, 21],\n",
       " [21, 27],\n",
       " [43, 44, 45, 48],\n",
       " [0, 43, 44],\n",
       " [0],\n",
       " [0, 1],\n",
       " [8, 9],\n",
       " [6, 8, 10, 14, 16],\n",
       " [32, 33],\n",
       " [34, 35],\n",
       " [14, 15],\n",
       " [23, 24],\n",
       " [1, 2, 12, 25],\n",
       " [2, 12, 25],\n",
       " [2],\n",
       " [2, 3, 4],\n",
       " [12, 15],\n",
       " [25, 26],\n",
       " [25],\n",
       " [12],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0, 2, 4, 5],\n",
       " [11],\n",
       " [12, 14],\n",
       " [18, 19],\n",
       " [16, 17],\n",
       " [12],\n",
       " [12],\n",
       " [14],\n",
       " [0, 1, 2],\n",
       " [3],\n",
       " [4],\n",
       " [10, 11],\n",
       " [10, 11],\n",
       " [11],\n",
       " [7, 8],\n",
       " [11],\n",
       " [11],\n",
       " [11],\n",
       " [11],\n",
       " [],\n",
       " [0, 1, 4],\n",
       " [7, 12],\n",
       " [13],\n",
       " [4, 6],\n",
       " [4, 6],\n",
       " [4, 6],\n",
       " [4, 8],\n",
       " [19],\n",
       " [0, 7],\n",
       " [17, 18, 19],\n",
       " [3],\n",
       " [7, 9],\n",
       " [7, 8],\n",
       " [7, 14],\n",
       " [20, 21],\n",
       " [8, 9],\n",
       " [0, 3, 4],\n",
       " [3, 9],\n",
       " [1, 3],\n",
       " [1, 2, 3],\n",
       " [15, 17],\n",
       " [16],\n",
       " [4, 6, 9],\n",
       " [0, 5],\n",
       " [0, 9],\n",
       " [10, 11],\n",
       " [0, 1],\n",
       " [9, 12],\n",
       " [9, 12],\n",
       " [17],\n",
       " [0, 28, 29],\n",
       " [0, 1, 2, 5, 9],\n",
       " [0, 1, 5, 9],\n",
       " [4, 5, 6, 7],\n",
       " [14, 15, 18],\n",
       " [22],\n",
       " [9],\n",
       " [27, 28],\n",
       " [27, 28, 29],\n",
       " [27, 28],\n",
       " [0, 2],\n",
       " [0, 5],\n",
       " [8],\n",
       " [12, 13],\n",
       " [12, 13],\n",
       " [12, 13, 14],\n",
       " [13, 14],\n",
       " [0],\n",
       " [0, 2],\n",
       " [0, 8],\n",
       " [5],\n",
       " [5, 6],\n",
       " [0],\n",
       " [],\n",
       " [0, 1, 7, 12],\n",
       " [3, 4],\n",
       " [9],\n",
       " [4, 9],\n",
       " [2, 3],\n",
       " [19, 20],\n",
       " [27, 28],\n",
       " [0, 1],\n",
       " [21, 22],\n",
       " [9, 10],\n",
       " [2],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [0, 22],\n",
       " [19],\n",
       " [10, 19],\n",
       " [0],\n",
       " [0, 2],\n",
       " [2],\n",
       " [0, 1],\n",
       " [0, 7],\n",
       " [0, 4, 6, 7],\n",
       " [0, 4],\n",
       " [2],\n",
       " [0],\n",
       " [2],\n",
       " [2],\n",
       " [2],\n",
       " [3, 8, 14, 20],\n",
       " [0, 3],\n",
       " [2, 3],\n",
       " [3, 4],\n",
       " [3, 20, 22],\n",
       " [27],\n",
       " [20, 22, 31],\n",
       " [3, 31, 33],\n",
       " [1],\n",
       " [10, 12, 13, 17],\n",
       " [3],\n",
       " [7],\n",
       " [3, 4],\n",
       " [8, 9],\n",
       " [0, 6, 9],\n",
       " [0, 3, 9],\n",
       " [0, 6, 7, 9],\n",
       " [0, 9, 11],\n",
       " [0, 9, 20],\n",
       " [0, 9, 27],\n",
       " [7, 9],\n",
       " [7, 10],\n",
       " [11, 16, 17, 18],\n",
       " [7, 12, 13, 14, 15, 17],\n",
       " [],\n",
       " [0, 2],\n",
       " [0, 2],\n",
       " [0, 1, 3],\n",
       " [0],\n",
       " [0, 4],\n",
       " [0, 4],\n",
       " [0, 5],\n",
       " [0, 4, 5],\n",
       " [0, 7, 10, 11],\n",
       " [11, 13],\n",
       " [11, 13],\n",
       " [11, 13],\n",
       " [11, 13],\n",
       " [5],\n",
       " [6],\n",
       " [0],\n",
       " [4, 5],\n",
       " [4, 5],\n",
       " [0],\n",
       " [0],\n",
       " [10],\n",
       " [1, 10, 11],\n",
       " [4, 7],\n",
       " [8],\n",
       " [15],\n",
       " [14],\n",
       " [10, 18],\n",
       " [0],\n",
       " [0, 1],\n",
       " [13],\n",
       " [2],\n",
       " [3],\n",
       " [1],\n",
       " [4, 5],\n",
       " [8],\n",
       " [9],\n",
       " [11, 12],\n",
       " [11, 12],\n",
       " [0],\n",
       " [0, 2],\n",
       " [0, 2],\n",
       " [3],\n",
       " [4, 5],\n",
       " [6],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [2],\n",
       " [2, 3],\n",
       " [5],\n",
       " [0, 13],\n",
       " [14, 15],\n",
       " [3],\n",
       " [3],\n",
       " [1, 2, 3, 4],\n",
       " [23],\n",
       " [5, 11, 12],\n",
       " [23, 24, 25, 26],\n",
       " [46, 47],\n",
       " [48, 49],\n",
       " [0],\n",
       " [0, 1],\n",
       " [2, 3, 5],\n",
       " [2, 4],\n",
       " [9],\n",
       " [12],\n",
       " [0, 1, 9],\n",
       " [12],\n",
       " [16],\n",
       " [0],\n",
       " [0, 1],\n",
       " [0, 2, 4],\n",
       " [0, 12],\n",
       " [14, 23],\n",
       " [39, 40, 41, 50],\n",
       " [0, 1],\n",
       " [7],\n",
       " [7, 9],\n",
       " [15],\n",
       " [16],\n",
       " [30, 31],\n",
       " [30, 39],\n",
       " [30, 36, 37],\n",
       " [0, 1, 2, 6, 7],\n",
       " [0, 1, 2, 6, 7],\n",
       " [8],\n",
       " [13, 16, 17],\n",
       " [17, 18, 19],\n",
       " [17, 19, 20],\n",
       " [17, 20],\n",
       " [38, 39, 40, 41],\n",
       " [44, 45],\n",
       " [46, 47],\n",
       " [1, 4, 13],\n",
       " [14],\n",
       " [14],\n",
       " [15, 16],\n",
       " [15, 16],\n",
       " [18],\n",
       " [18],\n",
       " [18],\n",
       " [18],\n",
       " [0, 2, 3, 4],\n",
       " [0],\n",
       " [12, 13, 14],\n",
       " [16, 17],\n",
       " [15, 23, 24],\n",
       " [27, 28],\n",
       " [15, 27, 34],\n",
       " [15, 27, 37],\n",
       " [46, 52],\n",
       " [27, 38, 42, 43],\n",
       " [57, 58, 59],\n",
       " [46, 58],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [2, 3],\n",
       " [3, 4],\n",
       " [4, 5],\n",
       " [17],\n",
       " [22, 23, 24, 25],\n",
       " [26],\n",
       " [],\n",
       " [0, 2],\n",
       " [2],\n",
       " [2],\n",
       " [3, 8],\n",
       " [19, 23],\n",
       " [18, 23, 24],\n",
       " [24],\n",
       " [32, 33],\n",
       " [0],\n",
       " [2, 3],\n",
       " [7],\n",
       " [13],\n",
       " [7, 8],\n",
       " [14],\n",
       " [16, 18, 19],\n",
       " [22, 23],\n",
       " [24, 25],\n",
       " [36, 37],\n",
       " [5],\n",
       " [5],\n",
       " [5, 6, 7],\n",
       " [12, 13],\n",
       " [9, 10, 11],\n",
       " [13],\n",
       " [14],\n",
       " [15],\n",
       " [16],\n",
       " [17],\n",
       " [19, 20, 21],\n",
       " [29, 31],\n",
       " [29, 30, 31],\n",
       " [32],\n",
       " [0],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2, 4],\n",
       " [8, 11, 12, 13],\n",
       " [13, 14, 15, 17, 18],\n",
       " [20],\n",
       " [20, 21, 22, 24],\n",
       " [20, 24, 25],\n",
       " [20, 24, 25],\n",
       " [30, 31, 33],\n",
       " [30, 35, 37],\n",
       " [30, 36],\n",
       " [56, 59, 60],\n",
       " [11],\n",
       " [12],\n",
       " [8, 9],\n",
       " [13, 14],\n",
       " [13, 15],\n",
       " [17],\n",
       " [33, 34, 35, 36],\n",
       " [36],\n",
       " [0, 1],\n",
       " [2],\n",
       " [9, 10],\n",
       " [2, 3],\n",
       " [2, 5, 6],\n",
       " [14],\n",
       " [19],\n",
       " [22, 23, 26, 29, 33, 37],\n",
       " [22, 23, 26, 29, 33, 37],\n",
       " [2],\n",
       " [2],\n",
       " [37, 38],\n",
       " [29, 31],\n",
       " [23],\n",
       " [0],\n",
       " [0],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 3, 4, 5],\n",
       " [14, 15, 16],\n",
       " [0, 2, 26, 29, 30],\n",
       " [31, 32, 33, 34],\n",
       " [0, 2],\n",
       " [0, 2],\n",
       " [13],\n",
       " [13],\n",
       " [16],\n",
       " [22],\n",
       " [30],\n",
       " [38, 39],\n",
       " [0],\n",
       " [0],\n",
       " [5, 7, 9, 13],\n",
       " [5, 7, 9, 13],\n",
       " [23, 24],\n",
       " [26, 27],\n",
       " [8, 10],\n",
       " [13, 14, 15, 16],\n",
       " [24, 25, 26],\n",
       " [13, 14, 15, 16],\n",
       " [20, 21, 22],\n",
       " [27, 28],\n",
       " [33, 34],\n",
       " [33, 35],\n",
       " [33, 37],\n",
       " [33, 37, 38],\n",
       " [39, 40, 41],\n",
       " [],\n",
       " [0, 1, 10],\n",
       " [7],\n",
       " [0, 1, 10],\n",
       " [10],\n",
       " [10],\n",
       " [10],\n",
       " [10],\n",
       " [10],\n",
       " [10],\n",
       " [10],\n",
       " [10],\n",
       " [0],\n",
       " [2],\n",
       " [20],\n",
       " [20, 21, 22],\n",
       " [0, 2],\n",
       " [36],\n",
       " [2, 17],\n",
       " [46, 47, 48, 49, 62, 63, 64],\n",
       " [0],\n",
       " [0, 1],\n",
       " [0, 5, 6, 7],\n",
       " [8, 9],\n",
       " [21, 22],\n",
       " [22, 24, 25, 26],\n",
       " [29, 30, 31, 32, 33],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [14, 15, 16, 17],\n",
       " [20],\n",
       " [20],\n",
       " [22, 23, 25, 26],\n",
       " [29, 30, 31, 32],\n",
       " [47, 48],\n",
       " [0],\n",
       " [51, 52, 53],\n",
       " [1, 2, 3, 5, 6],\n",
       " [7, 8, 9],\n",
       " [9, 11, 12],\n",
       " [22, 23, 26, 27, 28],\n",
       " [31, 32, 33],\n",
       " [39, 42],\n",
       " [39, 44],\n",
       " [0, 5, 6],\n",
       " [11, 19, 20],\n",
       " [21, 22, 23],\n",
       " [11, 30],\n",
       " [11, 40, 41, 42],\n",
       " [11, 52, 53, 54],\n",
       " [1, 11, 13, 28],\n",
       " [13, 14],\n",
       " [0, 13, 14, 22, 25, 26],\n",
       " [8, 9, 11, 13],\n",
       " [0, 27, 31],\n",
       " [31, 32],\n",
       " [27, 28],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [1],\n",
       " [2, 5],\n",
       " [7, 8, 9],\n",
       " [18, 20, 21],\n",
       " [24],\n",
       " [0, 5, 6, 7],\n",
       " [5, 9],\n",
       " [5, 9],\n",
       " [9, 10, 11],\n",
       " [12, 13, 14],\n",
       " [24, 25],\n",
       " [24, 25],\n",
       " [24, 25],\n",
       " [33],\n",
       " [0],\n",
       " [0, 1, 2],\n",
       " [0],\n",
       " [0, 10, 12, 15, 17],\n",
       " [10, 15, 17, 18, 19, 20],\n",
       " [24],\n",
       " [24],\n",
       " [24],\n",
       " [24],\n",
       " [17, 24, 25, 26],\n",
       " [4],\n",
       " [4, 5],\n",
       " [5],\n",
       " [6],\n",
       " [5],\n",
       " [6],\n",
       " [6],\n",
       " [1],\n",
       " [1, 5, 7],\n",
       " [2, 3],\n",
       " [1, 2, 3, 4],\n",
       " [0, 1],\n",
       " [0, 5],\n",
       " [0, 7],\n",
       " [6, 9, 10, 19, 25, 31, 35],\n",
       " [10, 19, 20],\n",
       " [10],\n",
       " [10, 19, 20],\n",
       " [19, 20],\n",
       " [19, 20, 21],\n",
       " [10, 12],\n",
       " [10, 12, 14],\n",
       " [19, 23],\n",
       " [13, 14],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [1, 2, 7, 8, 10],\n",
       " [1, 2, 7, 8, 9],\n",
       " [1, 2, 7, 8, 10],\n",
       " [9, 10],\n",
       " [25, 26, 27],\n",
       " [0, 1, 3],\n",
       " [9, 12, 13],\n",
       " [9, 15],\n",
       " [21, 24],\n",
       " [27, 28, 29],\n",
       " [27, 28],\n",
       " [27, 28],\n",
       " [9, 14, 15, 16],\n",
       " [21, 24],\n",
       " [19, 30, 31],\n",
       " [5, 6, 7, 9, 10, 11, 15],\n",
       " [15, 16],\n",
       " [18, 19],\n",
       " [35, 37],\n",
       " [35, 37],\n",
       " [35, 37],\n",
       " [0, 1],\n",
       " [3],\n",
       " [6, 7],\n",
       " [16, 17, 18],\n",
       " [20, 21],\n",
       " [29, 32],\n",
       " [30, 32],\n",
       " [39, 40],\n",
       " [22, 23, 24, 25],\n",
       " [18],\n",
       " [32],\n",
       " [23],\n",
       " [],\n",
       " [34],\n",
       " [0, 4, 9, 31, 32],\n",
       " [0, 5],\n",
       " [2, 5],\n",
       " [5, 6],\n",
       " [5, 6],\n",
       " [30, 31]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model_eval(new_network, eval_train_batches, 0, training_data['QUESTIONS'].apply(lambda x: x[0]['SHINT_']).tolist(), 0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a53720000ed403c8b8eb8573ff7b626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1807), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr = 0.000005\n",
      "epoch 0 train_loss: 0.122\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57a2168935514ff29a673e445e8104b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-155-41a2b2197348>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_train_3d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.00002\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-108-292a0695e69a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(network, data, dev_batches, num_epochs, lr)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunning_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch %d train_loss: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcurrent_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mnew_model_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp_golds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-107-b9b4ee56998e>\u001b[0m in \u001b[0;36mnew_model_eval\u001b[0;34m(network, dev_batches, current_epoch, sp_golds, avg_loss)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mout_dct\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_fgc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0msp_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_dct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-aa65ccc0f9ec>\u001b[0m in \u001b[0;36mpredict_fgc\u001b[0;34m(self, batch, threshold)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_fgc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0mmax_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mmax_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-aa65ccc0f9ec>\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-aa65ccc0f9ec>\u001b[0m in \u001b[0;36mforward_nn\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mmax_sent_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "train(new_network, dataloader_train_3d, a, 20, 0.00002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 768])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Parameter(torch.FloatTensor(768).uniform_(-0.1, 0.1)).expand(2, 10, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 7, 68])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = iter(dataloader_train_3d).next()['ids']\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 4397,  342, 1367, 2548, 1355, 4385, 4342, 4342, 4500,  784,  720,\n",
       "         3341, 7157, 4635, 6009, 8024, 2130, 2768, 1400, 1315, 5543, 3175,  912,\n",
       "         4638, 3123, 6822, 5632, 2346, 1673, 2349,  775, 1358, 4635, 6009, 1920,\n",
       "         7623, 8043,  102, 7479, 5865, 6814,  782, 4638, 2608, 2552,  680, 3675,\n",
       "         1213, 8024,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 101, 4397,  342, 1367, 2548, 1355, 4385, 4342, 4342, 4500,  784,  720,\n",
       "         3341, 7157, 4635, 6009, 8024, 2130, 2768, 1400, 1315, 5543, 3175,  912,\n",
       "         4638, 3123, 6822, 5632, 2346, 1673, 2349,  775, 1358, 4635, 6009, 1920,\n",
       "         7623, 8043,  102, 4397,  679,  852, 2868, 2245,  749,  782, 5102, 4638,\n",
       "         4761, 6399, 7566, 1818, 8024,  102,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 101, 4397,  342, 1367, 2548, 1355, 4385, 4342, 4342, 4500,  784,  720,\n",
       "         3341, 7157, 4635, 6009, 8024, 2130, 2768, 1400, 1315, 5543, 3175,  912,\n",
       "         4638, 3123, 6822, 5632, 2346, 1673, 2349,  775, 1358, 4635, 6009, 1920,\n",
       "         7623, 8043,  102,  738, 3136, 2193, 2769,  812, 8024,  102,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 101, 4397,  342, 1367, 2548, 1355, 4385, 4342, 4342, 4500,  784,  720,\n",
       "         3341, 7157, 4635, 6009, 8024, 2130, 2768, 1400, 1315, 5543, 3175,  912,\n",
       "         4638, 3123, 6822, 5632, 2346, 1673, 2349,  775, 1358, 4635, 6009, 1920,\n",
       "         7623, 8043,  102, 6206,  809, 3291,  711,  782, 6887, 4638, 5125, 4868,\n",
       "         3341, 2190, 2521, 1220, 4289,  511,  102,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]], device='cuda:0')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_network.loss(iter(dataloader_train_3d).next())[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_network.loss(iter(dataloader_train_3d).next())[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': tensor([[[ 101, 1380, 2577,  ...,    0,    0,    0],\n",
       "          [ 101, 1380, 2577,  ...,    0,    0,    0],\n",
       "          [ 101, 1380, 2577,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 101, 1380, 2577,  ...,    0,    0,    0],\n",
       "          [ 101, 1380, 2577,  ...,    0,    0,    0],\n",
       "          [ 101, 1380, 2577,  ...,    0,    0,    0]],\n",
       " \n",
       "         [[ 101, 5018,  671,  ...,    0,    0,    0],\n",
       "          [ 101, 5018,  671,  ...,    0,    0,    0],\n",
       "          [ 101, 5018,  671,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 101, 5018,  671,  ...,    0,    0,    0],\n",
       "          [ 101, 5018,  671,  ...,    0,    0,    0],\n",
       "          [ 101, 5018,  671,  ...,    0,    0,    0]]], device='cuda:0'),\n",
       " 'mask_ids': tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]]], device='cuda:0'),\n",
       " 'segment_ids': tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]]], device='cuda:0'),\n",
       " 'labels': tensor([[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]], device='cuda:0')}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter(dataloader_train_3d).next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Improved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data_with_performance_0 = datapreprocessing(validation_data, True)\n",
    "training_data_with_performance_0 = datapreprocessing(training_data, True)\n",
    "test_data_with_performance_0 = datapreprocessing(test_data, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a07dee24f94334b3b836ebff3d932e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=882), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'sp_em': 0.18, 'sp_prec': 0.573, 'sp_recall': 0.381, 'sp_f1': 0.43}\n",
      "epoch 0 eval_recall: 0.381 eval_f1: 0.430 loss: 0.001\n"
     ]
    }
   ],
   "source": [
    "train_pred_0, train_obs_0 = new_model_eval(new_network, b, 0, training_data['QUESTIONS'].apply(lambda x: x[0]['SHINT_']).tolist()\n",
    ", 0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_with_performance_0['train_pred'] = train_pred_0\n",
    "training_data_with_performance_0['train_obs'] = train_obs_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_sp = []\n",
    "for i in range(training_data_with_performance_0.shape[0]):\n",
    "    para = training_data_with_performance_0['Sentence_List'][i]\n",
    "    sen = []\n",
    "    for index in training_data_with_performance_0['train_pred'][i]:\n",
    "        sen.append(para[index])\n",
    "    correct_sp.append(sen)\n",
    "training_data_with_performance_0['Pred_List'] = correct_sp\n",
    "correct_sp = []\n",
    "for i in range(training_data_with_performance_0.shape[0]):\n",
    "    para = training_data_with_performance_0['Sentence_List'][i]\n",
    "    sen = []\n",
    "    for index in training_data_with_performance_0['train_obs'][i]:\n",
    "        sen.append(para[index])\n",
    "    correct_sp.append(sen)\n",
    "training_data_with_performance_0['Obs_List'] = correct_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_with_performance_0.drop(['SE_Index', 'Label', 'train_pred', 'train_obs'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Sentence_List</th>\n",
       "      <th>Length</th>\n",
       "      <th>Pred_List</th>\n",
       "      <th>Obs_List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>苏东坡的老家在哪?</td>\n",
       "      <td>[嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...</td>\n",
       "      <td>35</td>\n",
       "      <td>[苏轼才20岁，]</td>\n",
       "      <td>[苏轼回蜀守丧，]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>苏东坡出生于哪一年?</td>\n",
       "      <td>[嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...</td>\n",
       "      <td>35</td>\n",
       "      <td>[苏轼才20岁，]</td>\n",
       "      <td>[嘉佑二年（1057年），, 苏轼才20岁，]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>苏东坡和谁一起进京参加会考?</td>\n",
       "      <td>[嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...</td>\n",
       "      <td>35</td>\n",
       "      <td>[苏轼才20岁，]</td>\n",
       "      <td>[苏轼才20岁，, 与弟弟苏辙一同进京参加会考，]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>苏东坡与曾巩是否同为欧阳修的学生?</td>\n",
       "      <td>[嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...</td>\n",
       "      <td>35</td>\n",
       "      <td>[苏轼以一篇《刑赏忠厚之至论》的论文得到考官梅尧臣的青睐，]</td>\n",
       "      <td>[欧阳修亦十分赞赏，, 原本欲拔擢为第一，, 但又怕该文为自己的门生曾巩所作，, 为了避嫌，...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>苏东坡与王安石在职场上是否理念相同?</td>\n",
       "      <td>[嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...</td>\n",
       "      <td>35</td>\n",
       "      <td>[苏轼以一篇《刑赏忠厚之至论》的论文得到考官梅尧臣的青睐，]</td>\n",
       "      <td>[反对王安石变法中的一些作为，, 王安石于是屡次在神宗面前诋毁苏轼，]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>小明感染肠病毒后痊瘉一周后是否就不会再传染给别人了?</td>\n",
       "      <td>[国内肠病毒轻症疫情持续上升，, 另新增1例肠病毒71型并发重症病例。, 疾病管制署再次呼吁...</td>\n",
       "      <td>42</td>\n",
       "      <td>[请尽速送大医院接受治疗。]</td>\n",
       "      <td>[痊愈后肠病毒会随著粪便排出达8到12周之久。]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>877</td>\n",
       "      <td>这起诈骗案件发生于台北市哪一个行政区？</td>\n",
       "      <td>[松山分局三民派出所警员白小帆，, 警员张秀秀。, 于一百零八年十月三十一日十五时至十七时，...</td>\n",
       "      <td>32</td>\n",
       "      <td>[松山分局三民派出所警员白小帆，, 于一百零八年十月三十一日十五时至十七时，, 疑似遭到诈骗...</td>\n",
       "      <td>[松山分局三民派出所警员白小帆，, 疑似遭到诈骗两元，]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>878</td>\n",
       "      <td>这起诈骗案件发生的日期是哪一天？</td>\n",
       "      <td>[松山分局三民派出所警员白小帆，, 警员张秀秀。, 于一百零八年十月三十一日十五时至十七时，...</td>\n",
       "      <td>32</td>\n",
       "      <td>[疑似遭到诈骗两元，, 到场后，发现系一名年约八十二岁陈姓妇人\\n欲提领新台币三十三万元。]</td>\n",
       "      <td>[于一百零八年十月三十一日十五时至十七时，, 疑似遭到诈骗两元，]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>这起诈骗案件的受害人姓氏为何？</td>\n",
       "      <td>[松山分局三民派出所警员白小帆，, 警员张秀秀。, 于一百零八年十月三十一日十五时至十七时，...</td>\n",
       "      <td>32</td>\n",
       "      <td>[疑似遭到诈骗两元，]</td>\n",
       "      <td>[疑似遭到诈骗两元，, 到场后，发现系一名年约八十二岁陈姓妇人\\n欲提领新台币三十三万元。]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>881</td>\n",
       "      <td>反诈骗专线电话是几号？</td>\n",
       "      <td>[松山分局三民派出所警员白小帆，, 警员张秀秀。, 于一百零八年十月三十一日十五时至十七时，...</td>\n",
       "      <td>32</td>\n",
       "      <td>[避免遭诈骗。]</td>\n",
       "      <td>[也可拨打一六五求证，, 避免遭诈骗。]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>723 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Question  \\\n",
       "0                     苏东坡的老家在哪?   \n",
       "1                    苏东坡出生于哪一年?   \n",
       "2                苏东坡和谁一起进京参加会考?   \n",
       "4             苏东坡与曾巩是否同为欧阳修的学生?   \n",
       "5            苏东坡与王安石在职场上是否理念相同?   \n",
       "..                          ...   \n",
       "875  小明感染肠病毒后痊瘉一周后是否就不会再传染给别人了?   \n",
       "877         这起诈骗案件发生于台北市哪一个行政区？   \n",
       "878            这起诈骗案件发生的日期是哪一天？   \n",
       "880             这起诈骗案件的受害人姓氏为何？   \n",
       "881                 反诈骗专线电话是几号？   \n",
       "\n",
       "                                         Sentence_List  Length  \\\n",
       "0    [嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...      35   \n",
       "1    [嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...      35   \n",
       "2    [嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...      35   \n",
       "4    [嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...      35   \n",
       "5    [嘉佑二年（1057年），, 苏轼才20岁，, 与弟弟苏辙一同进京参加会考，, 苏轼中进士第...      35   \n",
       "..                                                 ...     ...   \n",
       "875  [国内肠病毒轻症疫情持续上升，, 另新增1例肠病毒71型并发重症病例。, 疾病管制署再次呼吁...      42   \n",
       "877  [松山分局三民派出所警员白小帆，, 警员张秀秀。, 于一百零八年十月三十一日十五时至十七时，...      32   \n",
       "878  [松山分局三民派出所警员白小帆，, 警员张秀秀。, 于一百零八年十月三十一日十五时至十七时，...      32   \n",
       "880  [松山分局三民派出所警员白小帆，, 警员张秀秀。, 于一百零八年十月三十一日十五时至十七时，...      32   \n",
       "881  [松山分局三民派出所警员白小帆，, 警员张秀秀。, 于一百零八年十月三十一日十五时至十七时，...      32   \n",
       "\n",
       "                                             Pred_List  \\\n",
       "0                                            [苏轼才20岁，]   \n",
       "1                                            [苏轼才20岁，]   \n",
       "2                                            [苏轼才20岁，]   \n",
       "4                       [苏轼以一篇《刑赏忠厚之至论》的论文得到考官梅尧臣的青睐，]   \n",
       "5                       [苏轼以一篇《刑赏忠厚之至论》的论文得到考官梅尧臣的青睐，]   \n",
       "..                                                 ...   \n",
       "875                                     [请尽速送大医院接受治疗。]   \n",
       "877  [松山分局三民派出所警员白小帆，, 于一百零八年十月三十一日十五时至十七时，, 疑似遭到诈骗...   \n",
       "878     [疑似遭到诈骗两元，, 到场后，发现系一名年约八十二岁陈姓妇人\\n欲提领新台币三十三万元。]   \n",
       "880                                        [疑似遭到诈骗两元，]   \n",
       "881                                           [避免遭诈骗。]   \n",
       "\n",
       "                                              Obs_List  \n",
       "0                                            [苏轼回蜀守丧，]  \n",
       "1                              [嘉佑二年（1057年），, 苏轼才20岁，]  \n",
       "2                            [苏轼才20岁，, 与弟弟苏辙一同进京参加会考，]  \n",
       "4    [欧阳修亦十分赞赏，, 原本欲拔擢为第一，, 但又怕该文为自己的门生曾巩所作，, 为了避嫌，...  \n",
       "5                  [反对王安石变法中的一些作为，, 王安石于是屡次在神宗面前诋毁苏轼，]  \n",
       "..                                                 ...  \n",
       "875                           [痊愈后肠病毒会随著粪便排出达8到12周之久。]  \n",
       "877                       [松山分局三民派出所警员白小帆，, 疑似遭到诈骗两元，]  \n",
       "878                  [于一百零八年十月三十一日十五时至十七时，, 疑似遭到诈骗两元，]  \n",
       "880     [疑似遭到诈骗两元，, 到场后，发现系一名年约八十二岁陈姓妇人\\n欲提领新台币三十三万元。]  \n",
       "881                               [也可拨打一六五求证，, 避免遭诈骗。]  \n",
       "\n",
       "[723 rows x 5 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mismatch = training_data_with_performance_0[training_data_with_performance_0['Pred_List'] != training_data_with_performance_0['Obs_List']]\n",
    "train_mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 17\n",
    "print(train_mismatch.loc[i]['Question'])\n",
    "print(train_mismatch.loc[i]['Pred_List'])\n",
    "print(train_mismatch.loc[i]['Obs_List'])\n",
    "train_mismatch.loc[i]['Sentence_List']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0724 09:52:32.290062 140341672732480 tokenization_utils.py:375] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /root/.cache/torch/transformers/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for a in dataloader_train_3d:\n",
    "    for b in a['']:\n",
    "        for c in b:\n",
    "            print(c)\n",
    "            #print(tokenizer.convert_ids_to_tokens(c.tolist()))\n",
    "    counter += 1\n",
    "    if counter == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
